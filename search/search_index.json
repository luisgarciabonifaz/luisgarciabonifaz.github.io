{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bienvenido a la web de clases de Luis Garc\u00eda /Benvingut a la web de classes de Luis Garc\u00eda","text":"<p>Esta es la wiki que uso para colgar los contenidos de las asignaturas que imparto en Ciclos Formativos</p>"},{"location":"#grado-medio-smr","title":"Grado Medio SMR","text":"<ul> <li>Sistemes Operatius Monolloc </li> </ul>"},{"location":"#curso-de-especializacion-en-inteligencia-artificialy-big-data","title":"Curso de especializacion en Inteligencia Artificialy Big Data","text":"<ul> <li>Big Data Aplicado </li> <li>Sistemas Big Data </li> </ul>"},{"location":"BDA/IndiceBDA/","title":"Big Data Aplicado","text":""},{"location":"BDA/IndiceBDA/#temas","title":"Temas","text":"<ul> <li>T1 - Introducci\u00f3n Big Data </li> <li>T2 - Repaso SQL </li> <li>T3 - Bases de datos NoSQL </li> <li>T4 - MongoDB </li> <li>T5 - Almacenamiento de Datos </li> <li>T6 - ETL </li> <li>T7 - Visualizaci\u00f3n de Datos </li> <li>T8 - Bussines Intelligencen </li> <li>T9 - Proyecto </li> </ul>"},{"location":"BDA/Tema01/IntroduccionBigData/","title":"1. Introducci\u00f3n Big Data","text":""},{"location":"BDA/Tema01/IntroduccionBigData/#11-big-data","title":"1.1. Big Data","text":"<p>El Big Data es el an\u00e1lisis masivo de datos. Una cantidad de datos, tan sumamente grande, que las aplicaciones de software de procesamiento de datos que tradicionalmente se ven\u00edan usando no son capaces de capturar, tratar y poner en valor en un tiempo razonable.</p> <p>El mismo t\u00e9rmino tambi\u00e9n se refiere a las nuevas tecnolog\u00edas que hacen posible el almacenamiento y procesamiento, adem\u00e1s de al uso que se hace de la informaci\u00f3n obtenida a trav\u00e9s de dichas tecnolog\u00edas.</p> <p>La gran popularidad del Big Data es debida principalmente a la oportunidad que ven en ella las grandes empresas. El hecho de poder analizar millones de datos de distintas procedencias como redes sociales, im\u00e1genes digitales, emails, encuestas, logs, se\u00f1ales de m\u00f3vil, etc., permite que la toma de decisiones sea mucho m\u00e1s r\u00e1pida, precisa y efectiva.</p> Big Data permite abordar problemas empresariales que antes eran insolubles. <ul> <li>Generar informaci\u00f3n valiosa</li> <li>Perfeccionar campa\u00f1as y t\u00e9cnicas de marketing</li> <li>Entrenar m\u00e1quinas</li> <li>Modelado predictivo y otras aplicaciones avanzadas de an\u00e1lisis</li> <li>Reducir costos</li> <li>Ahorrar tiempo</li> <li>Comprender mejor las condiciones del mercado</li> <li>Vencer a grandes competidores y retener a clientes leales.</li> </ul> \u00bf Cuando considerar la utilizaci\u00f3n la arquitectura Big Data? <ul> <li>Los datos son demasiado grandes para que los almacenes de datos tradicionales los procesen.</li> <li>Transformaci\u00f3n y an\u00e1lisis de datos no estructurados.</li> <li>Necesidad de analizar datos en tiempo real con baja latencia.</li> </ul>"},{"location":"BDA/Tema01/IntroduccionBigData/#12-historia","title":"1.2. Historia","text":"<p>El t\u00e9rmino \u2018Big Data\u2019 ha estado en uso desde principios de los a\u00f1os 90. Aunque no se sabe exactamente qui\u00e9n fue el primero en usar el t\u00e9rmino, la mayor\u00eda de las personas atribuyen a John R. Mashey (que en ese momento trabajaba en Silicon Graphics) por hacer popular el t\u00e9rmino.</p> <p></p>"},{"location":"BDA/Tema01/IntroduccionBigData/#13-componentes-de-big-data","title":"1.3. Componentes de Big Data","text":"<p>Los componentes de Big Data constan de una variedad de elementos, pero no es necesario utilizarlos todos juntos para un caso de uso. Los componentes var\u00edan seg\u00fan el caso de uso empresarial.</p> <p></p>"},{"location":"BDA/Tema01/IntroduccionBigData/#131-fuentes-de-datos","title":"1.3.1. Fuentes de Datos","text":"<p>Las fuentes incluyen una gran variedad de datos, como bases de datos relacionales tradicionales, archivos de registro de procesos empresariales y aplicaciones, y mensajes en tiempo real generados por eventos y dispositivos de IoT.</p> <p>Los datos en Big Data pueden ser clasificados en tres tipos seg\u00fan su origen:</p> <ul> <li>Generados por m\u00e1quinas: procedentes de sensores (GPS, contadores\u2026), Web Log Data (redes, aplicaciones\u2026), procedentes de puntos de venta (c\u00f3digos de barras de un producto) y financieros (operaciones bancarias).</li> <li>Generados por personas: formularios, registros de contabilidad\u2026</li> <li>Datos externos: redes sociales, patentes, datos web, datos m\u00f3viles, etiquetas RFID (rastreo electr\u00f3nico) y c\u00f3digos de barras, datos de ubicaci\u00f3n, sensores de datos, entre otros.</li> </ul> <p>Seg\u00fan su estructura se pueden clasificar en tres tipos:</p> <ul> <li>Datos estructurados: son aquellos que se encuentran ordenados y organizados en una estructura predefinida, c\u00f3mo una tabla o una base de datos relacional. Estos datos son f\u00e1ciles de gestionar y analizar, ya que su estructura permite una mayor predictibilidad. Ejemplos de datos estructurados incluyen registros en tablas, ficheros XML asociados a un esquema, y facturas autogeneradas al realizar una compra.</li> <li>Datos semiestructurados: son aquellos que tienen cierta estructura, pero no est\u00e1n organizados en una estructura r\u00edgida c\u00f3mo los datos estructurados. Ejemplos de datos semiestructurados incluyen documentos JSON y XML sin esquema asociado.</li> <li>Datos no estructurados: son aquellos que no tienen una estructura predefinida y pueden ser dif\u00edciles de gestionar y analizar. Ejemplos de datos no estructurados incluyen publicaciones en redes sociales, v\u00eddeos, im\u00e1genes, y texto libre.</li> </ul> <p></p>"},{"location":"BDA/Tema01/IntroduccionBigData/#132-almacenamiento-de-datos","title":"1.3.2. Almacenamiento de Datos","text":"<p>El almacenamiento de este gran volumen de datos generalmente implican sistemas de almacenamiento distribuidos de gran capacidad que facilitan el an\u00e1lisis de esa inmensa cantidad de informaci\u00f3n.</p> <p>Hay muchas opciones disponibles para almacenar grandes vol\u00famenes de datos.</p> <ul> <li>Los sistemas de archivos distribuidos, como Hadoop Distributed File System (HDFS) y Google File System (GFS), son una opci\u00f3n popular para almacenar grandes conjuntos de datos en m\u00faltiples servidores.</li> <li>Los servicios de almacenamiento en la nube, como Amazon S3 y Microsoft Azure Blob Storage, tambi\u00e9n son opciones populares para almacenar datos en la nube.</li> </ul> <p>La gesti\u00f3n efectiva de los datos es esencial para garantizar su integridad y disponibilidad. Esto incluye:</p> <ul> <li>La implementaci\u00f3n de medidas de seguridad adecuadas para proteger los datos contra el acceso no autorizado</li> <li>La realizaci\u00f3n de copias de seguridad regulares para garantizar la recuperaci\u00f3n en caso de p\u00e9rdida de datos</li> <li>La implementaci\u00f3n de pol\u00edticas y procedimientos para garantizar que los datos se manejen de manera responsable y \u00e9tica.</li> </ul> <p>Esto \u00faltimo nos lleva al concepto de gobernanza de datos que abarca las pol\u00edticas y procedimientos que se implementan para garantizar que los datos de una organizaci\u00f3n sean precisos y que se manejen correctamente cuando se ingresan, almacenan, manejan, acceden y eliminan.</p> <p>Las responsabilidades de gobernanza de datos incluyen establecer la infraestructura y tecnolog\u00eda, configurar y mantener procesos y pol\u00edticas, e identificar a las personas (o cargos) de una organizaci\u00f3n que tienen la autoridad y responsabilidad de gestionar y salvaguardar tipos espec\u00edficos de datos.</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#133-ingesta-de-mensajes-en-tiempo-real","title":"1.3.3. Ingesta de Mensajes en Tiempo Real","text":"<p>La ingesti\u00f3n de datos en tiempo real incluye mecanismos para recibir mensajes en streaming, almacenarlos y procesarlos para obtener conocimientos. </p> <p>Los componentes que facilitan la recepci\u00f3n de mensajes act\u00faan c\u00f3mo un b\u00fafer mientras los datos se env\u00edan a un almacenamiento para su procesamiento. </p>"},{"location":"BDA/Tema01/IntroduccionBigData/#134-procesamiento-por-lotes","title":"1.3.4. Procesamiento por Lotes","text":"<p>El procesamiento por lotes generalmente implica conjuntos de datos grandes que se procesan secuencialmente para agregar, filtrar y preparar los datos para un an\u00e1lisis posterior. </p> <p>Este enfoque puede ser \u00fatil cuando se trata con datos hist\u00f3ricos o cuando se realizan an\u00e1lisis complejos que requieren m\u00e1s tiempo.</p> <p>Algunos de los componentes de procesamiento por lotes incluyen Azure Data Factory, Azure Batch, U-SQL (Azure Data Lake Analytics), cl\u00fasteres HDInsight Hadoop y Spark</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#135-procesamiento-en-tiempo-real","title":"1.3.5. Procesamiento en Tiempo Real","text":"<p>El procesamiento en tiempo real del Big Data implica analizar datos a medida que se generan para tomar decisiones o desencadenar acciones en tiempo real.</p> <p>Por ejemplo, el procesamiento en tiempo real puede utilizarse para monitorear feeds sociales en busca de menciones de una marca o producto en particular.</p> <p>Casos de Uso en Tiempo Real</p> <p>Algunos de los casos de uso en tiempo real para las arquitecturas mencionadas anteriormente son:</p> <ul> <li>Twitter y Facebook utilizan la arquitectura Lambda para llevar a cabo an\u00e1lisis en tiempo real y por lotes de sus mensajes y publicaciones.</li> <li>Los software integrados en los coches el\u00e9ctricos env\u00edan datos en tiempo real (a trav\u00e9s de dispositivos IoT/Edge) al fabricante, que luego realiza an\u00e1lisis de datos de sensores en tiempo real y por lotes para mejorar el rendimiento de los coches el\u00e9ctricos. Esto se basa en la arquitectura Lambda.</li> <li>El sector de las telecomunicaciones tiene grandes vol\u00famenes de datos que se pueden analizar en tiempo real para identificar y solucionar anomal\u00edas relacionadas con la red. Los datos pueden alimentar modelos de ML en tiempo real y el modelo de ML puede sugerir recomendaciones que se pueden implementar mediante flujos de IA. Esto suele seguir la arquitectura Kappa.</li> </ul>"},{"location":"BDA/Tema01/IntroduccionBigData/#136-procesamiento-hibrido","title":"1.3.6.  Procesamiento Hibrido","text":"<p>Es una mezcla de  los dos anteriores y tiene dos posibles arquitecturas:</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#1361-lambda","title":"1.3.6.1. Lambda","text":"<p>Su objetivo es tener un sistema robusto tolerante a fallos que sea linealmente escalable y que permita realizar escrituras y lecturas con baja latencia.</p> <p></p> <p>La nueva informaci\u00f3n recogida por el sistema se env\u00eda tanto a la capa de batch como a la capa de streaming (Speed Layer).</p> <p>En la capa batch (Batch Layer) se gestiona la informaci\u00f3n en crudo. Los datos nuevos se a\u00f1aden a los ya existentes. Seguidamente se hace un tratamiento mediante un proceso batch cuyo resultado ser\u00e1n las denominadas Batch Views.</p> <p>La capa que sirve los datos(Serving Layer), indexa las Batch Views para que puedan ser consultadas con baja latencia.</p> <p>La capa de streaming (Speed Layer), compensa la alta latencia de las escrituras que ocurre en la serving layer y solo tiene en cuenta los datos nuevos.</p> <p>Finalmente, la respuesta a las consultas realizadas se construye combinando los resultados de las Batch Views y de las vistas en tiempo real (Real-time Views).</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#1362-kappa","title":"1.3.6.2. Kappa","text":"<p>Su objetivo es eliminar la capa batch dejando solamente la capa de streaming.</p> <p>Esta capa, a diferencia de la de tipo batch, no tiene un comienzo ni un fin desde un punto de vista temporal y est\u00e1 continuamente procesando nuevos datos a medida que van llegando.</p> <p>Sus cuatro pilares principales son:</p> <ul> <li>Todo es un stream: las operaciones batch son un subconjunto de las operaciones de streaming, por lo que todo puede ser tratado como un stream.</li> <li>Los datos de partida no se modifican: los datos son almacenados sin ser transformados y las vistas se derivan de ellos. Un estado concreto puede ser recalculado puesto que la informaci\u00f3n de origen no se modifica.</li> <li>Solo existe un flujo de procesamiento: puesto que mantenemos un solo flujo, el c\u00f3digo, el mantenimiento y la actualizaci\u00f3n del sistema se ven reducidos considerablemente.</li> <li>Posibilidad de volver a lanzar un procesamiento: se puede modificar un procesamiento concreto y su configuraci\u00f3n para variar los resultados obtenidos partiendo de los mismos datos de entrada</li> </ul> <p></p>"},{"location":"BDA/Tema01/IntroduccionBigData/#137-almacen-de-datos-analiticos-data-warehouse","title":"1.3.7. Almac\u00e9n de Datos Anal\u00edticos (Data Warehouse)","text":"<p>Los almacenes de datos anal\u00edticos o  Data Warehouses en ingl\u00e9s, son sistemas de almacenamiento y gesti\u00f3n de datos dise\u00f1ados espec\u00edficamente para la recopilaci\u00f3n, organizaci\u00f3n y an\u00e1lisis de grandes vol\u00famenes de informaci\u00f3n empresarial. </p> <p>Estos almacenes est\u00e1n optimizados para facilitar la consulta y el procesamiento de datos con el objetivo de obtener informaci\u00f3n significativa para la toma de decisiones.</p> <p>Algunas de sus caracter\u00edsticas son:</p> <ul> <li>Consolidaci\u00f3n de datos </li> <li>Estructura optimizada</li> <li>Historizaci\u00f3n</li> <li>Rendimiento</li> <li>Herramientas de consulta y reporting</li> <li>Seguridad y control de acceso</li> </ul>"},{"location":"BDA/Tema01/IntroduccionBigData/#138-analisis-e-informes","title":"1.3.8. An\u00e1lisis e Informes","text":""},{"location":"BDA/Tema01/IntroduccionBigData/#1381-analisis","title":"1.3.8.1. An\u00e1lisis","text":"<p>Tipos de an\u00e1lisis de big data:</p> <ul> <li>Predictivo<ul> <li>El an\u00e1lisis predictivo implica utilizar t\u00e9cnicas estad\u00edsticas para hacer predicciones sobre eventos futuros bas\u00e1ndose en datos hist\u00f3ricos. Este enfoque puede aplicarse para generar conocimientos sobre tendencias o comportamientos futuros.</li> </ul> </li> <li>De diagn\u00f3stico<ul> <li>El an\u00e1lisis de diagn\u00f3stico utiliza algoritmos para descubrir patrones y relaciones dentro de grandes conjuntos de datos. Este enfoque puede aplicarse para extraer informaci\u00f3n \u00fatil de grandes vol\u00famenes de datos no estructurados o semiestructurados.</li> </ul> </li> <li>Descriptivo<ul> <li>El an\u00e1lisis descriptivo es un m\u00e9todo de an\u00e1lisis de datos que se utiliza para resumir y describir sus caracter\u00edsticas principales. Se utiliza com\u00fanmente para proporcionar una visi\u00f3n general de los datos y para identificar patrones y tendencias. </li> </ul> Uso <p>El an\u00e1lisis descriptivo puede utilizarse para obtener informaci\u00f3n a partir de conjuntos de datos grandes y complejos. Por ejemplo, una empresa podr\u00eda utilizar el an\u00e1lisis descriptivo para entender la demograf\u00eda de su base de clientes o para identificar patrones en el comportamiento de los clientes.</p> </li> <li>Prescriptivo con Big Data<ul> <li>El an\u00e1lisis prescriptivo es un tipo de an\u00e1lisis de datos que utiliza t\u00e9cnicas avanzadas de an\u00e1lisis, como el aprendizaje autom\u00e1tico y los algoritmos de optimizaci\u00f3n, para sugerir acciones que se pueden tomar para lograr un resultado deseado.</li> </ul> Uso <p>El an\u00e1lisis prescriptivo puede utilizarse para tomar decisiones basadas en datos a partir de la informaci\u00f3n obtenida a partir de conjuntos de datos grandes y complejos. Por ejemplo, una empresa podr\u00eda utilizar el an\u00e1lisis prescriptivo para optimizar su cadena de suministro o para determinar la mejor estrategia de precios para sus productos.</p> </li> </ul>"},{"location":"BDA/Tema01/IntroduccionBigData/#1382-informes-o-visualizacion-de-datos","title":"1.3.8.2. Informes o Visualizaci\u00f3n de datos","text":"<p>La visualizaci\u00f3n de datos es la presentaci\u00f3n de datos en formato ilustrado o gr\u00e1fico. Permite a los tomadores de decisiones ver la anal\u00edtica presentada de forma visual, de modo que puedan captar conceptos dif\u00edciles o identificar nuevos patrones. Con la visualizaci\u00f3n interactiva, se puede llevar el concepto un paso adelante utilizando tecnolog\u00eda para profundizar en diagramas y gr\u00e1ficas para observar mayor detalle, cambiando de forma interactiva qu\u00e9 datos se ven y c\u00f3mo se procesan.</p> <p>Hay muchas herramientas disponibles para la visualizaci\u00f3n de Big Data. Algunas de las herramientas m\u00e1s populares son Tableau, Power BI, Infogram, ChartBlocks, Datawrapper y Ploty. Estas herramientas permiten crear tablas, gr\u00e1ficos, mapas y otros tipos de visualizaciones para ayudar a comprender y comunicar los datos.</p> <p>La visualizaci\u00f3n de datos es importante porque permite transmitir conceptos de manera universal y r\u00e1pida. Tambi\u00e9n puede ayudar a identificar \u00e1reas que necesitan atenci\u00f3n o mejoras y esclarecer qu\u00e9 factores influencian el comportamiento de los clientes.</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#139-orquestacion","title":"1.3.9. Orquestaci\u00f3n","text":"<p>Para lograr un procesamiento por lotes o en tiempo real exitoso, la orquestaci\u00f3n del flujo de datos es muy importante para construir procesos por lotes o en tiempo real confiables y resistentes a fallos. </p>"},{"location":"BDA/Tema01/IntroduccionBigData/#1310-aprendizaje-automatico","title":"1.3.10. Aprendizaje Autom\u00e1tico","text":"<p>Big data y aprendizaje autom\u00e1tico son dos campos estrechamente relacionados y complementarios.</p> <ul> <li>Big data se refiere a conjuntos de datos extremadamente grandes y complejos que son dif\u00edciles de procesar utilizando m\u00e9todos tradicionales.</li> <li>El aprendizaje autom\u00e1tico, por otro lado, es una rama de la inteligencia artificial que se enfoca en desarrollar algoritmos que permitan a las m\u00e1quinas aprender de los datos y mejorar su rendimiento con el tiempo.</li> </ul> <p>El aprendizaje autom\u00e1tico aprovecha el big data para entrenar modelos m\u00e1s precisos y confiables. Cuanto m\u00e1s datos haya disponibles, m\u00e1s precisos y confiables ser\u00e1n los modelos del aprendizaje autom\u00e1tico. El aprendizaje autom\u00e1tico tiene aplicaciones amplias en el procesamiento y an\u00e1lisis del big data, c\u00f3mo la clasificaci\u00f3n y categorizaci\u00f3n autom\u00e1tica de datos, la detecci\u00f3n de anomal\u00edas y la predicci\u00f3n de resultados futuros.</p> <p>La combinaci\u00f3n de big data y aprendizaje autom\u00e1tico ofrece beneficios significativos. Permite descubrir informaci\u00f3n valiosa oculta en grandes vol\u00famenes de datos, mejorar la toma de decisiones basada en datos, automatizar tareas y optimizar procesos empresariales.</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#14-las-vs-de-la-arquitectura-big-data","title":"1.4. Las V's de la Arquitectura Big Data","text":"<p>El concepto de \"Las V's del Big Data\" se refiere a las caracter\u00edsticas clave que describen los datos masivos utilizados en el an\u00e1lisis de datos. A lo largo del tiempo, diferentes fuentes y expertos han propuesto diferentes cantidades de \"V's\" para describir estas caracter\u00edsticas. A continuaci\u00f3n, se mencionan las tres versiones m\u00e1s comunes:</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#las-3-vs-del-big-data","title":"Las 3 V's del Big Data:","text":"<ul> <li> <p>Volumen: Hace referencia a la cantidad de datos generados y almacenados. En el Big Data, se manejan conjuntos de datos extremadamente grandes.</p> </li> <li> <p>Variedad: Se refiere a la diversidad de tipos de datos. Estos pueden incluir texto, im\u00e1genes, audio, video, datos estructurados y no estructurados.</p> </li> <li> <p>Velocidad: Indica la rapidez con la que se generan y se deben analizar los datos. En el Big Data, se trata de procesar datos en tiempo real o casi en tiempo real.</p> </li> </ul>"},{"location":"BDA/Tema01/IntroduccionBigData/#las-5-vs-del-big-data","title":"Las 5 V's del Big Data:","text":"<p>Adem\u00e1s de las 3 V's mencionadas anteriormente, algunas fuentes tambi\u00e9n incluyen:</p> <ul> <li> <p>Veracidad: La calidad y precisi\u00f3n de los datos son esenciales. Los datos deben ser confiables y veraces para tomar decisiones precisas.</p> </li> <li> <p>Valor: Finalmente, el valor se refiere a la capacidad de extraer informaci\u00f3n valiosa y conocimiento \u00fatil de los datos. Los datos deben ser relevantes y aportar valor a una organizaci\u00f3n o proyecto.</p> </li> </ul>"},{"location":"BDA/Tema01/IntroduccionBigData/#las-7-vs-del-big-data","title":"Las 7 V's del Big Data:","text":"<p>Adem\u00e1s de las 5 V's mencionadas anteriormente, algunas fuentes tambi\u00e9n incluyen:</p> <ul> <li> <p>Viabilidad: Se refiere a la capacidad de llevar a cabo proyectos de Big Data de manera factible desde el punto de vista t\u00e9cnico y econ\u00f3mico.</p> </li> <li> <p>Visualizaci\u00f3n: La capacidad de representar y comunicar los datos de manera efectiva a trav\u00e9s de gr\u00e1ficos y herramientas visuales.</p> </li> </ul> <p>Estas V's son importantes para comprender las caracter\u00edsticas esenciales de los datos masivos y c\u00f3mo gestionarlos para obtener el m\u00e1ximo valor</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#15-infraestructura","title":"1.5. Infraestructura","text":"<p>Una infraestructura para Big Data debe facilitar la recopilaci\u00f3n, el almacenamiento y el an\u00e1lisis de grandes vol\u00famenes de datos, que pueden estar en diferentes formatos y gener\u00e1ndose en tiempo real. Para ello, se utilizan tecnolog\u00edas y servicios especiales que han sido creados espec\u00edficamente para dar soluci\u00f3n al procesamiento de estos enormes conjuntos de datos.</p> <p>Algunos de los principales elementos de hardware y software que integran una soluci\u00f3n arquitect\u00f3nica de Big Data son:</p> <ul> <li>Hardware: servidores, dispositivos de almacenamiento, redes de alta velocidad.</li> <li>Software: sistemas operativos, bases de datos, herramientas de an\u00e1lisis y visualizaci\u00f3n de datos.</li> </ul> <p>Estos son algunos ejemplos de infraestructuras para procesar el Big Data:</p> <ul> <li>Apache Hadoop: una de las soluciones m\u00e1s conocidas para analizar Big Data, que utiliza un marco de trabajo de c\u00f3digo abierto para almacenar y procesar grandes conjuntos de datos.</li> <li>Apache Spark: esta herramienta permite almacenar gran parte de los datos de procesamiento en la memoria y en el disco, lo que se traduce en una mayor rapidez.</li> <li>Bases de datos NoSQL: como Cassandra, son utilizadas para almacenar y gestionar grandes vol\u00famenes de datos no estructurados.</li> </ul> <p>La infraestructura para procesar el Big Data debe ser capaz de manejar grandes vol\u00famenes de datos y proporcionar herramientas para su an\u00e1lisis y visualizaci\u00f3n.</p>"},{"location":"BDA/Tema01/IntroduccionBigData/#16-bibliografia","title":"1.6. Bibliografia","text":"<ul> <li>Arquitectura Big Data</li> <li>Qu\u00e9 es Big Data</li> <li>Qu\u00e9 es Big Data y para que sirve</li> <li>Historia de Big Data</li> <li>Arqruitecturas Lamda y Kappa </li> </ul>"},{"location":"BDA/Tema01/Introducion_OLD/","title":"1. Introducci\u00f3n Big Data","text":""},{"location":"BDA/Tema01/Introducion_OLD/#11-big-data","title":"1.1. Big Data","text":"<p>Big Data es una colecci\u00f3n de conjuntos de datos que son lo suficientemente grandes y complejos como para hacer obsoleta la arquitectura tradicional de almacenamiento y procesamiento de datos.</p> <p>\u00bf Cuando considerar la utilizaci\u00f3n la arquitectura Big Data?</p> Escenarios <ul> <li>Los datos son demasiado grandes para que las tiendas de datos tradicionales los procesen.</li> <li>Transformaci\u00f3n y an\u00e1lisis de datos no estructurados.</li> <li>Necesidad de analizar datos en tiempo real con baja latencia.</li> </ul> <p>Tipos de cargas de trabajo</p> <p>Los tipos de cargas de trabajo que se pueden considerar incluyen:</p> <ul> <li>Procesamiento por lotes de datos.</li> <li>Procesamiento en tiempo real de datos en movimiento.</li> </ul> <p>Las 3 Vs del Big Data son Volumen, Velocidad y Variedad.</p> <ul> <li>El Volumen se refiere a la cantidad de datos</li> <li>La Velocidad se refiere a la velocidad a la que se generan y procesan los datos</li> <li>La Variedad se refiere a los diferentes tipos de datos disponibles.</li> </ul> <p>Big Data es importante en el mundo actual porque puede utilizarse para abordar problemas empresariales que antes eran insolubles, generar informaci\u00f3n valiosa, perfeccionar campa\u00f1as y t\u00e9cnicas de marketing, entrenar m\u00e1quinas, modelado predictivo y otras aplicaciones avanzadas de an\u00e1lisis, reducir costos, ahorrar tiempo, comprender mejor las condiciones del mercado, vencer a grandes competidores y retener a clientes leales.</p>"},{"location":"BDA/Tema01/Introducion_OLD/#12-historia","title":"1.2. Historia","text":"<p>El t\u00e9rmino \u2018Big Data\u2019 ha estado en uso desde principios de los a\u00f1os 90. Aunque no se sabe exactamente qui\u00e9n fue el primero en usar el t\u00e9rmino, la mayor\u00eda de las personas atribuyen a John R. Mashey (que en ese momento trabajaba en Silicon Graphics) por hacer popular el t\u00e9rmino.</p> <p></p>"},{"location":"BDA/Tema01/Introducion_OLD/#13-tecnologias","title":"1.3. Tecnolog\u00edas","text":"<p>Hay muchas tecnolog\u00edas populares de Big Data c\u00f3mo Hadoop, Spark y bases de datos NoSQL. Estas tecnolog\u00edas pueden compararse en funci\u00f3n de sus casos de uso y capacidades.</p> <p>Las tecnolog\u00edas de Big Data se pueden dividir en cuatro categor\u00edas principales:</p> <ul> <li>Almacenamiento de datos: Las tecnolog\u00edas de Big Data que se ocupan del almacenamiento de datos tienen la capacidad de recuperar, almacenar y gestionar grandes conjuntos de datos. Est\u00e1 compuesto por infraestructura que permite a los usuarios almacenar los datos para que sean f\u00e1cilmente accesibles. La mayor\u00eda de las plataformas de almacenamiento de datos son compatibles con otros programas. Dos herramientas com\u00fanmente utilizadas son Apache Hadoop y MongoDB.</li> <li>Miner\u00eda de datos: La miner\u00eda de datos extrae patrones y tendencias \u00fatiles a partir del conjunto de datos sin procesar. Tecnolog\u00edas c\u00f3mo Rapidminer y Presto pueden convertir datos estructurados y no estructurados en informaci\u00f3n utilizable.</li> <li>An\u00e1lisis de datos: El an\u00e1lisis de datos utiliza t\u00e9cnicas avanzadas c\u00f3mo el aprendizaje autom\u00e1tico y el an\u00e1lisis estad\u00edstico para obtener informaci\u00f3n a partir del conjunto de datos.</li> <li>Visualizaci\u00f3n de datos: La visualizaci\u00f3n de datos es importante para comprender el Big Data porque permite a los tomadores de decisiones ver anal\u00edticas presentadas visualmente para que puedan comprender conceptos dif\u00edciles o identificar nuevos patrones.</li> </ul> <p>Cada una de estas categor\u00edas est\u00e1 asociada con ciertas herramientas, y deber\u00e1s elegir la herramienta adecuada para tus necesidades empresariales dependiendo del tipo de tecnolog\u00eda de Big Data que se requiera.</p>"},{"location":"BDA/Tema01/Introducion_OLD/#14-aplicaciones","title":"1.4. Aplicaciones","text":"<p>Big Data se utiliza en diversas industrias c\u00f3mo: la salud, las finanzas, el comercio minorista, etc. Los beneficios del uso del Big Data incluyen:</p> <ul> <li>Una mejor toma de decisiones</li> <li>Un aumento de la eficiencia</li> <li>Capacidad para descubrir nuevos conocimientos</li> </ul> <p>Sin embargo, tambi\u00e9n hay desaf\u00edos asociados con el uso del Big Data c\u00f3mo gestionar grandes vol\u00famenes de datos y garantizar la privacidad de los datos.</p>"},{"location":"BDA/Tema01/Introducion_OLD/#15-big-data-y-aprendizaje-automatico","title":"1.5. Big Data y Aprendizaje Autom\u00e1tico","text":"<p>Big data y aprendizaje autom\u00e1tico son dos campos estrechamente relacionados y complementarios. * Big data se refiere a conjuntos de datos extremadamente grandes y complejos que son dif\u00edciles de procesar utilizando m\u00e9todos tradicionales. * El aprendizaje autom\u00e1tico, por otro lado, es una rama de la inteligencia artificial que se enfoca en desarrollar algoritmos que permitan a las m\u00e1quinas aprender de los datos y mejorar su rendimiento con el tiempo.</p> <p>El aprendizaje autom\u00e1tico aprovecha el big data para entrenar modelos m\u00e1s precisos y confiables. Cuanto m\u00e1s datos haya disponibles, m\u00e1s precisos y confiables ser\u00e1n los modelos del aprendizaje autom\u00e1tico. El aprendizaje autom\u00e1tico tiene aplicaciones amplias en el procesamiento y an\u00e1lisis del big data, c\u00f3mo la clasificaci\u00f3n y categorizaci\u00f3n autom\u00e1tica de datos, la detecci\u00f3n de anomal\u00edas y la predicci\u00f3n de resultados futuros.</p> <p>La combinaci\u00f3n de big data y aprendizaje autom\u00e1tico ofrece beneficios significativos. Permite descubrir informaci\u00f3n valiosa oculta en grandes vol\u00famenes de datos, mejorar la toma de decisiones basada en datos, automatizar tareas y optimizar procesos empresariales.</p>"},{"location":"BDA/Tema01/Introducion_OLD/#16-fuentes-u-origen-de-los-datos","title":"1.6. Fuentes u origen de los datos","text":"<p>Los datos en Big Data pueden ser clasificadas en tres tipos seg\u00fan su origen:</p> <ul> <li>Generados por m\u00e1quinas: procedentes de sensores (GPS, contadores\u2026), Web Log Data (redes, aplicaciones\u2026), procedentes de puntos de venta (c\u00f3digos de barras de un producto) y financieros (operaciones bancarias).</li> <li>Generados por personas: formularios, registros de contabilidad\u2026</li> <li>Datos externos: redes sociales, patentes, datos web, datos m\u00f3viles, etiquetas RFID (rastreo electr\u00f3nico) y c\u00f3digos de barras, datos de ubicaci\u00f3n, sensores de datos, entre otros.</li> </ul> <p>Seg\u00fan su estructura se pueden clasificar en tres tipos:</p> <ul> <li>Datos estructurados: son aquellos que se encuentran ordenados y organizados en una estructura predefinida, c\u00f3mo una tabla o una base de datos relacional. Estos datos son f\u00e1ciles de gestionar y analizar, ya que su estructura permite una mayor predictibilidad. Ejemplos de datos estructurados incluyen registros en tablas, ficheros XML asociados a un esquema, y facturas autogeneradas al realizar una compra.</li> <li>Datos semiestructurados: son aquellos que tienen cierta estructura, pero no est\u00e1n organizados en una estructura r\u00edgida c\u00f3mo los datos estructurados. Ejemplos de datos semiestructurados incluyen documentos JSON y XML sin esquema asociado.</li> <li>Datos no estructurados: son aquellos que no tienen una estructura predefinida y pueden ser dif\u00edciles de gestionar y analizar. Ejemplos de datos no estructurados incluyen publicaciones en redes sociales, v\u00eddeos, im\u00e1genes, y texto libre.</li> </ul> <p></p>"},{"location":"BDA/Tema01/Introducion_OLD/#17-infraestructura","title":"1.7. Infraestructura","text":"<p>Una infraestructura para Big Data debe facilitar la recopilaci\u00f3n, el almacenamiento y el an\u00e1lisis de grandes vol\u00famenes de datos, que pueden estar en diferentes formatos y gener\u00e1ndose en tiempo real. Para ello, se utilizan tecnolog\u00edas y servicios especiales que han sido creados espec\u00edficamente para dar soluci\u00f3n al procesamiento de estos enormes conjuntos de datos.</p> <p>Algunos de los principales elementos de hardware y software que integran una soluci\u00f3n arquitect\u00f3nica de Big Data son:</p> <ul> <li>Hardware: servidores, dispositivos de almacenamiento, redes de alta velocidad.</li> <li>Software: sistemas operativos, bases de datos, herramientas de an\u00e1lisis y visualizaci\u00f3n de datos.</li> </ul> <p>Estos son algunos ejemplos de infraestructuras para procesar el Big Data:</p> <ul> <li>Apache Hadoop: una de las soluciones m\u00e1s conocidas para analizar Big Data, que utiliza un marco de trabajo de c\u00f3digo abierto para almacenar y procesar grandes conjuntos de datos.</li> <li>Apache Spark: esta herramienta permite almacenar gran parte de los datos de procesamiento en la memoria y en el disco, lo que se traduce en una mayor rapidez.</li> <li>Bases de datos NoSQL: como Cassandra, son utilizadas para almacenar y gestionar grandes vol\u00famenes de datos no estructurados.</li> </ul> <p>La infraestructura para procesar el Big Data debe ser capaz de manejar grandes vol\u00famenes de datos y proporcionar herramientas para su an\u00e1lisis y visualizaci\u00f3n.</p>"},{"location":"BDA/Tema01/Introducion_OLD/#18-almacenamiento","title":"1.8. Almacenamiento","text":"<p>Hay muchas opciones disponibles para almacenar grandes vol\u00famenes de datos. * Los sistemas de archivos distribuidos, como Hadoop Distributed File System (HDFS) y Google File System (GFS), son una opci\u00f3n popular para almacenar grandes conjuntos de datos en m\u00faltiples servidores. * Los servicios de almacenamiento en la nube, como Amazon S3 y Microsoft Azure Blob Storage, tambi\u00e9n son opciones populares para almacenar datos en la nube.</p> <p>La gesti\u00f3n efectiva de los datos es esencial para garantizar su integridad y disponibilidad. Esto incluye: * La implementaci\u00f3n de medidas de seguridad adecuadas para proteger los datos contra el acceso no autorizado * La realizaci\u00f3n de copias de seguridad regulares para garantizar la recuperaci\u00f3n en caso de p\u00e9rdida de datos * La implementaci\u00f3n de pol\u00edticas y procedimientos para garantizar que los datos se manejen de manera responsable y \u00e9tica.</p>"},{"location":"BDA/Tema01/Introducion_OLD/#19-procesamiento","title":"1.9. Procesamiento","text":"<p>Dos opciones de procesamiento:</p> <ul> <li> <p>En tiempo real</p> <ul> <li>El procesamiento en tiempo real del Big Data implica analizar datos a medida que se generan para tomar decisiones o desencadenar acciones en tiempo real.</li> <li>Por ejemplo, el procesamiento en tiempo real puede utilizarse para monitorear feeds sociales en busca de menciones de una marca o producto en particular.</li> </ul> </li> <li> <p>Por lotes o en Batch</p> <ul> <li>El procesamiento por lotes implica analizar grandes vol\u00famenes de datos a la vez en lugar de en tiempo real.</li> <li>Este enfoque puede ser \u00fatil cuando se trata con datos hist\u00f3ricos o cuando se realizan an\u00e1lisis complejos que requieren m\u00e1s tiempo.</li> </ul> </li> </ul>"},{"location":"BDA/Tema01/Introducion_OLD/#110-analisis-con-big-data","title":"1.10. An\u00e1lisis con Big Data","text":"<p>Tipos de an\u00e1lisis de big data:</p> <ul> <li>Predictivo<ul> <li>El an\u00e1lisis predictivo implica utilizar t\u00e9cnicas estad\u00edsticas para hacer predicciones sobre eventos futuros bas\u00e1ndose en datos hist\u00f3ricos. Este enfoque puede aplicarse para generar conocimientos sobre tendencias o comportamientos futuros.</li> </ul> </li> <li>De diagn\u00f3stico<ul> <li>El an\u00e1lisis de diagn\u00f3stico utiliza algoritmos para descubrir patrones y relaciones dentro de grandes conjuntos de datos. Este enfoque puede aplicarse para extraer informaci\u00f3n \u00fatil de grandes vol\u00famenes de datos no estructurados o semiestructurados.</li> </ul> </li> <li>Descriptivo<ul> <li>El an\u00e1lisis descriptivo es un m\u00e9todo de an\u00e1lisis de datos que se utiliza para resumir y describir sus caracter\u00edsticas principales. Se utiliza com\u00fanmente para proporcionar una visi\u00f3n general de los datos y para identificar patrones y tendencias. </li> <li>En el contexto de Big Data, el an\u00e1lisis descriptivo puede utilizarse para obtener informaci\u00f3n a partir de conjuntos de datos grandes y complejos. Por ejemplo, una empresa podr\u00eda utilizar el an\u00e1lisis descriptivo para entender la demograf\u00eda de su base de clientes o para identificar patrones en el comportamiento de los clientes.</li> </ul> </li> <li>Prescriptivo con Big Data<ul> <li>El an\u00e1lisis prescriptivo es un tipo de an\u00e1lisis de datos que utiliza t\u00e9cnicas avanzadas de an\u00e1lisis, como el aprendizaje autom\u00e1tico y los algoritmos de optimizaci\u00f3n, para sugerir acciones que se pueden tomar para lograr un resultado deseado.</li> <li>En el contexto de Big Data, el an\u00e1lisis prescriptivo puede utilizarse para tomar decisiones basadas en datos a partir de la informaci\u00f3n obtenida a partir de conjuntos de datos grandes y complejos. Por ejemplo, una empresa podr\u00eda utilizar el an\u00e1lisis prescriptivo para optimizar su cadena de suministro o para determinar la mejor estrategia de precios para sus productos.</li> </ul> </li> </ul>"},{"location":"BDA/Tema01/Introducion_OLD/#111-visualizacion-de-datos","title":"1.11. Visualizaci\u00f3n de datos","text":"<p>La visualizaci\u00f3n de datos es la presentaci\u00f3n de datos en formato ilustrado o gr\u00e1fico. Permite a los tomadores de decisiones ver la anal\u00edtica presentada de forma visual, de modo que puedan captar conceptos dif\u00edciles o identificar nuevos patrones. Con la visualizaci\u00f3n interactiva, se puede llevar el concepto un paso adelante utilizando tecnolog\u00eda para profundizar en diagramas y gr\u00e1ficas para observar mayor detalle, cambiando de forma interactiva qu\u00e9 datos se ven y c\u00f3mo se procesan.</p> <p>Hay muchas herramientas disponibles para la visualizaci\u00f3n de Big Data. Algunas de las herramientas m\u00e1s populares son Tableau, Infogram, ChartBlocks, Datawrapper y Ploty. Estas herramientas permiten crear tablas, gr\u00e1ficos, mapas y otros tipos de visualizaciones para ayudar a comprender y comunicar los datos.</p> <p>La visualizaci\u00f3n de datos es importante porque permite transmitir conceptos de manera universal y r\u00e1pida. Tambi\u00e9n puede ayudar a identificar \u00e1reas que necesitan atenci\u00f3n o mejoras y esclarecer qu\u00e9 factores influencian el comportamiento de los clientes.</p>"},{"location":"BDA/Tema02/Pruebas/","title":"Pruebas","text":"Pulsa para ver Esta es la soluci\u00f3n:  <pre><code>CREATE DATABASE menagerie;\nCREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20), species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);\n</code></pre> <p>Mi Documento</p> Escenarios <ul> <li>Los datos son demasiado grandes para que las tiendas de datos tradicionales los procesen.</li> <li>Transformaci\u00f3n y an\u00e1lisis de datos no estructurados.</li> <li>Necesidad de analizar datos en tiempo real con baja latencia.</li> </ul> <pre><code>select * from luis\nwhere nombre=\"luis\"from juan\n</code></pre>"},{"location":"BDA/Tema02/Pruebas/#seccion-1","title":"Secci\u00f3n 1","text":"<p>\u00a1Bienvenido a mi documento de ejemplo!</p> <p>Nota Importante</p> <p>Esta es una nota importante que los lectores pueden ocultar o mostrar.</p> <p>Consejo</p> <p>Aqu\u00ed tienes un consejo \u00fatil para los lectores.</p>"},{"location":"BDA/Tema02/Pruebas/#seccion-2","title":"Secci\u00f3n 2","text":"<p>En esta secci\u00f3n, vamos a mostrar c\u00f3mo usar bloques colapsados anidados.</p> Advertencia <p>Esta es una advertencia que se puede colapsar</p> <p>Peligro</p> <p>\u00a1Cuidado! Esto es peligroso.</p> <p>M\u00e1s Informaci\u00f3n</p> <p>Aqu\u00ed hay informaci\u00f3n adicional.</p>"},{"location":"BDA/Tema02/Pruebas/#seccion-3","title":"Secci\u00f3n 3","text":"<p>Continuemos con m\u00e1s contenido.</p> <p>Consejo</p> <p>Otra sugerencia \u00fatil para los lectores.</p>"},{"location":"BDA/Tema02/Pruebas/#seccion-4","title":"Secci\u00f3n 4","text":"<p>Finalizamos el documento.</p> <p>Nota de Cierre</p> <p>Esta es una nota de cierre.</p>"},{"location":"BDA/Tema02/RepasoSQL/","title":"2. SQL","text":""},{"location":"BDA/Tema02/RepasoSQL/#21-comandos","title":"2.1. Comandos","text":"<p>Existen tres tipos de comandos SQL:</p> <ul> <li>Los DDL (Data Definition Language) que permiten crear y definir nuevas bases de datos, campos e \u00edndices.</li> <li>Los DML (Data Manipulation Language) que permiten generar consultas para ordenar, filtrar y extraer datos de la base de datos.</li> <li>Los DCL (Data Control Language) que se encargan de definir los permisos sobre los datos.</li> </ul> <p>Revisaremos los dos primeros.</p>"},{"location":"BDA/Tema02/RepasoSQL/#22-ddl","title":"2.2. DDL","text":""},{"location":"BDA/Tema02/RepasoSQL/#221-create","title":"2.2.1. CREATE","text":"<p>Este comando crea un objeto dentro del gestor de base de datos. Puede ser una base de datos, tabla, \u00edndice, procedimiento almacenado o vista. <pre><code>CREATE DATABASE menagerie;\nCREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20), species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);&lt;details&gt;\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#222-alter","title":"2.2.2. ALTER","text":"<p>Este comando permite modificar la estructura de un objeto. Se pueden agregar/quitar campos a una tabla, modificar el tipo de un campo, agregar/quitar \u00edndices a una tabla, modificar un trigger, etc. <pre><code>ALTER TABLE 'NOMBRE_TABLA' ADD nuevo_campo INT;\nALTER TABLE 'NOMBRE_TABLA' RENAME COLUMN nombre_antiguo TO nombre_nuevo;\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#223-drop","title":"2.2.3 DROP","text":"<p>Este comando elimina un objeto de la base de datos. Se puede combinar con la sentencia ALTER. <pre><code>DROP TABLE 'NOMBRE_TABLA';\nDROP DATABASE 'BASEDATOS';\nALTER TABLE 'NOMBRE_TABLA' DROP COLUMN NOMBRE_COLUMNA;\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#224-truncate","title":"2.2.4. TRUNCATE","text":"<p>Este comando borra todo el contenido de una tabla, pero no borra la tabla. <pre><code>TRUNCATE TABLE 'NOMBRE_TABLA';\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#23-dml","title":"2.3. DML","text":""},{"location":"BDA/Tema02/RepasoSQL/#231-insert","title":"2.3.1. INSERT","text":"<p>Una sentencia INSERT de SQL agrega uno o m\u00e1s registros a una (y s\u00f3lo una) tabla en una base de datos relacional. Forma b\u00e1sica: <pre><code>INSERT INTO 'tabla' ('columna1', ['columna2,...']) VALUES ('valor1', ['valor2,...'])\n</code></pre> Ejemplo: <pre><code>INSERT INTO agenda_telefonica VALUES ('Jhonny Aguiar', 080473968);\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#232-update","title":"2.3.2 UPDATE","text":"<p>Una sentencia UPDATE de SQL es utilizada para modificar los valores de un conjunto de registros existentes en una tabla. Ejemplo: <pre><code>UPDATE mi_tabla SET campo1 = 'nuevo valor campo1' WHERE campo2 = 'N';\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#233-delete","title":"2.3.3. DELETE","text":"<p>Una sentencia DELETE de SQL borra uno o m\u00e1s registros existentes en una tabla.</p> <p>Forma b\u00e1sica: <pre><code>DELETE FROM 'tabla' WHERE 'columna1' = 'valor1'\n</code></pre> Ejemplo: <pre><code>DELETE FROM My_table WHERE field2 = 'N';\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#24-clausulas","title":"2.4. Cl\u00e1usulas","text":"<p>Las cl\u00e1usulas son condiciones de modificaci\u00f3n utilizadas para definir los datos que desea seleccionar o manipular.</p> <ul> <li>FROM: Utilizada para especificar la tabla de la cual se van a seleccionar los registros.</li> <li>GROUP BY: Utilizada para separar los registros seleccionados en grupos espec\u00edficos.</li> <li>HAVING: Utilizada para expresar condici\u00f3n que debe satisfacer cada grupo.</li> <li>ORDER BY: Utilizada para ordenar los registros seleccionados de acuerdo con un orden espec\u00edfico.</li> <li>WHERE: Utilizada para determinar los registros seleccionados en la cl\u00e1usula FROM.</li> </ul> <pre><code>SELECT campos FROM tabla\nWHERE campo=X\nORDER BY campo2\nGROUP BY campos3 HAVING suma&gt;3\n</code></pre>"},{"location":"BDA/Tema02/RepasoSQL/#25-operadores","title":"2.5. Operadores","text":"<ul> <li>Operadores L\u00f3gicos: AND, OR y NOT</li> <li>Operadores de comparaci\u00f3n: &lt;, &gt;, &lt;&gt;, &lt;=, &gt;=, BETWEEN, LIKE, In</li> </ul>"},{"location":"BDA/Tema02/RepasoSQL/#26-funciones-de-agregado","title":"2.6. Funciones de agregado","text":"<p>Las funciones de agregado se usan dentro de una cl\u00e1usula SELECT en grupos de registros para devolver un \u00fanico valor que se aplica a un grupo de registros. Los campos que aparecen en el SELECT que no son funciones de agregado deben aparecer en la clausula GROUP BY.</p> <p>Funciones:</p> <ul> <li>AVG</li> <li>COUNT</li> <li>SUM</li> <li>MAX</li> <li>MIN</li> </ul> <pre><code>SELECT Dpto, AVG(Sueldo)\nFROM Empleados\nGROUP BY Dpto;\n</code></pre>"},{"location":"BDA/Tema02/RepasoSQL/#27-consultas","title":"2.7. Consultas","text":"<p>Consultas de selecci\u00f3n se utilizan para indicar al motor de datos que devuelva informaci\u00f3n de las bases de datos, esta informaci\u00f3n es devuelta en forma de conjunto de registros. Este conjunto de registros es modificable. <pre><code>SELECT Campos FROM Tabla;\nSELECT Nombre, Telefono FROM Clientes;\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#271-consultas-de-seleccion-basicas","title":"2.7.1. Consultas de selecci\u00f3n b\u00e1sicas","text":"<p>Ordenar los registros con ORDER BY: <pre><code>SELECT CodigoPostal, Nombre, Telefono FROM Clientes ORDER BY CodigoPostal DESC , Nombre ASC;\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#272-consultas-con-predicado","title":"2.7.2. Consultas con predicado","text":"<p>TOP: Devuelve un cierto n\u00famero de registros que entran en un rango especificado por una cl\u00e1usula ORDER BY. <pre><code>SELECT TOP 25 Nombre, Apellido FROM Estudiantes ORDER BY Nota DESC;\n</code></pre></p> <p>DISTINCT: Omite los registros que contienen datos duplicados en los campos seleccionados. Para que los valores de cada campo listado en la instrucci\u00f3n SELECT se incluyan en la consulta deben ser \u00fanicos. <pre><code>SELECT DISTINCT Apellido FROM Empleados;\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#28-criterios-de-seleccion","title":"2.8. Criterios de selecci\u00f3n","text":"<p>Operadores l\u00f3gicos: <pre><code>SELECT * FROM Empleados WHERE Edad &gt; 25 AND Edad &lt; 50;\n\nSELECT * FROM Empleados WHERE (Edad &gt; 25 AND Edad &lt; 50) OR Sueldo = 100;\n\nSELECT * FROM Empleados WHERE NOT Estado = 'Soltero';\n\nSELECT * FROM Empleados WHERE (Sueldo &gt; 100 AND Sueldo &lt; 500) OR (Provincia = 'Madrid' AND Estado = 'Casado');\n</code></pre></p> <p>Operador BETWEEN: <pre><code>SELECT * FROM Pedidos WHERE CodPostal Between 28000 And 28999;\n</code></pre></p> <p>Operador LIKE: Se utiliza para comparar una expresi\u00f3n de cadena con una expresi\u00f3n SQL. <pre><code>SELECT * FROM personas WHERE nombre LIKE 'AN%'\n</code></pre> Operador IN: <pre><code>SELECT * FROM Pedidos WHERE Provincia In ('Madrid', 'Barcelona', 'Sevilla');\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#29-agregacion","title":"2.9. Agregaci\u00f3n","text":"<p>AVG: <pre><code>SELECT Avg(Gastos) AS Promedio FROM Pedidos WHERE Gastos &gt; 100;\n</code></pre> MAX, MIN: <pre><code>SELECT Min(Gastos) AS ElMin FROM Pedidos WHERE Pais = 'Costa Rica';\n\nSELECT Max(Gastos) AS ElMax FROM Pedidos WHERE Pais = 'Costa Rica';\n</code></pre> SUM: <pre><code>SELECT Sum(PrecioUnidad * Cantidad) AS Total FROM DetallePedido;\n</code></pre></p> <p>GROUP BY: <pre><code>SELECT Id_Familia, Sum(Stock) FROM Productos GROUP BY Id_Familia;\n</code></pre> HAVING: <pre><code>SELECT Id_Familia Sum(Stock) FROM Productos GROUP BY Id_Familia HAVING Sum(Stock) &gt; 100 AND NombreProducto Like 'BOS%';\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#210-claves","title":"2.10. Claves","text":"<p>Claves Primarias y Ajenas: <pre><code>CREATE TABLE Orders ( OrderID int NOT NULL, OrderNumber int NOT NULL, PersonID int, PRIMARY KEY (OrderID), FOREIGN KEY (PersonID) REFERENCES Persons(PersonID)\n)\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#211-consultas-multitabla","title":"2.11. Consultas multitabla","text":"<p>Trabajaremos con estas tablas:</p> <p>Tabla Clientes:</p> cid nombre telefono 1 jose 111 2 manuel 222 3 maria 333 4 jesus 4444 <p>Tabla Acciones:</p> aid cid action cantidad 1 2 REDHAT 10 2 2 NOVEL 20 3 4 SUN 30 4 5 FORD 100 <p>JOIN: </p> <p>La sentencia SQL JOIN se utiliza para relacionar varias tablas. Nos permitir\u00e1 obtener un listado de los campos que tienen coincidencias en ambas tablas. <pre><code>SELECT nombre, telefono, accion, cantidad FROM Clientes JOIN Acciones ON Clientes.cid=Acciones.cid;\n</code></pre></p> nombre telefono action cantidad maria 222 REDHAT 10 jesus 4444 NOVEL 20 jesus 4444 SUN 30 <p>LEFT JOIN: </p> <p>La sentencia LEFT JOIN nos dar\u00e1 el resultado anterior m\u00e1s los campos de la tabla de la izquierda del JOIN que no tienen coincidencias en la tabla de la derecha. <pre><code>SELECT nombre, telefono, accion, cantidad FROM Clientes LEFT JOIN Acciones ON Clientes.cid=Acciones.cid;\n</code></pre></p> nombre telefono action cantidad jose 111 NULL NULL maria 222 REDHAT 10 manuel 333 NULL NULL jesus 4444 NOVEL 20 jesus 4444 SUN 30 <p>RIGHT JOIN: </p> <p>Id\u00e9ntico funcionamiento que en el caso anterior pero con la tabla que se incluye en la consulta a la derecha del JOIN. <pre><code>SELECT nombre, telefono, accion, cantidad FROM Clientes RIGHT JOIN Acciones ON Clientes.cid=Acciones.cid;\n</code></pre></p> nombre telefono action cantidad maria 222 REDHAT 10 jesus 4444 NOVEL 20 jesus 4444 SUN 30 NULL NULL FORD 100 <p>UNION y UNION ALL: </p> <p>Podemos combinar el resultado de varias sentencias con UNION o UNION ALL. UNION no nos muestra los resultados duplicados, pero UNION ALL si los muestra. <pre><code>SELECT nombre, telefono, accion, cantidad FROM Clientes LEFT JOIN Acciones ON Clientes.cid=Acciones.cid WHERE accion IS NULL UNION SELECT nombre, telefono, accion, cantidad\nFROM Clientes RIGHT JOIN Acciones ON Clientes.cid=Acciones.cid WHERE nombre IS NULL;1\n</code></pre></p> nombre telefono action cantidad jose 111 NULL NULL manuel 333 NULL NULL NULL NULL FORD 100 <p>RESUMEN</p> <p></p>"},{"location":"BDA/Tema02/RepasoSQL/#212-vistas","title":"2.12. Vistas","text":"<p>La cl\u00e1usula CREATE VIEW permite la creaci\u00f3n de vistas. La cl\u00e1usula asigna un nombre a la vista y permite especificar la consulta que la define. <pre><code>CREATE VIEW ClientesConAcciones AS SELECT nombre, telefono, accion, cantidad FROM Clientes JOIN Acciones ON Clientes.cid=Acciones.cid;\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#213-funciones-miscelanea","title":"2.13. Funciones Miscel\u00e1nea","text":"<p>CONVERT: </p> <p>Convierte el valor de salida en un tipo de datos espec\u00edfico. <pre><code>CONVERT(valor, tipo)\n</code></pre></p> <p>ISNULL: </p> <p>Por lo general, si no especifica el valor sin valor para su atributo, es probable que termine con algunos valores nulos en la columna. Pero puede lidiar con ellos f\u00e1cilmente usando la funci\u00f3n isnull(). <pre><code>ISNULL(expresi\u00f3n)\n</code></pre></p> <p>IF: </p> <p>Finalmente, la funci\u00f3n m\u00e1s importante que usar\u00e1 en SQL es la funci\u00f3n if (). Le permite definir la condicionalidad if que se encuentra en cualquier lenguaje de programaci\u00f3n. Tiene una sintaxis simple: <pre><code>IF(expresi\u00f3n, valor_si_verdadero, valor_si_falso)\n</code></pre></p>"},{"location":"BDA/Tema02/RepasoSQL/#214-datos-para-practicar","title":"2.14. Datos para practicar","text":"<p>Aqui tienes los comandos SQL para crear unas tablas con datos para pruebas</p> <pre><code>CREATE TABLE Alumnos (\nAlumnoID INT PRIMARY KEY,\nNombre VARCHAR(50),\nEdad INT,\nProfesorID INT\n);\n</code></pre> <p><pre><code>CREATE TABLE Profesores (\nProfesorID INT PRIMARY KEY,\nNombre VARCHAR(50),\nMateria VARCHAR(50)\n);\n</code></pre> <pre><code>INSERT INTO Alumnos (AlumnoID, Nombre, Edad, ProfesorID)\nVALUES\n(1, 'Juan P\u00e9rez', 18, 101),\n(2, 'Mar\u00eda L\u00f3pez', 19, 102),\n(3, 'Pedro P\u00e9rez', 17, 101),\n(4, 'Luis Garcia', 19, 102),\n(5, 'Maria Martinez', 17, 103),\n(6, 'Eva Gonzaleza', 19, 104);\n\nINSERT INTO Profesores (ProfesorID, Nombre, Materia)\nVALUES\n(101, 'Profesor Smith', 'Matem\u00e1ticas'),\n(102, 'Profesora Johnson', 'Historia'),\n(103, 'Profesor Martinez', 'Lengua'),\n(104, 'Profesora Eva', 'Ingles');\n</code></pre></p>"},{"location":"BDA/Tema03/NoSQL/","title":"3. NoSQL","text":""},{"location":"BDA/Tema03/NoSQL/#31-bases-de-datos-no-sql","title":"3.1. Bases de datos No SQL","text":""},{"location":"BDA/Tema03/NoSQL/#311-que-son-las-bases-de-datos-nosql","title":"3.1.1. \u00bfQu\u00e9 son las bases de datos NoSQL?","text":"<p>Las bases de datos NoSQL (NoSQL significa \"Not Only SQL\" o \"No Solo SQL\") son sistemas de gesti\u00f3n de bases de datos dise\u00f1ados para manejar tipos de datos y escenarios de aplicaci\u00f3n que no se ajustan bien a las bases de datos relacionales tradicionales. </p> <p>A diferencia de las bases de datos SQL, que utilizan un esquema fijo y tablas para almacenar datos, las bases de datos NoSQL utilizan diferentes modelos de datos y estructuras de almacenamiento flexibles.</p>"},{"location":"BDA/Tema03/NoSQL/#312-caracteristicas-de-las-bases-de-datos-nosql","title":"3.1.2. Caracter\u00edsticas de las bases de datos NoSQL:","text":"<ul> <li> <p>Esquema flexible: NoSQL permite almacenar datos sin necesidad de un esquema predefinido.</p> </li> <li> <p>Escalabilidad horizontal: Las bases de datos NoSQL est\u00e1n dise\u00f1adas para escalar horizontalmente.</p> </li> <li> <p>Modelos de datos variados: Existen varios tipos de bases de datos NoSQL, incluyendo bases de datos de documentos, bases de datos de columnas, bases de datos clave-valor y bases de datos de grafos.</p> </li> <li> <p>Alta disponibilidad: Las bases de datos NoSQL suelen garantizar la disponibilidad continua de los datos.</p> </li> </ul>"},{"location":"BDA/Tema03/NoSQL/#313-ventajas-de-las-bases-de-datos-nosql","title":"3.1.3. Ventajas de las bases de datos NoSQL:","text":"<ul> <li> <p>Escalabilidad: Son ideales para aplicaciones web y m\u00f3viles que requieren escalabilidad r\u00e1pida y eficiente.</p> </li> <li> <p>Flexibilidad: Pueden manejar datos no estructurados o semiestructurados.</p> </li> <li> <p>Rendimiento: Ofrecen un rendimiento m\u00e1s r\u00e1pido para ciertos tipos de consultas.</p> </li> </ul>"},{"location":"BDA/Tema03/NoSQL/#314-desventajas-de-las-bases-de-datos-nosql","title":"3.1.4. Desventajas de las bases de datos NoSQL:","text":"<ul> <li> <p>Falta de est\u00e1ndares: La diversidad de modelos y sistemas NoSQL dificulta la elecci\u00f3n y la migraci\u00f3n entre sistemas.</p> </li> <li> <p>Menos soporte para consultas complejas: No son ideales para aplicaciones que requieren operaciones complejas de tipo JOIN y agregaci\u00f3n.</p> </li> </ul>"},{"location":"BDA/Tema03/NoSQL/#32-tipos-de-bases-de-datos-nosql","title":"3.2. Tipos de bases de datos NoSQL:","text":""},{"location":"BDA/Tema03/NoSQL/#321-bases-de-datos-de-documentos","title":"3.2.1. Bases de datos de documentos:","text":"<ul> <li>Almacenan datos en formato de documentos semiestructurados, como JSON o XML.</li> <li>Caracter\u00edsticas:<ul> <li>Una clave \u00fanica para cada registro que normalmente suele ser un documento con una estructura simple como JSON o XML. </li> <li>Se apoya en la utilizaci\u00f3n de documentos para almacenar informaci\u00f3n.</li> <li>Los documentos se agrupan en colecciones.</li> <li>Modelado flexible, recomendado para aplicaciones web, m\u00f3viles o rrss que var\u00edan constantemente.</li> <li>Escritura r\u00e1pida y mayor rendimiento.</li> </ul> </li> </ul> <ul> <li>Ejemplos:<ul> <li>MongoDB</li> <li>Couchbase</li> </ul> </li> </ul>"},{"location":"BDA/Tema03/NoSQL/#322-bases-de-datos-de-clave-valor","title":"3.2.2. Bases de datos de clave-valor","text":"<ul> <li>Almacenan datos com\u00f3 pares clave y valor</li> <li>Caracter\u00edsticas:<ul> <li>En este tipo de modelos cada elemento tiene asociada una clave \u00fanica</li> <li>Tiene asociada una clave \u00fanica lo que permite un acceso muy r\u00e1pido.</li> <li>Su objetivo es la escalabilidad y la disponibilidad.</li> <li>Operaciones b\u00e1sicas get, put, delete.</li> <li>Recomendado all\u00ed donde es necesario un acceso muy r\u00e1pido en un volumen inmenso de datos.<ul> <li>Sesiones</li> <li>E-shopping</li> </ul> </li> <li>No existe un est\u00e1ndar para el manejo de datos.</li> <li>Un \u00fanico m\u00e9todo de acceso.</li> </ul> </li> </ul> <ul> <li>Ejemplos:<ul> <li>Apache Cassandra</li> <li>HBase</li> </ul> </li> </ul>"},{"location":"BDA/Tema03/NoSQL/#323-bases-de-datos-columnas","title":"3.2.3. Bases de datos columnas","text":"<ul> <li>Almacenan datos en columnas en lugar de filas.</li> <li> <p>Caracter\u00edsticas</p> <ul> <li>Cada entrada genera una columna</li> <li>Los datos est\u00e1n dispuestos uno debajo del otro</li> <li>Gira la BBDD orientada a filas   </li> <li>En el disco duro los datos se muestran de manera unidimensional:<ul> <li>1,MongoDB,Documental,2,Cassandra,Key-value..</li> <li>1,2,3;MongoDB,Cassandra,Redshift\u2026</li> </ul> </li> <li>Aconsejado para evaluaci\u00f3n en BigData</li> <li>Desaconsejado en aplicaciones transaccionales</li> </ul> </li> <li> <p>Ejemplos:</p> <ul> <li>Redis</li> <li>Riak</li> </ul> </li> </ul>"},{"location":"BDA/Tema03/NoSQL/#324-bases-de-datos-de-grafos","title":"3.2.4. Bases de datos de grafos","text":"<ul> <li>Almacenan datos como nodos y relaciones.</li> <li> <p>Caracter\u00edsticas.</p> <ul> <li>Representan la informaci\u00f3n con grafos:<ul> <li>Nodos: propiedades de los datos.</li> <li>Aristas: relaciones entre los objetos.</li> </ul> </li> <li>Utilizan algoritmos especiales para realizar las b\u00fasquedas:<ul> <li>B\u00fasqueda en profundidad: el siguiente nodo m\u00e1s profundo.</li> <li>B\u00fasqueda en anchura: va movi\u00e9ndose entre los niveles.</li> </ul> </li> <li>Resultados en tiempo real.</li> <li>Estructuras flexibles y \u00e1giles</li> <li>Dif\u00edcil de escalar </li> </ul> </li> <li> <p>Ejemplos:</p> <ul> <li>Neo4j</li> <li>Amazon Neptune</li> </ul> </li> </ul> <p>Recuerda</p> <p>Cada tipo de base de datos NoSQL tiene sus propias caracter\u00edsticas y casos de uso espec\u00edficos. La elecci\u00f3n depender\u00e1 de las necesidades de tu proyecto.</p>"},{"location":"BDA/Tema03/NoSQL/#33-dynamodb","title":"3.3. DynamoDB","text":"<p>Amazon DynamoDB es un servicio de base de datos NoSQL administrado proporcionado por Amazon Web Services (AWS). Es un tipo de base de datos NoSQL que se ajusta a la categor\u00eda de bases de datos de clave-valor y de documentos. </p>"},{"location":"BDA/Tema03/NoSQL/#331-caracteristicas","title":"3.3.1. Caracter\u00edsticas","text":"<ul> <li> <p>Modelo de datos de clave-valor:</p> <ul> <li>DynamoDB almacena datos en pares de clave-valor, donde cada elemento en la base de datos tiene una clave \u00fanica que se utiliza para acceder a los datos.</li> <li>Las claves son sensibles a may\u00fasculas y min\u00fasculas y se utilizan para buscar y recuperar datos.</li> </ul> </li> <li> <p>Soporte para documentos y atributos anidados:</p> <ul> <li>Aunque DynamoDB utiliza un modelo de clave-valor, admite atributos anidados y permite almacenar datos complejos, lo que lo hace adecuado para aplicaciones que requieren estructuras de datos m\u00e1s complejas.</li> </ul> </li> <li> <p>Caracter\u00edsticas de seguridad y control de acceso:</p> <ul> <li>DynamoDB ofrece opciones de seguridad y control de acceso para proteger tus datos, incluyendo la integraci\u00f3n con Identity and Access Management (IAM) de AWS.</li> </ul> </li> <li> <p>Totalmente administrado:</p> <ul> <li>Como un servicio totalmente administrado, AWS se encarga de tareas como la implementaci\u00f3n, la escalabilidad, la gesti\u00f3n de r\u00e9plicas y la copia de seguridad de datos.</li> </ul> </li> </ul>"},{"location":"BDA/Tema03/NoSQL/#332-estructura-de-la-informacion-en-dynamodb","title":"3.3.2. Estructura de la informaci\u00f3n en DynamoDB","text":"<p>Tablas: En DynamoDB, los datos se organizan en tablas. Cada tabla puede considerarse como un conjunto de elementos relacionados. Por ejemplo, si est\u00e1s construyendo una aplicaci\u00f3n de comercio electr\u00f3nico, puedes tener una tabla para productos, una para pedidos, y otra para usuarios. Cada tabla es independiente y puede tener su propio esquema.</p> <p>Elementos (o Items): Los elementos son las unidades b\u00e1sicas de datos en DynamoDB y se asemejan a las filas en una base de datos relacional. Cada elemento se almacena como un conjunto de atributos (columnas). No es necesario que todos los elementos en una tabla tengan el mismo conjunto de atributos, lo que le da una gran flexibilidad. Por ejemplo, en una tabla de productos, un elemento podr\u00eda tener atributos como \"nombre\", \"precio\", \"descripci\u00f3n\", mientras que otro elemento podr\u00eda tener \"nombre\", \"precio\" y \"disponibilidad\".</p> <p>Clave Primaria: Cada elemento en DynamoDB debe tener una clave primaria que consiste en uno o dos componentes: clave de partici\u00f3n y opcionalmente una clave de ordenaci\u00f3n (sort key). La clave de partici\u00f3n se utiliza para distribuir los elementos a trav\u00e9s de m\u00faltiples particiones y garantizar una distribuci\u00f3n equitativa de la carga. La clave de ordenaci\u00f3n permite ordenar los elementos dentro de una partici\u00f3n. Esto es \u00fatil para realizar consultas espec\u00edficas en un rango de claves.</p> <p>La estructura de las tablas en DynamoDB es flexible y puede cambiar con el tiempo a medida que evolucionan los requisitos de tu aplicaci\u00f3n. Puedes agregar o eliminar atributos de los elementos sin afectar a los elementos existentes en la tabla.</p> <p>Ejemplo</p> <p>Tabla: Usuarios</p> <ul> <li>Clave de Partici\u00f3n (Primary Key): ID del Usuario</li> <li>Atributos:<ul> <li>Nombre</li> <li>Email</li> <li>Edad</li> <li>Direcci\u00f3n</li> </ul> </li> </ul> <p>En esta tabla, \"ID del Usuario\" es la clave de partici\u00f3n y se usa para distribuir los elementos. Los atributos son las columnas que almacenan informaci\u00f3n sobre cada usuario. Puedes realizar consultas para buscar usuarios por su ID, y los atributos te permiten almacenar informaci\u00f3n adicional sobre cada usuario.</p> <p>Recuerda</p> <p>DynamoDB no requiere un esquema fijo, por lo que puedes adaptar la estructura de tus tablas y elementos seg\u00fan las necesidades de tu aplicaci\u00f3n a medida que evoluciona con el tiempo.</p>"},{"location":"BDA/Tema03/NoSQL/#333-partiql","title":"3.3.3. PartiQL","text":"<p>PartiQL es un lenguaje de consulta que se puede utilizar para interactuar con las tablas de DynamoDB. Ejemplos:</p> <p><pre><code>INSERT INTO \"Alumnos\" VALUE {  'Id_Alumno' : 1,\n'Nombre' : 'Luis Garcia',\n'Edad' : 30,\n'Curso' : 'Primero'\n}\n</code></pre> <pre><code>INSERT INTO \"Alumnos\" VALUE {  'Id_Alumno' : 2,\n'Nombre' : 'Jose Perez',\n'Edad' : 23,\n'Curso' : 'Primero',\n'Sip' : 'A12345'\n}\n</code></pre></p> <pre><code>SELECT Id_Alumno, Nombre FROM \"Alumnos\" WHERE Id_Alumno = 1\n</code></pre> <p>Documentaci\u00f3n </p>"},{"location":"BDA/Tema04/MongoDB/","title":"3. MongoDB","text":""},{"location":"BDA/Tema04/MongoDB/#31-conceptos-basicos","title":"3.1. Conceptos B\u00e1sicos","text":"<p>Los elementos de MongoDB son:</p> <ul> <li>Bases de Datos: Act\u00faa cada una como un contenedor de alto nivel</li> <li>Colecciones: Una base de datos tendr\u00e1 0 o m\u00e1s colecciones. Una colecci\u00f3n es muy similar a lo que entendemos como tabla dentro de un SGDB.</li> <li>Documentos: Las colecciones contiene 0 o m\u00e1s documentos, por lo que es similar a una fila o registro de un RDMS.</li> </ul> <p></p>"},{"location":"BDA/Tema04/MongoDB/#311-documentos","title":"3.1.1. Documentos","text":"<p>El coraz\u00f3n de MongoDB es el documento, un conjunto ordenado de claves con valores asociados. Su representaci\u00f3n como hemos nombrado en el tema anterior es en JSON, un formato muy intuitivo y que no pensamos que requiera mayor explicaci\u00f3n. Este podr\u00eda ser un ejemplo sencillo de un documento que guarda el nombre, apellidos y dedad de una persona. A la izquierda de los dos puntos el nombre del campo y a la derecha el valor.</p> <pre><code>  {\nnombre:\"Jose Antonio\",\napellidos:\"Guillem Benedito\",\nedad:35\n}\n</code></pre> <p>Las claves de los documentos:</p> <ul> <li>No pueden ser nulas.</li> <li>No pueden contener los caracteres . (punto) y $ (d\u00f3lar).</li> <li>Puede contener cualquiera de los dem\u00e1s caracteres UTF-8 existentes.</li> <li>Son case-sensitive (sensible a may\u00fasculas y min\u00fasculas), por lo que las claves \u201cnombre\u201d y \u201cNombre\u201d son diferentes, y por tanto consideradas como campos diferentes.</li> <li>Las claves dentro de un mismo documento deben ser \u00fanicas, no pueden duplicarse. As\u00ed por ejemplo el siguiente documento no es v\u00e1lido por tener dos veces la clave nota.</li> </ul> <pre><code>  {\nnombre:\"Jose Antonio\",\nnota:8.9,\nnota:7.2 }\n</code></pre> <p>Cada documento en Mongo debe tener obligatoriamente un campo _id con valor \u00fanico y que actuar\u00e1 como identificador \u00fanico del documento. Es tan necesario este campo que cuando se guarda un documento sin especificarlo, Mongo autom\u00e1ticamente le asigna uno del tipo ObjectId.</p>"},{"location":"BDA/Tema04/MongoDB/#312-colecciones","title":"3.1.2. Colecciones","text":"<p>Una colecci\u00f3n es un grupo de documentos, es lo an\u00e1logo a las tablas en el modelo relacional. Las colecciones tienen esquemas din\u00e1micos, lo que significa que los documentos dentro de una colecci\u00f3n pueden tener m\u00faltiples \u201cformas\u201d. Por ejemplo, los siguientes documentos podr\u00edan guardarse en la misma colecci\u00f3n, a pesar de tener diferentes campos, y diferentes tipos de datoS. <pre><code>  { nombre:\"Jose Antonio\", edad:35 }\n{ username::\"pepito\", type:6, active:true }\n</code></pre></p> <p>Hay algunas restricciones respecto al nombre que una colecci\u00f3n puede tener:</p> <ul> <li>La cadena vac\u00eda (\u201c\u201d) no es un nombre v\u00e1lido.</li> <li>Lo puede contener el car\u00e1cter null.</li> <li>No se pueden crear colecciones cuyo nombre empiece por \u201csystem.\u201d, ya que es un prefijo reservado para colecciones internas.</li> <li>No debe contener el car\u00e1cter $ (d\u00f3lar).</li> </ul>"},{"location":"BDA/Tema04/MongoDB/#32-operaciones-basicas","title":"3.2. Operaciones b\u00e1sicas","text":""},{"location":"BDA/Tema04/MongoDB/#321-insercion","title":"3.2.1. Inserci\u00f3n","text":"<p>Para insertar un documento en una colecci\u00f3n, utilice el m\u00e9todo: <pre><code>  db.alumno.insert({\"name\":\"Antonio Cuenca\"})\n</code></pre></p> <p>El comando ha a\u00f1adido autom\u00e1ticamente el campo _id de tipo ObjectId, ya que como hemos explicado, todo documento debe tener un identificador \u00fanico. Pero el uso del tipo ObjectId para el campo _id no es obligatorio, podemos utilizar cualquier valor, siempre y cuando garanticemos su unicidad. A continuaci\u00f3n insertamos una nueva alumna, especificando que su _id es el n\u00famero 10 (tipo Long). <pre><code>  db.alumno.insert({_id:NumberLong(10), name:\"Eva\",apellidos:\"Perez Garcia\"})\n</code></pre></p> <p>Si queremos insertar m\u00faltiples documentos,podemos hacer la inserci\u00f3n m\u00e1s r\u00e1pida utilizando batch inserts, que permiten insertar en bloque un array de documentos a la colecci\u00f3n. Esto se consigue con solo pasar un array de objetos al comando insert. <pre><code>  db.numerosprimos.insert(\n[{_id:2},{_id:3},{_id:5},{_id:7},{_id:11},{_id:13},{_id:17},{_id:19}] )\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#322-borrado","title":"3.2.2. Borrado","text":"<p>Vaya con cuidado, eliminar colecciones completas es muy sencillo en Mongo. Esto borrar\u00e1 todo, tanto la colecci\u00f3n como meta propiedades asociadas a ella o \u00edndices creados sobre campos.   db.alumno.drop() Por otra parte, para eliminar solo documentos de una colecci\u00f3n, tenemos el comando remove, que recibe como par\u00e1metro el criterio de borrado en forma de documento JSON. En ese caso, solo los documentos que cumplen el criterio se eliminar\u00e1n de la colecci\u00f3n. <pre><code>  db.numerosprimos.remove( {id:23})\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#323-modificacion","title":"3.2.3. Modificaci\u00f3n","text":"<p>Para modificar un documento se utiliza el m\u00e9todo update. Este m\u00e9todo recibe dos par\u00e1metros, el primero es el criterio de actualizaci\u00f3n, y el segundo el modificador, que describe los cambios que deben realizarse.</p> <p>Esta es la lista de modificadores:</p> Modificador Acci\u00f3n $set Asigna el valor a un campo $unset Elimina cualquier campo de uno o varios documentos $inc Incrementar el valor num\u00e9rico de una clave existente $push A\u00f1adir elementos a un array $pull Elimina elementos de un array basados en un criterio $pop Elimina el primer o \u00faltimo elemento del array upsert Si no existe el documentoe lo crea multi Modifica multiples documentos <p>Veamoslos:</p> <p>$set</p> <p>Asigna el valor a un campo. Si el campo todav\u00eda no existe en el documento lo crear\u00e1. Se utiliza en el segundo par\u00e1metro que se le pasa al comando update. <pre><code>    db.alumno.insert( { name:\"Arturo\", apellidos:\"Leon Zapata\" })\ndb.alumno.update( {name:\"Arturo\"}, { $set: {edad:17} })\n</code></pre></p> <p>Podemos darle valor a varios campos a la vez, simplemente informando los pares clave:valor separados por coma. En este ejemplo damos valor a tres campos diferentes con un solo comando. <pre><code>    db.alumno.update({name:\"Arturo\"},{$set:{nota:8.2,orden:12,actitud:\"positiva\"}})\n</code></pre></p> <p>$unset</p> <p>Para eliminar cualquier campo de uno o varios documentos lo hacemos tambi\u00e9n con el comando update pero con el modificador $unset.</p> <p>En MongoDB es habitual utilizar los valores 1 y -1 para indicar verdadero y falso respectivamente. En este caso, al especificar valor 1 estamos diciendo que la clave entra dentro del conjunto de campos en los que queremos aplicar el $unset.</p> <p>De esta forma, si queremos eliminar el campo \"edad\" del documento que guarda la informaci\u00f3n del alumno \"Arturo\", lo har\u00edamos as\u00ed. <pre><code>    db.alumno.update({name:\"Arturo\"},{$unset:{edad:1}})\n</code></pre></p> <p>$inc</p> <p>Este modificador puede utilizarse para incrementar o decrementar el valor num\u00e9rico de una clave existente o para crear una nueva si no existe. <pre><code>    db.alumno.update({name:\"Arturo\"},{$inc:{puntuacion:2}})\n</code></pre></p> <p>Otros operadores que podemos utilizar de forma similar son $mul, $min, $max y $currentDate. <pre><code>    db.alumno.update({name:\"Arturo\"},{$min:{puntuacion:3}})\n</code></pre></p> <p>El ejemplo de arriba modifica la puntuaci\u00f3n y le asigna un 3, si esta es mayor que 3. Tambien se puede leer como que le asinga el menor de los valores, el actual o el propuesto en la actualizaci\u00f3n.</p> <p>$push</p> <p>Se utiliza para a\u00f1adir elementos a un array. Si el array no existe lo crea con los elementos indicados en el push, y si ya existe los a\u00f1ade al final del array. <pre><code>    db.alumno.insert({name:\"Sofia\", apellidos:\"Alarcon Sevilla\"})\ndb.alumno.update({name:\"Sofia\"},\n{$push:{\"asignaturas\":{name:\"Matematicas\", nota:9.1}}}\n)\n</code></pre></p> <p>$pull</p> <p>Hay varias formas de eliminar elementos de un array. Cuando queremos borrar elementos basados en alg\u00fan criterio, el modificador adecuado es $pull. Partimos de un array y borraremos elementos <pre><code>    db.lists.insert({\"todo\": [\"lavar platos\", \"colada\", \"tender\"]})\n</code></pre> Para eliminar la colada har\u00edamos. <pre><code>    db.lists.update({},{$pull:{\"todo\":\"colada\"}})\n</code></pre></p> <p>$pop</p> <p>Para eliminar el primer o \u00faltimo elemento del array. Para eliminar el \u00faltimo elemento del array: <pre><code>    db.lists.update({},{$pop:{todo:1}})\n</code></pre> Para eliminar el prtimer elemento del array: <pre><code>    db.lists.update({},{$pop:{todo:-1}})\n</code></pre></p> <p>Upsert</p> <p>Un upsert es un tipo de update especial. Si no se encuentra ning\u00fan documento que haga matching con el criterio del update, entonces se crear\u00e1 un nuevo documento combinando el criterio y lo que se quiere actualizar. Si se encuentra un documento que haga matching se actualizar\u00e1 normalmente. Para decirle a MongoDB que queremos hacer un upsert, solo hay que pasar al comando update un tercer par\u00e1metro, con valor true. Esto significa que el update se comportar\u00e1 como lo acabamos de explicar.  <pre><code>    update({...},{...},true)\ndb.alumno.update({name:\"Sofia\"},\n{$set:{apellidos:\"Alarcon Revilla\"}},\n{upsert:true})\n</code></pre></p> <p>Multiples Documentos</p> <p>Para modificar m\u00faltiples documentos, en el tercer par\u00e1metro del update indicaremos {multi: true}.  <pre><code>    db.books.update({lang:\"en\"},\n{$inc: {price: 50.00}}, {multi:true})\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#33-consultas","title":"3.3. Consultas","text":"<p>El m\u00e9todo find es el qu\u00e9 se utiliza para hacer queries en Mongo. Es el equivalente al comando select en el modelo relacional. Al consultar una colecci\u00f3n, Mongo nos devolver\u00e1 un subconjunto de documentos, que variar\u00e1 desde el conjunto vaci\u00f3 hasta la colecci\u00f3n completa.</p> <p>Find tiene varios par\u00e1metros de entrada, el primero de ellos especifica los documentos que queremos recuperar, esto es, el criterio de b\u00fasqueda. <pre><code>    db.coleccion.find({ clave:valor })\n</code></pre> La funci\u00f3n anterior nos devolver\u00eda documentos de la colecci\u00f3n coleccion cuyo campo clave tenga un valor igual a valor.</p> <p>El valor por defecto para este primer par\u00e1metro es {}, que significa \"cualquier documento\". Por tanto una query como db.coleccion1.find({ }) devolver\u00e1 todos los documentos de la colecci\u00f3n coleccion1. Como es el valor por defecto para el criterio de la consulta es equivalente hacer find({ }) y find( ). <pre><code>    db.alumno.find({edad:17})\ndb.alumno.find({name:\"Antonio\"})\n</code></pre></p> <p>Igual que en SQL podemos especificar los campos que queremos recuperar (select campo1, campo2, campo3 from tabla ... ), podemos hacerlo tambi\u00e9n en Mongo. Para ello solo tenemos que pasar un segundo par\u00e1metro al m\u00e9todo find, en el que decimos los que queremos. <pre><code>    db.coleccion1.find({ },{ clave3:1, clave4:1 })\n</code></pre> Los campos que queremos que sean devueltos les pondremos el valor 1. El campo _id siempre se devuelve. Tambi\u00e9n podemos especificar los campos que no queremos que sean devueltos, en este caso como valor para cada una de esos campos, pondremos cero. El resultado ser\u00e1 que se devolver\u00e1n el resto de documentos. <pre><code>  db.coleccion1.find({ },{ clave3:0, clave4:0 })\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#331-operadores-de-comparacion","title":"3.3.1 Operadores de comparaci\u00f3n","text":"<p>MongoDB permite utilizar los siguientes operadores de comparaci\u00f3n:</p> Operador Condici\u00f3n $lt &lt; $lte &lt;= $gt &gt; $gte &gt;= <p>La sintaxis es: <pre><code>  clave: { $operador: valor }\n</code></pre> As\u00ed si por ejemplo queremos recuperar los libros con un precio mayor que 10 lo har\u00edamos utilizando el operador $gt sobre el campo precio: <pre><code>  db.libro.find({\"precio\":{$gt:10}},{titulo:1,precio:1})\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#332-operadores-logicos","title":"3.3.2. Operadores l\u00f3gicos","text":"Operador Acci\u00f3n Sintaxis $in Recupera documentos cuyo campo clave est\u00e9 entre alguno de los valores especificados en el array clave:{$in:[valor1,valor2,valorN]} $nin Recupera documentos cuyo campo clave NO est\u00e9 entre alguno de los valores especificados en el array clave:{$nin:[valor1,valor2,valorN]} $or Con el siguiente find, vamos a recuperar aquellos documentos que est\u00e9n en stock (enstock:false) o que tengan editorial (editorial:null). $or:[{clave1:valor1},{clave2:valor2},{claveN:valorN}] $nor Con el siguiente find, vamos a recuperar aquellos documentos que no est\u00e9n en stock (enstock:false) o que no tengan editorial (editorial:null). $nor:[{clave1:valor1},{clave2:valor2},{claveN:valorN}] $not Es lo que se conoce como un metacondicional, que son opeadores que pueden aplicarse por encima de cualquier otro criterio. Su sintaxis es sencilla, solo hay que ponerlo \u201cfuera\u201d de aquello que queremos negar. $not:{criterio} $exist Se utiliza para comprobar los documentos que tienen informado o no un campo determinado clave:{$exists:boolean} <p>Ejemplos</p> <p><pre><code>db.libro.find({editorial:{$in:[\"Debolsillo\",\"Planeta\",\"Gigamesh\"]}},\n{titulo:1,editorial:1}\n)\n</code></pre> <pre><code>  db.libro.find({editorial:{$nin:[\"Debolsillo\",\"Planeta\",\"Gigamesh\"]}},\n{titulo:1,editorial:1}\n)\n</code></pre> <pre><code>  db.libro.find({$or:[{enstock:false},{editorial:null}]},\n{titulo:1,editorial:1,enstock:1}\n)\n</code></pre> <pre><code>  db.libro.find({$nor:[{enstock:false},{editorial:null}]},\n{titulo:1,editorial:1,enstock:1}\n)\n</code></pre> <pre><code>  db.libro.find( { paginas: {$not: { $eq:480 } } },\n{titulo:1,paginas:1}\n)\n</code></pre> <pre><code>  db.libro.find({paginas:{$exists:true}},{paginas:1})\n</code></pre></p> <p>null</p> <p>Tiene un comportamiento un poco extra\u00f1o, ya que hace matching en los siguientes casos:</p> <ul> <li>Con valores que almacenan null, por ejemplo \u201cy\u201d : null</li> <li>Con campos que no existen en un documento. Si por ejemplo el documento A no tiene informado el campo x, una b\u00fasqueda por { x:null } s\u00ed que se encontrar\u00eda.</li> </ul>"},{"location":"BDA/Tema04/MongoDB/#333-busqueda-de-texto","title":"3.3.3. B\u00fasqueda de texto","text":"<p>En MongoDB, podemos realizar b\u00fasquedas de texto usando expresiones regulares. Aqu\u00ed tienes un ejemplo: <pre><code>  db.libro.find({autor:/posteguillo/iu},{titulo:1,autor:1}).pretty()\n</code></pre></p> <ul> <li>La opci\u00f3n \"i\" hace que la b\u00fasqueda sea insensible a may\u00fasculas y min\u00fasculas.</li> <li>La opci\u00f3n \"u\" hace que sea insensible a los acentos diacr\u00edticos.</li> </ul>"},{"location":"BDA/Tema04/MongoDB/#334-consultas-con-arrays","title":"3.3.4. Consultas con Arrays","text":"<p>Creamos una colecci\u00f3n para ver los ejemplos <pre><code>  db.comida.insert({fruta:[\"manzana\",\"platano\",\"pera\"]})\n</code></pre></p> <p>Para buscar documentos que tengan un elemento concreto dentro del array, es tan simple como poner el nombre del array y el valor que queremos encontrar. <pre><code>  db.comida.findOne({fruta:\"pera\"})\n</code></pre></p> <p>Podemos utilizar cualquiera de los operadores aprendidos hasta el momento, como por ejemplo $in, para recuperar documentos que tengan alguno de los valores especificados. <pre><code>  db.comida.findOne({fruta: { $in:[\"pera\",\"platano\",\"melocoton\"] }})\n</code></pre></p> <p>Si necesita recuperar arrays que contengan m\u00e1s de un elemento, puede utilizar el operador $all, que permite especificar una lista de elementos. Modificamos la colecci\u00f3n para ver unos ejemplos <pre><code>  db.comida.drop()\ndb.comida.insert({_id:1, fruta:[\"manzana\",\"platano\",\"melocoton\"]})\ndb.comida.insert({_id:2, fruta:[\"manzana\",\"kiwi\",\"naranja\"]})\ndb.comida.insert({_id:3, fruta:[\"cerezas\",\"platano\",\"manzana\"]})\n</code></pre></p> <p>Si ahora queremos documentos que tengan los elementos platano y manzana, lo haremos con $all de esta forma. <pre><code>  db.comida.find({fruta: { $all:[\"platano\",\"manzana\"]}})\n</code></pre></p> <p>Para recuperar documentos que tengan un valor concreto en cierto \u00edndice del array, se consigue poniendo dicho \u00edndice (empezando desde cero) tras un punto del array. Es decir: fruta.0 es el primer elemento del array. <pre><code>  db.comida.find({\"fruta.0\":\"cerezas\"})\n</code></pre></p> <p>$size</p> <p>Un condicional \u00fatil para las consultas contra arrays es $size, que permite recuperar arrays que tienen un determinado tama\u00f1o. La siguiente consulta muestra los documentos que tenga 2 frutas. <pre><code>  db.comida.find({fruta:{$size:2}})\n</code></pre></p> <p>$slice</p> <p>El operador $slice se utiliza para devolver un subconjunto de los elementos delarray. No influye en el criterio de b\u00fasqueda, solo es para especificar a mongo lo que queremos que nos devuelva. Su sintaxis es la siguiente.</p> <p>clave: { $slice: x}</p> <p>Donde seg\u00fan x:</p> <ul> <li>x es un entero positivo (p.ej 10), devuelve los primeros x elementos del array clave.</li> <li>x es un entero negativo (p.ej -10), devuelve los \u00faltimos x elementos del array clave.</li> <li>x es un array (p.ej [2,4], devuelve los elementos desde el 2 al 4, ambos incluidos.</li> </ul> <p>Ejemplos: <pre><code>  db.comida.find({},{fruta:{$slice:2}})\ndb.comida.find({},{fruta:{$slice:-2}})\ndb.comida.find({},{fruta:{$slice:[1,3]}})\n</code></pre></p> <p>Conjuntos de valores</p> <p>Si queremos obtener todos los diferentes valores que existen en un campo, utilizaremos el m\u00e9todo distinct <pre><code>  db.grades.distinct('type')\n</code></pre></p> <p>Contar valores</p> <p>Para contar el n\u00famero de documentos, en vez de find usaremos el m\u00e9todo count. Por ejemplo: <pre><code>  db.grades.count({type:\"exam\"})\ndb.grades.find({type:\"exam\"}).count() db.grades.count({type:\"essay\", score:{$gt:90}})\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#335-documentos-embebidos","title":"3.3.5. Documentos embebidos","text":"<p>Para hacer queries contra campos de documentos embebidos dentro de otros documentos, solamente hay que poner la \u201cruta\u201d completa de claves separada por puntos. </p> <p>Es decir, si tenemos por ejemplo una estructura como esta para los libros. <pre><code>  db.libro.save({\n\"_id\":\"9788408117117\",\n\"titulo\":\"Circo M\u00e1ximo\",\n\"autor\": {\nnombre:\"Santiago\",\napellidos:\"Posteguillo G\u00f3mez\",\nnacimiento: {\nanyo:1967,\nciudad:\"Valencia\"\n}\n},\n\"editorial\":\"Planeta\",\n\"enstock\":true,\n\"paginas\":1100,\n\"precio\":21.75\n})\n</code></pre></p> <p>Podemos lanzar queries directamente contra los documentos embebidos, autor y nacimiento de esta forma. <pre><code>  db.libro.findOne({\"autor.nombre\":\"Santiago\"})\n</code></pre></p> <p>El find anterior recuperar\u00e1 el primer documento donde el campo nombre, del campo autor sea \u201cSantiago\u201d. <pre><code>  db.libro.findOne({\"autor.nacimiento.anyo\":{$gt:1965}})\n</code></pre> El find anterior recuperar\u00e1 el primer documento donde el campo anyo, del campo nacimiento, del campo autor sea mayor que 1965.</p>"},{"location":"BDA/Tema04/MongoDB/#34-cursores","title":"3.4. Cursores","text":"<p>La base de datos devuelve resultados para find utilizando cursores, que realmente es un puntero a los resultados de una query, no los resultados en si mismos. Los clientes integrados con Mongo, iteran sobre los cursores para recuperar los resultados, y ofrecen un conjunto de funcionalidades como limitar el n\u00famero de resultados, saltar para no tener que recuperar obligatoriamente los primeros, ordenarlos, etc.</p> <p>Las opciones de query m\u00e1s comunes son limitar el n\u00famero de resultados, saltar un n\u00famero de resultados, y ordenarlos. Todas estas opciones deben especificarse en la propia query al sistema.</p> <p>Para fijar un l\u00edmite, debe concatenar la funci\u00f3n limit tras la funci\u00f3n find. Por ejemplo, para solo recuperar los primeros tres libros almacenados, use esto: <pre><code>  db.libro.find({},{titulo:1}).limit(3)\n</code></pre> La funci\u00f3n skip para \u201csaltar\u201d algunos resultados, funciona de forma similar a limit, concaten\u00e1ndola tras find. Con el siguiente skip(3) saltamos los primeros tres t\u00edtulos, y el cursor empezar\u00e1 a devolver a partir del cuarto. <pre><code> db.libro.find({},{titulo:1}).skip(3)\n</code></pre></p> <p>La funci\u00f3n sort sirve para ordenar los resultados que se devuelven. Recibe un objeto json con las claves y un valor 1 (para ordenaci\u00f3n ascendente) o -1 (para ordenaci\u00f3n descendente). <pre><code>  db.libro.find({},{titulo:1,precio:1,paginas:1}).sort({precio:1,paginas:-1})\n</code></pre></p> <p>Estas tres funciones, limit, skip y sort, pueden combinarse como se quiera para recuperar exactamente lo que queramos. <pre><code>  db.libro.find({},{titulo:1,precio:1,paginas:1}).limit(3).skip(2).sort({precio:1, paginas:-1}).pretty()\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#35-agregacion","title":"3.5. Agregaci\u00f3n","text":"<p>Una vez tenemos datos almacenados en MongoDB, queremos hacer algo m\u00e1s que solamente recuperarlos, queremos analizarlos de diversas formas interesantes. Esto lo conseguimos con la funci\u00f3n de agregaci\u00f3n que MongoDB ofrece.</p> <p>La agregaci\u00f3n nos permite transformar y combinar documentos en una colecci\u00f3n. B\u00e1sicamente, se construye un pipeline (secuencia de comandos) que procesan un conjunto de documentos a trav\u00e9s de varios \u201cbloques\u201d: filtrado, proyecciones, agrupaciones, ordenaci\u00f3n, limitaci\u00f3n y skipping.</p> <p>Por ejemplo, si de la colecci\u00f3n de  libros  de ejemplo quisi\u00e9ramos saber los tres autores con m\u00e1s libros escritos, crear\u00edamos un pipeline con los siguientes pasos:</p> <ul> <li>Proyectar\u00edamos el autor de cada libro.0</li> <li>Agrupar\u00edamos los autores por nombre, contando el n\u00famero de ocurrencias.</li> <li>Ordenar\u00edamos los autores por dicho n\u00famero de ocurrencias, descendentemente.</li> <li>Limitar\u00edamos el resultado a los primeros tres.</li> </ul> <p>Cada uno de estos pasos se corresponde con un operador de agregaci\u00f3n</p> <ol> <li> <p>{\u201c$project\u201d : { \u201cautor\u201d : 1 }} Esto \u201cproyecta/extrae\u201d el autor de cada documento. La sintaxis es similar al selector de campos utilizado con find (el segundo  par\u00e1metro), especificando \u201cnombrecampo\u201d: para incluir o \u201cnombrecampo\u201d:0 para excluir. Despu\u00e9s de esta operaci\u00f3n, cada documento de los resultados es algo as\u00ed:  {\u201c_id\u201d:id,  \u201cautor\u201d:\u201dnombre  de  autor\u201d}.  Estos  resultados  solo  existen  en memoria, no se escribir\u00e1n nunca a disco</p> </li> <li> <p>{\u201c$group\u201d : { \u201c_id\u201d:\u201d$autor\u201d, \u201ccount\u201d: {\u201c$sum\u201d:1}}}  Eso agrupa por autores e incrementa (\u201ccount\u201d) para cada documento en los que el autor aparece. Primero especificamos el campo por el que queremos agrupar, que es \u201cautor\u201d (Esto lo indicamos con el \u201c_id\u201d:\u201d$autor\u201d). Podr\u00edamos entenderlo como: tras el Group habr\u00e1 un documento resultado para cada autor, por lo que \u201cautor\u201d se convertir\u00e1 en el identificador \u00fanico (\u201c_id\u201d). El segundo campo significa a\u00f1adir 1 al campo \u201ccount\u201d para cada documento en el grupo. F\u00edjese  que los documentos de entrada (libro) no tienen el  campo \u201ccount\u201d, es un nuevo campo creado por el \u201c$group\u201d. Al final de este paso, cada documento resultado es algo como:  {\u201c_id\u201d:\u201dnombre_de_autor\u201d, \u201ccount\u201d: numero_de_libros}</p> </li> <li> <p>{\u201c$sort\u201d : {\u201ccount\u201d : -1}} Esto reordena los resultados por el valor del campo \u201ccount\u201d descendentemente (-1). En caso de ascendente ser\u00eda \u201ccount\u201d:1.</p> </li> <li> <p>{\u201c$limit\u201d : 3}  Limita el n\u00famero de resultados a los primeros tres.</p> </li> </ol> <p>Veamos todo esto con m\u00e1s detalle y partiendo de un ejemplo con una colecci\u00f3n de libros</p> <p><pre><code>db.libros.aggregate({$project:{autor:1}},\n{$group:{_id:\"$autor\",count:{$sum:1}}},\n{$sort:{count:-1}},\n{$limit:3}\n)\n</code></pre> Resultado: <pre><code>  { \"_id\" : \"Santiago Posteguillo\", \"count\" : 3 }\n{ \"_id\" : \"George R.R. Martin\", \"count\" : 2 }\n{ \"_id\" : \"Anna Casanovas\", \"count\" : 1 }\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#351-operadores-del-pipeline","title":"3.5.1. Operadores del pipeline","text":"<p>Cada operador recibe un conjunto de documentos, hace alg\u00fan tipo de transformaci\u00f3n sobre ellos, y despu\u00e9s pasa el resultado de la transformaci\u00f3n.  Esto es lo que se conoce como pipeline.</p> <p></p>"},{"location":"BDA/Tema04/MongoDB/#3511-operador-match","title":"3.5.1.1. Operador $match","text":"<p>El operador $match filtra documentos de forma que podamos ejecutar una agregaci\u00f3n sobre un subconjunto de documentos, puede utilizar todos los operadores para query estudiados ($gt, $lt, $in, etc).</p> <p>Con el siguiente ejemplo, filtrar\u00edamos solo aquellos libros con un precio mayor que 20, reduciendo el conjunto inicial de documentos y formando la entrada de  los siguientes pasos del pipeline. <pre><code>db.libros.aggregate({$match:{precio:{$gt:20}}})\n</code></pre> Como hemos comentado, cualquiera de las condiciones estudiadas del find podemos utilizarlas con match. Como por ejemplo, los libros en stock.  <pre><code>db.libros.aggregate({$match:{enstock:true}})\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#3512-operador-project","title":"3.5.1.2. Operador $project","text":"<p>La \u201cproyecci\u00f3n\u201d es mucho m\u00e1s potente en el pipeline que en el lenguaje \u201cnormal\u201d de la query. $project nos permite extraer campos de subdocumentos, renombrar campos, y realizar operaciones interesantes sobre ellos. </p> <p>La operaci\u00f3n m\u00e1s sencilla de $project realiza una selecci\u00f3n simple de unos documentos de entrada, es decir, de los documentos de entrada con campos a, b, c y d, con $project decimos que nos quedamos \u00fanicamente con a y c. Para incluir o excluir un campo, se utiliza la misma sintaxis que para el segundo argumento de una query, es decir \u201cnombrecampo\u201d: 1 para incluir o \u201cnombrecampo\u201d:0 para excluir. Por defecto, el campo \u201c_id\u201d siempre se devuelve si existe en los documentos de entrada. Lo podemos eliminar por ejemplo utilizando $project de la siguiente forma, en la que devolver\u00edamos todos los campos excepto \u201c_id\u201d. {$project:{ \u201c_id\u201d:0 }}.  </p> <p>Con $project tambi\u00e9n podemos renombrar el campo proyectado. Por ejemplo si queremos devolver el campo \u201c_id\u201d de los libros como \u201cisbn\u201d har\u00edamos esto.  <pre><code>db.libros.aggregate({$project:{isbn:\"$_id\"}})\n</code></pre></p> <p>La clave est\u00e1 en $_id, cuando ponemos el s\u00edmbolo del d\u00f3lar ($) m\u00e1s el nombre de un campo, nos estamos refiriendo al valor que tomar\u00e1 dicho campo para cada documento en el entorno de agregaci\u00f3n. Por tanto con $project: {\u201cisbn\u201d:\u201d$_id\u201d} estamos diciendo que proyectamos un nuevo campo isbn como el valor que tendr\u00e1 el campo _id en cada documento de entrada.  Igualmente podr\u00edamos haber renombrado cualquier otro campo, por ejemplo el campo \u201censtock\u201d como \u201cdisponible\u201d.  <pre><code>db.libros.aggregate({$project:{isbn:\"$_id\",disponible:\"$enstock\"}})\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#3513-operador-group","title":"3.5.1.3. Operador $group","text":"<p>Agrupa los documentos con el prop\u00f3sito de calcular valores agregados de una colecci\u00f3n de documentos. Cuando referenciamos al valor de un campo lo haremos poniendo entre comillas un $ delante del nombre del campo. Ejemplo:</p> <p><pre><code>db.libros.aggregate([{\n$group:{\n_id: \"$autor\",\ntotal: { $sum:1 }\n}\n}])\n</code></pre> Si lo que queremos es que el valor del identificador contenga un objeto, lo podemos hacer asoci\u00e1ndolo como valor:</p> <pre><code>db.libros.aggregate([{\n$group:{\n_id: { \"escritor\": \"$autor\" },\ntotal: { $sum:1 }\n}\n])\n</code></pre>"},{"location":"BDA/Tema04/MongoDB/#3514-expresiones-en-el-pipeline","title":"3.5.1.4. Expresiones en el Pipeline","text":"<p>La operaciones m\u00e1s simples en $project son inclusi\u00f3n, exclusi\u00f3n y nombres de campo (\u201c$nombrecampo\u201d). Aunque hay otras m\u00e1s, mucho m\u00e1s potentes. Podemos utilizar expresiones, que nos permiten combinar m\u00faltiples literales y variables en un valor \u00fanico. </p> <p>Expresiones matem\u00e1ticas. </p> <p>Las expresiones matem\u00e1ticas nos permiten manipular valores num\u00e9ricos contra los que operar, y que normalmente se especifican en un array. </p> <p>Esta es la sintaxis para cada operador matem\u00e1tico. </p> <ul> <li>\u201c$add\u201d: [ expr1, expr2, ... , exprN ]. Toma uno o mas expresiones y las suma. </li> <li>\u201c$substract\u201d: [ expr1, expr2 ]. Resta la expr2 a la expr1. </li> <li>\u201c$multiply\u201d: [ expr1, expr2, ..., exp\u00f3n ]. Toma una o m\u00e1s expresiones y las multiplica. </li> <li>\u201c$divide\u201d: [ expr1, expr2 ]. Divide la expr1 entre la expr2. </li> <li>\u201c$mod\u201d: [ expr1, expr2 ]. Divide la expr1 entre la expr2 y devuelve el resto. </li> </ul> <p>Por ejemplo, para obtener el montante total de los productos agrupados por fabricante, har\u00edamos:</p> <pre><code>db.libros.aggregate([{\n$group: {\n_id: {\n\"escritor\":\"$autor\"\n},\ntotalPrecio: {$sum:\"$precio\"}\n}\n}])\n</code></pre> <p>Expresiones de fechas. </p> <p>Muchas agregaciones son basadas en el tiempo. \u00bfQu\u00e9 ocurri\u00f3 la semana pasada? \u00bfY el mes pasado?. Es por esto que el entorno de agregaci\u00f3n tiene un conjunto de expresiones  que pueden utilizarse para extraer informaci\u00f3n sobre fechas de una forma muy usable, son: \u201c$year\u201d, \u201c$month\u201d,\u201c$week\u201d, \u201c$dayOfMonth\u201d, \u201c$dayOfWeek\u201d, \u201c$dayOfYear\u201d, \u201c$hour\u201d, \u201c$minute\u201d y \u201c$second\u201d. </p> <p>Con siguiente sentencia de agregaci\u00f3n vamos a recuperar tanto la fecha, como el a\u00f1o de dicha fecha, gracias a la expresi\u00f3n \u201c$year\u201d.</p> <pre><code>db.libros.aggregate({$project:{fecha:1,year:{$year:\"$fecha* }}})\n</code></pre> <p>Expresiones de Strings.</p> <p>Hay una pocas operaciones b\u00e1sicas sobre cadenas de caracteres que tambi\u00e9n podemos utilizar. Son estas: </p> <p>\u201c$substr\u201d: [ expr, start, length ]. Devuelve el substring de la expresi\u00f3n expr, empezando en la posici\u00f3n start de la cadena y devolviendo desde ah\u00ed un total de length caracteres. En el siguiente ejemplo proyectamos un campo inicio los primeros quince caracteres del campo t\u00edtulo. <pre><code>db.libros.aggregate({$project: {inicio:{$substr: [\"$titulo\",0,15] }}})\n</code></pre></p> <p>\u201c$concat\u201d: [ expr1, expr2, ..., exprN ]. Devuelve un nuevo string resultado de la concatenaci\u00f3n de expr1, expr2 y as\u00ed hasta exprN. En el siguiente ejemplo proyectamos un campo descripci\u00f3n en el que concatenamos el titulo, un gui\u00f3n, y el autor. <pre><code>db.libros.aggregate({$project:{descripcion:{$concat:[\"$titulo\",\" - \",\"$autor\"]},_id:0}})\n</code></pre></p> <p>\u201c$toLower\u201d: expr. Devuelve un string en min\u00fasculas.  \u201c$toUpper\u201d: expr. Devuelve un string en may\u00fasculas. </p> <p>Expresiones l\u00f3gicas.</p> <p>Existen algunas operaciones l\u00f3gicas que podemos utilizar. Replanteamos el ejemplo anterior de la proyecci\u00f3n del campo \u201cbarato\u201d utilizando uno de estos comparadores.  </p> <pre><code>db.libros.aggregate({$project:{barato:{$gt:[15,\"$precio\"]},precio:1} })\n</code></pre>"},{"location":"BDA/Tema04/MongoDB/#3515-operador-sort","title":"3.5.1.5. Operador $sort","text":"<p>Podemos ordenar por cualquier campo o conjunto de campos utilizando la misma sintaxis que para las queries \u201cnormales\u201d. </p> <p>Si tenemos que ordenar un n\u00famero de documentos muy elevado, es recomendable desde el punto de vista del rendimiento, que hagamos la ordenaci\u00f3n al principio del pipeline y adem\u00e1s tengamos un \u00edndice por el conjunto de campos por los que ordenar. De otra forma, $sort puede ser lento y consumir mucha memoria. </p> <p>Se pueden utilizar tanto campos existentes como campos proyectados para ordenar. De esta forma podemos por ejemplo completar la agregraci\u00f3n en la que calcul\u00e1bamos la media aritm\u00e9tica del precio de los libros por autor, y ordenar los resultados por dicha media calculada ascendentemente. </p> <pre><code>db.libros.aggregate({$group:{_id:\"$autor\", media:{$avg:\"$precio\"}}},\n{$sort:{media:1}}\n)\n</code></pre> <p>Para ordenar cada campo es valor 1, para ordenaci\u00f3n ascendente y -\u00ad\u20101 para descendente. En el siguiente ejemplo ordenamos primero por precio descendente y despu\u00e9s por p\u00e1ginas ascendente. <pre><code>db.libros.aggregate({$project:{precio:1,paginas:1}},\n{$sort:{precio:-1,paginas:1}}\n)\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#3516-operador-limit","title":"3.5.1.6. Operador $limit","text":"<p>La funci\u00f3n $limit toma un n\u00famero N y devuelve los primeros N documentos resultantes.  <pre><code>db.libros.aggregate({$project:{precio:1,paginas:1}},\n{$sort:{precio:-1,paginas:1}},\n{$limit:3}\n)\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#3517-operador-skip","title":"3.5.1.7. Operador $skip","text":"<p>La funci\u00f3n $skip toma un n\u00famero N y desecha los primeros N documentos del conjunto de resultados.  <pre><code>db.libros.aggregate({$project:{precio:1,paginas:1}},\n{$sort:{precio :-1,paginas:1}},\n{$skip:3}\n)\n</code></pre></p>"},{"location":"BDA/Tema04/MongoDB/#3518-operador-unwind","title":"3.5.1.8. operador $unwind","text":"<p>Dentro de una agregaci\u00f3n podemos utilizar el operador $unwind, se podr\u00eda traducir como \"aplanar\" ya que aplana los datos de un array convirti\u00e9ndo sus elementos en documentos independientes. Puede ser \u00fatil para poder acceder al interior de los elementos de un array cuando estos no son at\u00f3micos.</p> <pre><code>db.usuario.aggregate({$project: {comentarios:1}},\n{$unwind :\"$comentarios\" }\n)\n</code></pre>"},{"location":"BDA/Tema04/MongoDB/#3519-operador-lookup","title":"3.5.1.9. operador $lookup","text":"<p>El operador $lookup se utiliza para realizar una operaci\u00f3n de \"join\" entre dos colecciones en MongoDB, lo que te permite combinar documentos de una colecci\u00f3n con documentos de otra bas\u00e1ndote en un campo com\u00fan. </p> <p>Supongamos que tienes dos colecciones: ventas y clientes, y deseas combinar documentos de ambas bas\u00e1ndote en el campo cliente_id que se encuentra en ambas colecciones, y quieres obtener todos los pedidos junto con la informaci\u00f3n del cliente al que pertenecen. <pre><code>db.ventas.aggregate([\n{\n$lookup: {\nfrom: \"clientes\",   // El nombre de la segunda colecci\u00f3n\nlocalField: \"cliente_id\",  // El campo en la colecci\u00f3n \"ventas\"\nforeignField: \"cliente_id\",  // El campo en la colecci\u00f3n \"clientes\"\nas: \"cliente_info\"  // El nombre del nuevo campo que contendr\u00e1 la informaci\u00f3n del cliente\n}\n}\n]);\n</code></pre></p> <ol> <li>Usamos la operaci\u00f3n aggregate en la colecci\u00f3n ventas.</li> <li>Dentro del $lookup, especificamos la colecci\u00f3n clientes con la propiedad from.</li> <li>Luego, definimos localField como \"clienter_id\", que es el campo en la colecci\u00f3n ventas que se usar\u00e1 como clave para hacer la uni\u00f3n.</li> <li>foreignField se establece en \"cliente_id\", que es el campo correspondiente en la colecci\u00f3n clientes.</li> <li>Con la propiedad as, podemos darle un nombre al nuevo campo que contendr\u00e1 la informaci\u00f3n del cliente. En este caso, lo nombramos \"cliente_info\".</li> </ol> <p>Despu\u00e9s de ejecutar esta consulta, obtendr\u00e1s un nuevo campo en cada documento de la colecci\u00f3n ventas llamado \"cliente_info\". Este campo contendr\u00e1 la informaci\u00f3n del cliente al que pertenece la venta, lo que te permite acceder a los datos del cliente directamente desde los documentos de la colecci\u00f3n ventas.</p> <p>Con $lookp tambien podemos hacer un left join deberiamos incluir el parametro \"preserveNullAndEmptyArrays: true\" en el $unwind, tal como muestra el ejemplo:</p> <pre><code>db.productos.aggregate(\n{\n$lookup: {\nfrom: \"ventas\",\nlocalField: \"_id\",\nforeignField: \"producto_id\",\nas: \"datos_ventas\"\n}\n},\n{\n$unwind: {\npath: \"$datos_ventas\",\npreserveNullAndEmptyArrays: true\n}\n}\n)\n</code></pre>"},{"location":"BDA/Tema04/MongoDB/#36-actividades","title":"3.6. Actividades","text":""},{"location":"BDA/Tema04/MongoDB/#361-act_1","title":"3.6.1. Act_1","text":"<p>Vamos a trabajar con dos colecciones: profesores y asignaturas</p> <p>Para importar los datos y subirlos a MongoDB Atlas pod\u00e9is usar este comando: <pre><code>mongoimport --uri 'mongodb+srv://USUARIO:CONTRASE\u00d1A@CLUSTER/BASEDEDATOS?retryWrites=true&amp;w=majority' --collection='asignaturas' --file='asignaturas.json'\n</code></pre> Estas son las consultas propuestas:</p> <p>Insertar, Modificar y Borrar</p> <ol> <li>Listar todos los profesores  // db.profesores.find()</li> <li>Insertar un profesor y una asignatura en la colecci\u00f3n</li> <li>Actualizar la asignatura del profesor que acab\u00e1is de insertar</li> <li>Borrar el profesor que se acaba de insertar</li> <li>Actualizar todas las edades de los profesores en una unidad</li> <li>Usar upsert para a\u00f1adir un nuevo profesor con nombre \u201cAitor\u201d, en caso de que no lo encuentre, a\u00f1ade un campo \u201cPersonal\u201d con valor \u201dFijo\u201d</li> </ol> <p>Filtra, Ordenar y Contar mediante consultas</p> <ol> <li>Listar los profesores mostrando solo los nombres</li> <li>Ordenar por nombre de forma ascendente</li> <li>Ordenar por nombre de forma descendente</li> <li>Limitar a 2 una b\u00fasqueda general sobre la colecci\u00f3n profesores</li> <li>Limitar a 2 intercalando 1 salto entre resultados</li> <li>Contar el n\u00famero de profesores de la colecci\u00f3n</li> <li>Contar el n\u00famero de profesores que se llaman juan</li> </ol> <p>Selectores de consultas</p> <ol> <li>Listar las asignaturas con 23 alumnos</li> <li>Listar las asignaturas con 23 alumnos o m\u00e1s</li> <li>Listar las asignaturas que imparte el profesor Juan</li> <li>Listar las asignaturas que NO imparte el profesor Juan</li> <li>Listar las asignaturas que imparten Juan o Laura </li> <li>Listar las asignaturas que NO imparten ni Juan ni Laura </li> </ol>"},{"location":"BDA/Tema04/MongoDB/#362-act_2","title":"3.6.2. Act_2","text":"<p>Vamos a trabajar con 4 colecciones:</p> <ul> <li>articulos </li> <li>inventario</li> <li>productos</li> <li>calificaciones</li> </ul> <p>Trabajar con textos</p> <ol> <li>Buscar \u201cbacking\u201d en la colecci\u00f3n art\u00edculos</li> <li>Buscar \u201cbacking\u201d y \u201ccoffee\u201d en un mismo comando</li> <li>Buscar \u201cbacking\u201d excluyendo \u201ccoffee\u201d en un mismo comando</li> <li>Buscar la frase completa \u201ccaf\u00e9 con leche</li> <li>Realizar la misma consulta que la anterior pero teniendo en cuenta las tildes</li> <li>Realizar la misma consulta que la anterior pero teniendo en cuenta may\u00fasculas y min\u00fasculas</li> </ol> <p>Operadores con arrays</p> <ol> <li>Buscar todos los registros que en etiquetas tengan cuaderno y libro.</li> <li>Buscar los documentos con arrays de tama\u00f1o 5</li> </ol> <p>Modificadores de actualizaci\u00f3n</p> <ol> <li>Asignarle al producto con _id:1 un precio de 20 si el precio que tiene actualmente es menor</li> <li>Multiplica por dos 2 el precio del producto _id:1</li> </ol> <p>Modificadores de actualizaci\u00f3n de arrays</p> <ol> <li>Eliminar el primer elemento del array de la colecci\u00f3n de calificaciones para el alumno con id=1</li> <li>Eliminar el \u00faltimo elemento de un array</li> <li>Agregar la calificaci\u00f3n 90 al array</li> <li>Eliminar todos las \u201ccalis\u201d coincidentes con 100 y 81 un array se usa pullAll y los valores a buscar se ponen entre corchetes.</li> </ol>"},{"location":"BDA/Tema04/MongoDB/#363-act_3","title":"3.6.3. Act_3","text":"<p>Vamos a trabajar con una colecci\u00f3n de municipios </p> <ol> <li>Muestra el total de varones y de mujeres en la misma consulta</li> <li>Muestra la poblaci\u00f3n de cada provincia (Provincia y Poblaci\u00f3n total) en orden descendente</li> <li>Muestra en orden descendente las provincias (provincia y n\u00famero de poblaciones) con m\u00e1s de 20 de poblaciones cuya altitud sea mayor que 1000</li> </ol>"},{"location":"BDA/Tema04/MongoDB/#364-act_4","title":"3.6.4. Act_4","text":"<p>Utilizando estas colecciones de productos y ventas obten el importe total vendido de cada producto, indicando su nombre y descripi\u00f3n</p> Soluci\u00f3n_1 <pre><code>db.ventas.aggregate(\n{\n$lookup: {\nfrom: \"productos\",\nlocalField: \"producto_id\",\nforeignField: \"_id\",\nas: \"datos_producto\"\n}\n},\n{\n$unwind: \"$datos_producto\"\n},\n{\n$group: {\n_id: {\n_id: \"$producto_id\",\nNombre: \"$datos_producto.nombre\",\nDescripcion: \"$datos_producto.descripcion\"\n},\nTotal: { $sum: \"$total\" }\n}\n},\n{\n$project: {\n_id: 0,\nNombre: \"$_id.Nombre\",\nDescripcion: \"$_id.Descripcion\",\nImporteTotalVendido: \"$Total\"\n}\n}\n)\n</code></pre> Soluci\u00f3n_2 con left join. Incluye los articulos sin ventas <pre><code>db.productos.aggregate(\n{\n$lookup: {\nfrom: \"ventas\",\nlocalField: \"_id\",\nforeignField: \"producto_id\",\nas: \"datos_ventas\"\n}\n},\n{\n$unwind: {\npath: \"$datos_ventas\",\npreserveNullAndEmptyArrays: true\n}\n},\n{\n$group: {\n_id: {\n_id:\"$id\",\nNombre:\"$nombre\",\nDescripcionNombre:\"$descripcion\"\n},\nTotal:  {$sum :\"$datos_ventas.total\"}\n}\n},\n{\n$project: {\n_id: 0,\nNombre: \"$_id.Nombre\",\nDescripcion: \"$_id.Descripcion\",\nImporteTotalVendido: \"$Total\"\n}\n}\n)\n</code></pre>"},{"location":"BDA/Tema05/Almacenamiento/","title":"5. Almacenamiento","text":""},{"location":"BDA/Tema05/Almacenamiento/#51-tipos-de-archivos-en-big-data","title":"5.1  Tipos de Archivos en Big Data","text":""},{"location":"BDA/Tema05/Almacenamiento/#511-clasificaccion-de-los-archivos-en-funcion-del-tipo-de-datos","title":"5.1.1. Clasificacci\u00f3n de los archivos en funci\u00f3n del tipo de datos","text":"Tipo de Datos Descripcion Formatos comunes Ejemplos Observaciones Archivos de Datos Estructurados Datos organizados en un formato con una estructura fija y predefinida, como las tablas de una base de datos relacional. CSV Archivos de hojas de c\u00e1lculo, bases de datos SQL y archivos CSV. Los archivos estructurados son eficientes para almacenar datos tabulares, pero pueden ser menos flexibles para datos variados o no estructurados. Archivos de Datos Semiestructurados No siguen una estructura fija como los datos estructurados, pero tienen cierta organizaci\u00f3n o jerarqu\u00eda, como en el caso de archivos JSON o XML. JSON y XML Archivos JSON que almacenan configuraciones, datos de sensores o informaci\u00f3n de productos. Los datos semiestructurados son ideales para representar informaci\u00f3n jer\u00e1rquica, como configuraciones de aplicaciones o datos de sensores. Archivos de Datos No Estructurados Carecen de una organizaci\u00f3n o formato definido y pueden incluir archivos de im\u00e1genes, videos, documentos de texto sin formato y audio, entre otros. Im\u00e1genes JPEG, videos MP4, documentos de texto sin formato, grabaciones de audio, etc. Se utilizan herramientas de procesamiento de medios, visi\u00f3n por computadora, reconocimiento de voz y an\u00e1lisis de texto para extraer informaci\u00f3n de datos no estructurados. Archivos de Log Registran eventos y actividades, como transacciones, errores o interacciones de usuarios. Herramientas como Splunk, ELK Stack (Elasticsearch, Logstash, Kibana) y Apache Flume se utilizan para analizar y visualizar datos de registros."},{"location":"BDA/Tema05/Almacenamiento/#512-formatos-de-archivos-mas-comunes-en-big-data","title":"5.1.2. Formatos de Archivos M\u00e1s Comunes en Big Data","text":"Formato Descripcion Usos m\u00e1s comunes Avro Avro es un formato de datos que se utiliza para la serializaci\u00f3n de datos y es compatible con m\u00faltiples lenguajes de programaci\u00f3n. Es eficiente, compacto, esquem\u00e1tico y permite la evoluci\u00f3n de esquemas de datos. Avro se utiliza en sistemas de registro y en la comunicaci\u00f3n entre componentes de Big Data. Parquet Parquet es un formato de columna abierto que se utiliza para el almacenamiento eficiente de datos estructurados y semiestructurados. Ofrece compresi\u00f3n eficiente y procesamiento de columnas, lo que lo hace adecuado para an\u00e1lisis de Big Data. Parquet se utiliza en aplicaciones de an\u00e1lisis de datos, como Apache Hive y Apache Impala. ORC ORC (Optimized Row Columnar) es un formato de archivo de columna optimizado para la eficiencia en el almacenamiento y procesamiento de datos. Se compara favorablemente con Parquet y Avro en t\u00e9rminos de eficiencia y velocidad de consulta. ORC se utiliza en sistemas como Apache Hive y proporciona un rendimiento eficiente en consultas anal\u00edticas. Sequence Los archivos Sequence almacenan datos en un formato de secuencia binaria y son adecuados para la entrada y salida de datos de alto rendimiento. Se utilizan para almacenar registros y datos de flujo."},{"location":"BDA/Tema05/Almacenamiento/#513-almacenamiento-de-datos-en-columnas-vs-filas","title":"5.1.3. Almacenamiento de Datos en Columnas vs Filas","text":"<p>El almacenamiento de datos en columnas y en filas son dos enfoques diferentes para organizar y almacenar datos en bases de datos.</p> Almacenamieto En Filas En Columnas Descripcion Cada fila representa una entidad o un registro completo. En operaciones de lectura/escritura de registros completos. Eficiente ara operaciones de actualizaci\u00f3n frecuente de registros individuales. Para operaciones de agregaci\u00f3n y an\u00e1lisis de datos, como consultas OLAP y an\u00e1lisis de datos grandes. No Eficiente Para operaciones de agregaci\u00f3n y an\u00e1lisis de datos que implican m\u00faltiples columnas Para operaciones de actualizaci\u00f3n frecuente de registros individuales. Adecuado Para bases de datos transaccionales y aplicaciones que requieren actualizaciones frecuentes. Para bases de datos anal\u00edticas y almacenes de datos (Data Warehouses). Ejemplo BD Relacionales tradicionales. BD Anal\u00edticas columnares, como Apache Cassandra o Apache HBase. <p>Comparativa con un ejemplo.</p> <p>Si tenemos la siguiente tabla:</p> Name City Age Matt LosAngeles 27 Dave SanFrancisco 30 Tin Oakland 33 <p>En un almacenamiento por Filas los datos se guardan asi:</p> Matt LosAngeles 27 Dave SanFrancisco 30 Tin Oakland 33 <p>En una almacenamiento por Columnas ser\u00eda as\u00ed:</p> Matt Dave Tin Oakland Los Angeles San Francisco 27 30 33 <p>Mas info</p>"},{"location":"BDA/Tema05/Almacenamiento/#52-repositorios","title":"5.2  Repositorios","text":"<p>Un repositorio de Big Data es un sistema de almacenamiento centralizado y gestionado dise\u00f1ado para almacenar, administrar y organizar grandes vol\u00famenes de datos. Estos repositorios se utilizan para reunir y conservar una amplia variedad de datos, incluidos datos estructurados, semiestructurados y no estructurados, con el objetivo de facilitar su posterior an\u00e1lisis y procesamiento.</p> <p>Caracter\u00edsticas:</p> <ol> <li> <p>Escalabilidad: Un repositorio de Big Data debe ser altamente escalable, lo que significa que puede manejar grandes vol\u00famenes de datos a medida que la organizaci\u00f3n crece sin comprometer el rendimiento.</p> </li> <li> <p>Diversidad de Datos: Debe admitir diversos tipos de datos, desde datos estructurados en bases de datos relacionales hasta datos no estructurados como registros de servidores web, documentos de texto, im\u00e1genes, videos y m\u00e1s.</p> </li> <li> <p>Almacenamiento Eficiente: Utiliza t\u00e9cnicas de almacenamiento eficiente para aprovechar al m\u00e1ximo el espacio de almacenamiento y minimizar los costos.</p> </li> <li> <p>Procesamiento Distribuido: Puede trabajar en conjunto con sistemas de procesamiento distribuido, como Hadoop, para permitir el an\u00e1lisis de datos a gran escala.</p> </li> <li> <p>Metadatos y Catalogaci\u00f3n: Proporciona capacidades de gesti\u00f3n de metadatos y catalogaci\u00f3n para facilitar la b\u00fasqueda y el acceso a los datos almacenados.</p> </li> <li> <p>Seguridad y Control de Acceso: Debe ofrecer mecanismos de seguridad para proteger los datos almacenados y controlar el acceso a los mismos.</p> </li> <li> <p>Almacenamiento en Bruto: Los datos se almacenan en su forma original, lo que permite su conservaci\u00f3n sin procesar para an\u00e1lisis posteriores.</p> </li> <li> <p>Integraci\u00f3n con Herramientas de An\u00e1lisis: Debe ser compatible con una variedad de herramientas y tecnolog\u00edas de an\u00e1lisis de datos para permitir el procesamiento y an\u00e1lisis de datos de manera eficiente.</p> </li> <li> <p>Tolerancia a Fallos: Debe estar dise\u00f1ado para ser tolerante a fallos y garantizar la disponibilidad y confiabilidad de los datos.</p> </li> </ol> <p>Herramientas:</p> <ol> <li>Apache HDFS (Hadoop Distributed File System):</li> <li> <p>Descripci\u00f3n: HDFS es el sistema de archivos distribuido de Hadoop y se utiliza para almacenar grandes conjuntos de datos de manera distribuida. Es fundamental en el ecosistema Hadoop.</p> </li> <li> <p>Apache Cassandra:</p> </li> <li> <p>Descripci\u00f3n: Cassandra es una base de datos distribuida altamente escalable y sin un solo punto de fallo. Es especialmente buena para escribir y leer grandes cantidades de datos en un entorno distribuido.</p> </li> <li> <p>Amazon S3 (Simple Storage Service):</p> </li> <li> <p>Descripci\u00f3n: No es una herramienta de c\u00f3digo abierto, pero es una opci\u00f3n popular en la nube para el almacenamiento de datos a gran escala. Amazon S3 es un servicio de almacenamiento de objetos que puede gestionar grandes cantidades de datos.</p> </li> <li> <p>Azure Data Lake Storage:</p> </li> <li> <p>Descripci\u00f3n: Azure Data Lake Storage es un servicio de almacenamiento escalable y seguro para big data. Permite almacenar y analizar grandes cantidades de datos de manera eficiente. Puedes usarlo en conjunto con otras herramientas y servicios de Azure.</p> </li> <li> <p>Azure Databricks:</p> </li> <li> <p>Descripci\u00f3n: Azure Databricks es una plataforma de an\u00e1lisis de big data basada en Apache Spark. Ofrece un entorno colaborativo para cient\u00edficos de datos, ingenieros y analistas para procesar y analizar grandes conjuntos de datos.</p> </li> <li> <p>Azure Blob Storage:</p> </li> <li>Descripci\u00f3n: Aunque no es espec\u00edfico de big data, Azure Blob Storage es un servicio de almacenamiento de objetos en la nube que puede utilizarse para almacenar grandes cantidades de datos, y es com\u00fanmente utilizado en entornos de big data.</li> </ol>"},{"location":"BDA/Tema05/Almacenamiento/#53-cubos-olap","title":"5.3  Cubos OLAP","text":"<p>OLAP es una tecnolog\u00eda que permite a los usuarios realizar an\u00e1lisis multidimensionales de datos. Proporciona una vista r\u00e1pida y flexible de los datos a trav\u00e9s de un modelo multidimensional.</p>"},{"location":"BDA/Tema05/Almacenamiento/#531-fundamentos-de-cubos-olap","title":"5.3.1. Fundamentos de Cubos OLAP","text":"<p>Los cubos OLAP representan datos en m\u00faltiples dimensiones, lo que permite una vista rica y flexible de los datos. Las dimensiones pueden ser atributos como tiempo, producto o ubicaci\u00f3n.</p> <p></p> <p>Los modelos  de datos en los cubos OLAP son Estrella y Copo de Nieve. En el modelo de estrella, los datos se organizan en una tabla de hechos central con dimensiones relacionadas. En el modelo de copo de nieve, las dimensiones se normalizan en varias tablas, lo que reduce la redundancia de datos.</p> <p>Los cubos OLAP ofrecen un rendimiento superior para consultas anal\u00edticas, son ideales para datos multidimensionales y facilitan el an\u00e1lisis interactivo de datos.</p>"},{"location":"BDA/Tema05/Almacenamiento/#532-tipos-de-cubos-olap","title":"5.3.2.  Tipos de Cubos OLAP","text":"<ul> <li>Cubos MOLAP (Multidimensional OLAP): Almacenan datos preagregados en una estructura multidimensional optimizada para consultas. Ejemplo: Microsoft Analysis Services: </li> <li>Cubos ROLAP (Relational OLAP): Utilizan bases de datos relacionales subyacentes para almacenar datos multidimensionales. Ejemplos: SAP BW (SAP Business Warehouse) y Oracle OLAP.</li> <li>Cubos HOLAP (Hybrid OLAP): Combinan caracter\u00edsticas de MOLAP y ROLAP para equilibrar el rendimiento y la flexibilidad. Ejemplo: Microsoft SQL Server Analysis Services (HOLAP)</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#533-dimensiones-y-medidas","title":"5.3.3.  Dimensiones y Medidas","text":"<p>Las dimensiones son atributos por los cuales se puede analizar un conjunto de datos, mientras que las medidas representan los valores num\u00e9ricos a analizar, como ventas, ingresos, cantidad de productos, etc.</p> <p>Ejemplos de Dimensiones: Tiempo (d\u00eda, mes, a\u00f1o), producto (categor\u00eda, marca), ubicaci\u00f3n (ciudad, pa\u00eds) y m\u00e1s.</p> <p>Ejemplos de Medidas: Ventas, ingresos, cantidad de productos vendidos, entre otros.</p>"},{"location":"BDA/Tema05/Almacenamiento/#534-herramientas-olap","title":"5.3.4.  Herramientas OLAP","text":"<p>Ejemplos de Herramientas y Sistemas OLAP Populares: </p> <ul> <li>Mondrian</li> <li>Microsoft Analysis Services</li> <li>IBM Cognos </li> </ul> <p>Estas herramientas proporcionan interfaces de usuario para crear y explorar cubos OLAP.</p>"},{"location":"BDA/Tema05/Almacenamiento/#535-integracion-con-big-data","title":"5.3.5.  Integraci\u00f3n con Big Data","text":"<p>Los cubos OLAP son esenciales para analizar grandes vol\u00famenes de datos, ya que permiten un acceso eficiente a datos multidimensionales. Pero se requiere la preparaci\u00f3n y transformaci\u00f3n de datos a partir de fuentes de datos antes de cargarlos en cubos OLAP.</p>"},{"location":"BDA/Tema05/Almacenamiento/#54-data-warehouse","title":"5.4  Data Warehouse","text":""},{"location":"BDA/Tema05/Almacenamiento/#541-definicion","title":"5.4.1. Definici\u00f3n","text":"<p>Un Data Warehouse es un sistema de almacenamiento de datos dise\u00f1ado para consolidar, limpiar y estructurar datos empresariales de diversas fuentes con el fin de facilitar el an\u00e1lisis y la generaci\u00f3n de informes.</p> <p>Los Data Warehouses desempe\u00f1an un papel fundamental en la consolidaci\u00f3n de datos de m\u00faltiples fuentes en un \u00fanico repositorio centralizado, lo que facilita el acceso y la toma de decisiones basadas en datos.</p> <p></p>"},{"location":"BDA/Tema05/Almacenamiento/#542-caracteristicas-clave","title":"5.4.2. Caracter\u00edsticas Clave","text":"<ul> <li>Estructura de Datos: Los datos se almacenan de manera organizada en tablas relacionales que permiten la consulta y an\u00e1lisis eficiente.</li> <li>Procesamiento de Datos: Los datos se someten a procesos de extracci\u00f3n, transformaci\u00f3n y carga (ETL) para limpiar, transformar y estructurar los datos para su an\u00e1lisis.</li> <li>Orientado a la Toma de Decisiones: Los Data Warehouses est\u00e1n dise\u00f1ados para admitir consultas, an\u00e1lisis y generaci\u00f3n de informes que respalden la toma de decisiones empresariales.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#543-componentes-de-un-data-warehouse","title":"5.4.3. Componentes de un Data Warehouse","text":"<ol> <li> <p>Datos de Origen (Data Sources):</p> <ul> <li>Representan las diversas fuentes de datos de la empresa. Pueden incluir bases de datos operativas, archivos planos, datos de redes sociales, registros de transacciones, entre otros.</li> </ul> </li> <li> <p>Proceso de Extracci\u00f3n, Transformaci\u00f3n y Carga (ETL):</p> <ul> <li>Este proceso es crucial para la integraci\u00f3n de datos. Incluye:<ul> <li>Extracci\u00f3n (Extract): Obtenci\u00f3n de datos desde las fuentes de origen.</li> <li>Transformaci\u00f3n (Transform): Limpieza, normalizaci\u00f3n y transformaci\u00f3n de datos para que sean coherentes y \u00fatiles.</li> <li>Carga (Load): Almacenamiento de datos transformados en el data warehouse.</li> </ul> </li> </ul> </li> <li> <p>Almac\u00e9n de Datos (Data Warehouse):</p> <ul> <li>Es el repositorio central donde se almacenan los datos consolidados y transformados. El almac\u00e9n de datos suele tener una estructura espec\u00edfica para facilitar el an\u00e1lisis, como un esquema dimensional o esquema en estrella.</li> </ul> </li> <li> <p>Esquema Dimensional:</p> <ul> <li>Es una estructura organizativa de datos que permite un acceso r\u00e1pido y eficiente a los datos en el data warehouse. Incluye dimensiones (aspectos de inter\u00e9s, como tiempo, producto, ubicaci\u00f3n) y hechos (n\u00fameros cuantificables, como ingresos, unidades vendidas).</li> </ul> </li> <li> <p>Herramientas de Consulta y Reporting:</p> <ul> <li>Permiten a los usuarios ejecutar consultas y generar informes basados en los datos almacenados en el data warehouse. Ejemplos incluyen SQL para consultas directas y herramientas de reporting como Tableau, Power BI, etc.</li> </ul> </li> <li> <p>Herramientas de Visualizaci\u00f3n:</p> <ul> <li>Ayudan a presentar los datos de manera comprensible a trav\u00e9s de gr\u00e1ficos, tablas, dashboards, etc. Estas herramientas permiten a los usuarios analizar los datos de manera m\u00e1s efectiva.</li> </ul> </li> <li> <p>Metadatos:</p> <ul> <li>Informaci\u00f3n sobre los datos almacenados en el data warehouse, como definiciones de tablas, descripciones de campos y detalles sobre la transformaci\u00f3n de datos. Los metadatos son esenciales para comprender y gestionar eficazmente la informaci\u00f3n almacenada.</li> </ul> </li> <li> <p>Seguridad y Control de Acceso:</p> <ul> <li>Mecanismos para garantizar que solo las personas autorizadas tengan acceso a ciertos datos. Esto incluye controles de acceso, cifrado y auditor\u00eda.</li> </ul> </li> <li> <p>Backup y Recuperaci\u00f3n:</p> <ul> <li>Procesos y pol\u00edticas para realizar copias de seguridad regulares de los datos almacenados en el data warehouse y procedimientos para recuperar datos en caso de p\u00e9rdida.</li> </ul> </li> <li> <p>Gesti\u00f3n de Rendimiento:</p> <ul> <li>Estrategias y herramientas para optimizar el rendimiento del data warehouse, como la indexaci\u00f3n adecuada, el particionamiento de tablas y la optimizaci\u00f3n de consultas.</li> </ul> </li> </ol>"},{"location":"BDA/Tema05/Almacenamiento/#544-herramientas","title":"5.4.4. Herramientas:","text":"<ul> <li>Amazon Redshift: Data Warehouse de alto rendimiento en la nube de AWS.</li> <li>Google BigQuery: Data Warehouse completamente administrado en la nube de GCP.</li> <li>Snowflake: Plataforma de Data Warehouse en la nube.</li> <li>Microsoft Azure Synapse Analytics (anteriormente Azure SQL Data Warehouse): Data Warehouse de Azure.</li> <li>Oracle Exadata: Soluci\u00f3n de Data Warehouse de Oracle.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#55-data-lake","title":"5.5  Data Lake","text":""},{"location":"BDA/Tema05/Almacenamiento/#551-definicion","title":"5.5.1. Definici\u00f3n","text":"<p>Un Data Lake es un sistema de almacenamiento de datos que permite la ingesta y almacenamiento de datos en su forma bruta y sin procesar, sin la necesidad de una estructura de datos fija. Puede contener datos de diversas fuentes y formatos.</p> <p>El Data Lake desempe\u00f1a un papel fundamental al permitir la ingesti\u00f3n y el almacenamiento de datos en bruto desde diversas fuentes, lo que facilita el acceso y el an\u00e1lisis de datos en su forma original.</p> <p></p>"},{"location":"BDA/Tema05/Almacenamiento/#552-caracteristicas-clave","title":"5.5.2. Caracter\u00edsticas Clave","text":"<ul> <li>Almacenamiento en Bruto: Los datos se almacenan en su forma original, sin procesar ni estructurar previamente.</li> <li>Escalabilidad: Los Data Lakes son altamente escalables y pueden manejar grandes vol\u00famenes de datos, lo que los hace adecuados para Big Data.</li> <li>Variedad de Datos: Pueden contener datos estructurados, semiestructurados y no estructurados, lo que les brinda flexibilidad en la gesti\u00f3n de datos diversos.</li> <li>Flexibilidad: No se requiere una estructura de datos fija, lo que permite experimentar con diferentes tipos de datos y esquemas.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#553-componentes-de-un-data-lake","title":"5.5.3. Componentes de un Data Lake","text":"<p>Almacenamiento de Datos Los datos se almacenan generalmente en sistemas de archivos distribuidos como Hadoop HDFS o en servicios en la nube, lo que proporciona una capacidad de almacenamiento escalable.</p> <p>Ingesta de Datos Los datos se pueden ingresar mediante carga por lotes, transmisi\u00f3n en tiempo real y la ingesti\u00f3n de datos en bruto, lo que permite la adquisici\u00f3n continua de datos.</p>"},{"location":"BDA/Tema05/Almacenamiento/#554-datos-en-un-data-lake","title":"5.5.4. Datos en un Data Lake","text":"<p>En un Data Lake tenemos todos los tipos de datos posibles:</p> <ul> <li>Datos Estructurados: Esto incluye archivos CSV o JSON que se almacenan sin procesar y conservan su estructura original.</li> <li>Datos Semiestructurados: Ejemplos son documentos XML o JSON que pueden no cumplir con una estructura r\u00edgida.</li> <li>Datos No Estructurados: Esto abarca datos como im\u00e1genes, audio o texto sin formato que no siguen una estructura espec\u00edfica.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#56-data-lakehouse","title":"5.6  Data LakeHouse","text":""},{"location":"BDA/Tema05/Almacenamiento/#561-definicion","title":"5.6.1 Definici\u00f3n","text":"<p>Un Data Lakehouse es un sistema de gesti\u00f3n de datos que combina las ventajas de los Data Warehouses y los Data Lakes. Al igual que un Data Lake, almacena datos en su forma bruta, pero aporta capacidades de procesamiento integrado y consultas eficientes, lo que permite un an\u00e1lisis m\u00e1s r\u00e1pido. Combina la escalabilidad de un Data Lake con el rendimiento mejorado de un Data Warehouse.</p> <p>El Data Lakehouse introduce capacidades transaccionales, permitiendo operaciones de escritura m\u00e1s controladas, lo que facilita el mantenimiento de la integridad y consistencia de los datos.</p> <p></p>"},{"location":"BDA/Tema05/Almacenamiento/#562-caracteristicas-clave","title":"5.6.2 Caracter\u00edsticas Clave","text":"<ul> <li>Almacenamiento en Bruto: Al igual que en un Data Lake, los datos se almacenan en su forma original y sin procesar.</li> <li>Procesamiento Integrado: Ofrece capacidades de procesamiento integrado para consultas y an\u00e1lisis m\u00e1s eficientes.</li> <li>Escalabilidad: Mantiene la escalabilidad de un Data Lake, lo que permite manejar grandes vol\u00famenes de datos.</li> <li>Rendimiento Mejorado: Combina el rendimiento de un Data Warehouse con la flexibilidad de un Data Lake.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#563-componentes-de-un-data-lakehouse","title":"5.6.3 Componentes de un Data Lakehouse","text":"<ul> <li>Almacenamiento de Datos: Los datos se almacenan generalmente utilizando sistemas de archivos distribuidos o servicios en la nube, manteniendo la capacidad de escalabilidad.</li> <li>Procesamiento de Datos: Permite consultas anal\u00edticas y generaci\u00f3n de informes de manera eficiente.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#564-modelo-de-datos","title":"5.6.4  Modelo de Datos","text":"<p>Almacenamiento en Bruto: Al igual que en un Data Lake los datos se almacenan en su forma original sin procesar, lo que permite la conservaci\u00f3n de datos en bruto para futuros an\u00e1lisis.</p> <p>Modelo de Datos Estructurados: Estructuraci\u00f3n de Datos cuando sea Necesario. Aunque los datos se almacenan en bruto, es posible aplicar esquemas de datos para estructurarlos seg\u00fan las necesidades.</p>"},{"location":"BDA/Tema05/Almacenamiento/#565-consultas-y-analisis","title":"5.6.5  Consultas y An\u00e1lisis","text":"<ul> <li>Los usuarios pueden realizar consultas SQL y utilizar tecnolog\u00eda OLAP para el an\u00e1lisis de datos multidimensionales. Adem\u00e1s, se facilita la generaci\u00f3n de informes y el an\u00e1lisis para la toma de decisiones empresariales.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#566-herramientas","title":"5.6.6  Herramientas:","text":"<ul> <li>Delta Lake: Biblioteca de c\u00f3digo abierto que agrega confiabilidad transaccional a los Data Lakes.</li> <li>Apache Iceberg: Otra biblioteca de c\u00f3digo abierto para tablas de datos en Data Lakes.</li> <li>Databricks Delta: Soluci\u00f3n de Data Lakehouse ofrecida por Databricks, que es una plataforma de an\u00e1lisis de datos basada en Apache Spark.</li> <li>Apache Hive: Un sistema de almacenamiento y procesamiento de datos de c\u00f3digo abierto basado en Hadoop que se puede usar tanto en Data Lakes como en Data Warehouses.</li> <li>Google Cloud Bigtable: Base de datos distribuida NoSQL de alto rendimiento de GCP, que se puede utilizar como parte de una arquitectura de Data Lakehouse.akehouse2.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#57-comparacion","title":"5.7. Comparaci\u00f3n","text":"Data Warehouse Data Lake Data Lakehouse Arquitectura Enfocada en el procesamiento de datos estructurados. Almacenamiento de datos en bruto sin procesar. Combina almacenamiento en bruto y procesamiento en un solo sistema. Datos Limpios, procesados y estructurados. En bruto, no procesados y pueden ser estructurados, semiestructurados o no estructurados. Estructurados y sin procesar, pero con la capacidad de procesamiento. Escalabilidad Suele ser m\u00e1s limitada en comparaci\u00f3n con Data Lakes y Lakehouses. Altamente escalable, puede manejar grandes vol\u00famenes de datos. Combina la escalabilidad de Data Lakes con capacidades de procesamiento. Rendimiento R\u00e1pido para consultas anal\u00edticas complejas en datos estructurados. M\u00e1s lento para consultas debido a la necesidad de procesamiento. Ofrece un equilibrio entre rendimiento y capacidad de procesamiento. Uso y Aplicaciones An\u00e1lisis de datos estructurados y m\u00e9tricas empresariales. Almacenamiento y procesamiento de datos brutos, experimentaci\u00f3n de datos. An\u00e1lisis de datos estructurados y no estructurados, aplicaciones h\u00edbridas."},{"location":"BDA/Tema05/Almacenamiento/#58-gobernanza-de-datos","title":"5.8. Gobernanza de datos","text":"<p>La gobernanza de datos se refiere al conjunto de procesos, pol\u00edticas, est\u00e1ndares y procedimientos que garantizan la calidad, integridad, seguridad, privacidad y cumplimiento normativo de los datos en una organizaci\u00f3n.Es esencial para garantizar que los datos sean confiables, precisos y seguros. Adem\u00e1s, es fundamental para cumplir con regulaciones de privacidad y normativas espec\u00edficas de la industria.</p> <p>Los datos son activos cr\u00edticos para las organizaciones y son la base de la toma de decisiones. La gesti\u00f3n adecuada de los datos es esencial para el \u00e9xito empresarial.</p> <p>Una s\u00f3lida gobernanza de datos conlleva beneficios como datos confiables, toma de decisiones informada y cumplimiento normativo, lo que mejora la eficiencia y la competitividad de la organizaci\u00f3n.</p>"},{"location":"BDA/Tema05/Almacenamiento/#581-componentes-clave-de-la-gobernanza-de-datos","title":"5.8.1. Componentes Clave de la Gobernanza de Datos","text":"<p>Pol\u00edticas y Procedimientos</p> <ul> <li>Establecer pol\u00edticas que rigen la gesti\u00f3n, calidad, privacidad y seguridad de los datos en la organizaci\u00f3n.</li> <li>Definir procesos y est\u00e1ndares que aseguren el cumplimiento de las pol\u00edticas.</li> <li>Supervisar y hacer cumplir las pol\u00edticas de datos para garantizar la conformidad.</li> </ul> <p>Metadatos</p> <ul> <li>Los metadatos describen los datos, su origen, estructura y significado, lo que facilita la gesti\u00f3n y el rastreo de los datos.</li> <li>Los metadatos son esenciales para catalogar, buscar y entender los datos.</li> <li>Los diccionarios de datos y los cat\u00e1logos de metadatos ayudan a organizar y acceder a informaci\u00f3n sobre los datos.</li> </ul> <p>Data Owners y Data Stewards</p> <p>Son los propietarios de los datos que establecen la direcci\u00f3n estrat\u00e9gica y la toma de decisiones en torno a los datos.</p> <p>Los data Stewards son los responsables de los datos y se centran en la implementaci\u00f3n opertiva y en garantiza que los datos cumplan los est\u00e1ndares y pol\u00edticas establecidas.</p> <p>Calidad de Datos</p> <ul> <li>Evaluar la calidad de los datos y tomar medidas para mejorarla.</li> <li>T\u00e9cnicas para Identificar y Resolver Problemas de Calidad de Datos: Utilizar t\u00e9cnicas como la validaci\u00f3n, limpieza y estandarizaci\u00f3n de datos.</li> <li>Monitorizaci\u00f3n continua para garantizar la calidad de los datos.</li> </ul> <p>Seguridad y Privacidad de Datos</p> <ul> <li>Implementar medidas de seguridad para proteger datos confidenciales y sensibles.</li> <li>Cumplir con regulaciones como el RGPD (Reglamento General de Protecci\u00f3n de Datos) para garantizar la privacidad de los datos.</li> <li>Establecer controles de acceso y permisos para garantizar que solo las personas autorizadas puedan acceder a los datos.</li> </ul> <p>Cumplimiento Normativo</p> <ul> <li>Asegurarse de que los datos cumplan con regulaciones espec\u00edficas de la industria en la que opera la organizaci\u00f3n.</li> <li>Mantener registros y documentaci\u00f3n que demuestren el cumplimiento de las regulaciones.</li> <li>Comprender las sanciones por incumplimiento y riesgos asociados.</li> </ul>"},{"location":"BDA/Tema05/Almacenamiento/#59-actividades","title":"5.9. Actividades","text":""},{"location":"BDA/Tema05/Almacenamiento/#591-actividad-1","title":"5.9.1. Actividad 1","text":"<p>La empresa ABC Retail tiene indetificados los siguiente requisitos:</p> <ul> <li>Necesidad de analizar las ventas por regi\u00f3n, producto y per\u00edodo de tiempo.</li> <li>Seguimiento del rendimiento de los empleados de ventas.</li> <li>An\u00e1lisis de inventario y gesti\u00f3n de existencias.</li> <li>Identificaci\u00f3n de tendencias de compras de clientes.</li> </ul> <p>Se pide: </p> <ol> <li> <p>Dise\u00f1o del Esquema Dimensional:</p> <ul> <li>Dise\u00f1a un esquema dimensional que refleje la estructura de datos necesaria para satisfacer los requisitos identificados. Debe incluir dimensiones y hechos relevantes para la empresa imaginaria.</li> </ul> </li> <li> <p>Selecci\u00f3n de Herramientas y Tecnolog\u00edas:</p> <ul> <li>Investigaci\u00f3n y selecci\u00f3n de las herramientas y tecnolog\u00edas que utilizar\u00e1n para implementar el data warehouse. Puedes considerar opciones como bases de datos anal\u00edticas, herramientas de ETL (Extract, Transform, Load), y herramientas de visualizaci\u00f3n.</li> </ul> </li> <li> <p>Creaci\u00f3n de un Modelo L\u00f3gico y F\u00edsico:</p> <ul> <li>Crea un modelo l\u00f3gico y f\u00edsico del data warehouse. El modelo l\u00f3gico puede representar las relaciones entre las tablas, mientras que el modelo f\u00edsico debe considerar aspectos de rendimiento y optimizaci\u00f3n.</li> </ul> </li> <li> <p>Desarrollo de Proceso ETL:</p> <ul> <li>Implementa un proceso ETL para cargar datos desde las fuentes de origen hasta el data warehouse. Esto incluye la extracci\u00f3n de datos, su transformaci\u00f3n seg\u00fan las necesidades y la carga en el data warehouse.</li> </ul> </li> <li> <p>Creaci\u00f3n de Reportes y Dashboards:</p> <ul> <li>Crea al menos dos reportes y un dashboard utilizando herramientas de visualizaci\u00f3n. Estos deben demostrar c\u00f3mo se pueden responder las preguntas anal\u00edticas identificadas en los requisitos.</li> </ul> </li> </ol>"},{"location":"BDA/Tema05/Almacenamiento/#592-actividad-2","title":"5.9.2. Actividad 2","text":"<p>Dado el siguiente caso de estudio:</p> <p>Un hospital est\u00e1 buscando implementar un sistema de gesti\u00f3n de datos m\u00e1s eficiente para abordar los desaf\u00edos de la diversidad de datos m\u00e9dicos, como registros de pacientes, resultados de pruebas, im\u00e1genes m\u00e9dicas, informes de laboratorio, etc. El objetivo es mejorar la accesibilidad, la seguridad y la capacidad de an\u00e1lisis de estos datos para mejorar la atenci\u00f3n al paciente, la investigaci\u00f3n m\u00e9dica y la eficiencia operativa.</p> <ol> <li>Anal\u00edzalo e identifica los desaf\u00edos que podr\u00edan enfrentar y discute c\u00f3mo un Data Lake podr\u00eda abordar esos desaf\u00edos.</li> <li>Recopila informaci\u00f3n sobre la arquitectura t\u00edpica de un Data Lake.</li> <li>Dise\u00f1a la arquitectura de un Data Lake para esa empresa, identificando componentes clave, herramientas utilizadas y c\u00f3mo abordar\u00edan los desaf\u00edos espec\u00edficos del escenario.</li> <li>Presenta tu dise\u00f1o conceptual al resto de la clase.</li> </ol>"},{"location":"BDA/Tema05/HerramientasDataLake/","title":"HerramientasDataLake","text":""},{"location":"BDA/Tema05/HerramientasDataLake/#555-herramientas","title":"5.5.5. Herramientas","text":"<ul> <li>Apache Hadoop: Plataforma de almacenamiento y procesamiento distribuido.</li> <li>Apache HDFS: Sistema de archivos distribuido de Hadoop.</li> <li>Amazon S3: Servicio de almacenamiento en la nube de Amazon Web Services (AWS).</li> <li>Google Cloud Storage: Servicio de almacenamiento en la nube de Google Cloud Platform (GCP).</li> <li>Azure Data Lake Storage: Servicio de almacenamiento en la nube de Microsoft Azure.</li> </ul> <p>Los elementos de una arquitectura de data lake son los siguientes:</p> <ul> <li>Fuentes de datos: Las fuentes de datos son los or\u00edgenes de los datos que se almacenar\u00e1n en el data lake. Pueden ser de una variedad de tipos, incluyendo sistemas de bases de datos, archivos, sensores y aplicaciones.</li> <li>Ingesta de datos: La ingesta de datos es el proceso de mover los datos de las fuentes al data lake. Puede ser manual o automatizado.</li> <li>Almacenamiento: El almacenamiento es el componente fundamental de un data lake. Debe ser capaz de almacenar grandes cantidades de datos de diferentes fuentes y formatos.<ul> <li>Zona Cruda (Raw Zone):Es la capa inicial del Data Lake donde se almacenan los datos en su formato original, sin procesar ni transformar.</li> <li>Zona de Procesamiento: En esta capa, los datos de la zona cruda se procesan y transforman seg\u00fan las necesidades del usuario o de los casos de uso espec\u00edficos.</li> <li>Zona de Presentaci\u00f3n (Serving Layer): Almacena datos listos para el consumo, optimizados para consultas y an\u00e1lisis.</li> </ul> </li> <li>Procesamiento y an\u00e1lisis: El procesamiento y an\u00e1lisis es el proceso de preparar los datos para su uso. Esto puede implicar la limpieza, transformaci\u00f3n y estructuraci\u00f3n de los datos.</li> <li>Gesti\u00f3n: La gesti\u00f3n es el proceso de administrar un data lake. Esto incluye tareas como la seguridad, el control de acceso y el monitoreo de rendimiento.</li> </ul> <p>Adem\u00e1s de estos elementos principales, los data lakes pueden incluir otros componentes, como:</p> <ul> <li>Infraestructura de datos: La infraestructura de datos incluye los servidores, los sistemas de almacenamiento y las redes que se utilizan para ejecutar el data lake.</li> <li>Herramientas de colaboraci\u00f3n: Las herramientas de colaboraci\u00f3n permiten a los usuarios trabajar juntos en el data lake.</li> <li>Herramientas de visualizaci\u00f3n: Las herramientas de visualizaci\u00f3n permiten a los usuarios visualizar los datos del data lake.</li> </ul>"},{"location":"SBD/IndiceSBD/","title":"Sistemas Big Data","text":""},{"location":"SBD/IndiceSBD/#temas","title":"Temas","text":"<ul> <li>T1 Big Data con AWS </li> <li>T2 Infraestructura AWS </li> <li>T3 Seguridad en AWS </li> <li>T4 Inform\u00e1tica AWS </li> <li>T12 AWS </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/","title":"Documentaci\u00f3n: Amazon Simple Storage Service (Amazon S3)","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#introduccion-a-amazon-s3","title":"Introducci\u00f3n a Amazon S3","text":"<p>Amazon Simple Storage Service (Amazon S3) es un servicio de almacenamiento en la nube escalable y duradero que permite almacenar y recuperar datos en cualquier momento desde cualquier ubicaci\u00f3n en la web. Amazon S3 es ampliamente utilizado para el almacenamiento de objetos, copias de seguridad, distribuci\u00f3n de contenido y como componente central de muchas aplicaciones en la nube.</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#conceptos-clave-de-amazon-s3","title":"Conceptos Clave de Amazon S3","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#1-buckets","title":"1. Buckets","text":"<ul> <li>Buckets: Un bucket de Amazon S3 es un contenedor para almacenar objetos. Los objetos se almacenan en buckets y deben tener un nombre \u00fanico en todo Amazon S3.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#2-objetos","title":"2. Objetos","text":"<ul> <li>Objetos: Los objetos son unidades de datos que se almacenan en buckets. Un objeto puede ser cualquier tipo de archivo, como documentos, im\u00e1genes, videos y m\u00e1s.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#3-regiones","title":"3. Regiones","text":"<ul> <li>Regiones: Amazon S3 est\u00e1 disponible en m\u00faltiples regiones de todo el mundo. Puedes seleccionar la regi\u00f3n que mejor se adapte a tus necesidades de rendimiento y cumplimiento.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#4-clases-de-almacenamiento","title":"4. Clases de Almacenamiento","text":"<ul> <li>Clases de Almacenamiento: Amazon S3 ofrece diversas clases de almacenamiento, como S3 Standard, S3 Intelligent-Tiering, S3 Glacier, S3 Glacier Deep Archive, entre otras, cada una dise\u00f1ada para diferentes casos de uso y costos.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#5-control-de-acceso","title":"5. Control de Acceso","text":"<ul> <li>Control de Acceso: Puedes definir pol\u00edticas de control de acceso para determinar qui\u00e9n puede acceder y qu\u00e9 acciones pueden realizar en tus buckets y objetos.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#configuracion-y-uso-basico-de-amazon-s3","title":"Configuraci\u00f3n y Uso B\u00e1sico de Amazon S3","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#1-creacion-de-un-bucket","title":"1. Creaci\u00f3n de un Bucket","text":"<ul> <li>Desde la Consola de AWS, puedes crear un nuevo bucket y seleccionar su regi\u00f3n.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#2-carga-de-objetos","title":"2. Carga de Objetos","text":"<ul> <li>Puedes cargar objetos en tu bucket utilizando la Consola de AWS, la AWS CLI o SDKs.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#3-acceso-a-objetos","title":"3. Acceso a Objetos","text":"<ul> <li>Puedes configurar permisos de acceso a objetos para definir qui\u00e9n puede ver y descargar los objetos.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#4-versiones-de-objetos","title":"4. Versiones de Objetos","text":"<ul> <li>Amazon S3 admite versiones de objetos, lo que permite mantener un historial de cambios en los objetos.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#5-almacenamiento-de-datos","title":"5. Almacenamiento de Datos","text":"<ul> <li>Utiliza las clases de almacenamiento adecuadas seg\u00fan tus requisitos de rendimiento y costo.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#casos-de-uso-comunes-de-amazon-s3","title":"Casos de Uso Comunes de Amazon S3","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#1-almacenamiento-de-copias-de-seguridad","title":"1. Almacenamiento de Copias de Seguridad","text":"<ul> <li>Utiliza Amazon S3 para almacenar copias de seguridad de tus datos y sistemas cr\u00edticos.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#2-distribucion-de-contenido-estatico","title":"2. Distribuci\u00f3n de Contenido Est\u00e1tico","text":"<ul> <li>Almacena y distribuye contenido web est\u00e1tico, como im\u00e1genes y archivos CSS, para mejorar la velocidad de carga de tu sitio web.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#3-almacenamiento-de-datos-para-aplicaciones","title":"3. Almacenamiento de Datos para Aplicaciones","text":"<ul> <li>Almacena datos de aplicaciones y archivos generados por usuarios en Amazon S3.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#4-almacenamiento-de-datos-para-analisis","title":"4. Almacenamiento de Datos para An\u00e1lisis","text":"<ul> <li>Almacena datos para an\u00e1lisis y procesamiento posterior utilizando servicios de AWS como Amazon Redshift y Amazon Athena.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#recomendaciones-de-seguridad","title":"Recomendaciones de Seguridad","text":"<ul> <li>Configuraci\u00f3n de Control de Acceso: Limita el acceso a tus buckets y objetos utilizando pol\u00edticas y ACLs.</li> <li>Cifrado de Datos: Habilita el cifrado de datos en reposo y en tr\u00e1nsito para proteger la confidencialidad de tus datos.</li> <li>Versionado de Objetos: Utiliza la funci\u00f3n de versionado de objetos para mantener un historial de cambios.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#ayuda-y-documentacion","title":"Ayuda y Documentaci\u00f3n","text":"<p>Amazon S3 ofrece documentaci\u00f3n completa en la p\u00e1gina oficial de AWS. Tambi\u00e9n puedes utilizar la AWS CLI y SDKs para interactuar program\u00e1ticamente con Amazon S3.</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#conclusion","title":"Conclusion","text":"<p>Amazon Simple Storage Service (Amazon S3) es un servicio de almacenamiento vers\u00e1til y altamente escalable que se utiliza en una amplia variedad de aplicaciones y casos de uso. Con la capacidad de almacenar, proteger y distribuir datos de manera confiable, Amazon S3 es un componente esencial de la infraestructura en la nube de AWS. Explora Amazon S3 para almacenar y administrar tus datos en la nube de forma eficiente y segura.</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#documentacion-ampliada-amazon-simple-storage-service-amazon-s3","title":"Documentaci\u00f3n Ampliada: Amazon Simple Storage Service (Amazon S3)","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#amazon-s3-clases-de-almacenamiento","title":"Amazon S3: Clases de Almacenamiento","text":"<p>Amazon S3 ofrece una variedad de clases de almacenamiento para satisfacer diferentes requisitos de rendimiento, costo y retenci\u00f3n de datos. Cada clase de almacenamiento est\u00e1 dise\u00f1ada para casos de uso espec\u00edficos. A continuaci\u00f3n, se explican las principales clases de almacenamiento de Amazon S3:</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#1-s3-standard","title":"1. S3 Standard","text":"<ul> <li> <p>Descripci\u00f3n: Esta es la clase de almacenamiento predeterminada de Amazon S3 y ofrece un alto rendimiento y durabilidad. Los datos almacenados en S3 Standard est\u00e1n disponibles de inmediato y se replican autom\u00e1ticamente en m\u00faltiples zonas de disponibilidad.</p> </li> <li> <p>Casos de Uso: Almacenamiento de datos cr\u00edticos para aplicaciones en l\u00ednea, distribuci\u00f3n de contenido web din\u00e1mico, copias de seguridad activas.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#2-s3-intelligent-tiering","title":"2. S3 Intelligent-Tiering","text":"<ul> <li> <p>Descripci\u00f3n: S3 Intelligent-Tiering es una clase de almacenamiento que optimiza autom\u00e1ticamente los costos. Los objetos se mueven autom\u00e1ticamente entre las capas de acceso frecuente y de acceso a largo plazo seg\u00fan su patr\u00f3n de acceso.</p> </li> <li> <p>Casos de Uso: Datos con patrones de acceso impredecibles, donde se desea una combinaci\u00f3n de rendimiento y ahorro de costos.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#3-s3-standard-ia-infrequent-access","title":"3. S3 Standard-IA (Infrequent Access)","text":"<ul> <li> <p>Descripci\u00f3n: Esta clase de almacenamiento est\u00e1 dise\u00f1ada para datos a los que se accede con menos frecuencia. Ofrece un costo menor que S3 Standard a cambio de una tarifa de recuperaci\u00f3n de datos si se accede antes de 30 d\u00edas.</p> </li> <li> <p>Casos de Uso: Almacenamiento de copias de seguridad a largo plazo, archivos de registro, datos de archivo inactivos.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#4-s3-one-zone-ia","title":"4. S3 One Zone-IA","text":"<ul> <li> <p>Descripci\u00f3n: Similar a S3 Standard-IA, pero los datos se almacenan en una sola zona de disponibilidad en lugar de replicarse en m\u00faltiples zonas. Esto reduce costos, pero los datos no est\u00e1n tan disponibles como en otras clases.</p> </li> <li> <p>Casos de Uso: Datos que pueden recrearse si se pierden, como copias de seguridad de bajo costo.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#5-s3-glacier","title":"5. S3 Glacier","text":"<ul> <li> <p>Descripci\u00f3n: S3 Glacier es una clase de almacenamiento de archivo que ofrece un costo extremadamente bajo a cambio de tiempos de acceso m\u00e1s lentos. Los datos se almacenan en formato de archivo y deben recuperarse antes de acceder a ellos.</p> </li> <li> <p>Casos de Uso: Archivado a largo plazo, cumplimiento normativo, datos de archivo que no se necesitan con frecuencia.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#6-s3-glacier-deep-archive","title":"6. S3 Glacier Deep Archive","text":"<ul> <li> <p>Descripci\u00f3n: Esta es la opci\u00f3n m\u00e1s econ\u00f3mica de Amazon S3, pero tambi\u00e9n la m\u00e1s lenta en t\u00e9rminos de acceso. Se utiliza para datos de archivo que se mantienen a largo plazo y rara vez se necesitan.</p> </li> <li> <p>Casos de Uso: Cumplimiento normativo a largo plazo, retenci\u00f3n de registros hist\u00f3ricos, datos de archivo de bajo costo.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#7-s3-outposts","title":"7. S3 Outposts","text":"<ul> <li> <p>Descripci\u00f3n: S3 Outposts permite almacenar datos en ubicaciones locales en los data centers de AWS Outposts. Los datos almacenados en S3 Outposts est\u00e1n sincronizados con la regi\u00f3n de AWS m\u00e1s cercana.</p> </li> <li> <p>Casos de Uso: Escenarios donde es necesario almacenar datos en ubicaciones locales en conjunto con infraestructura local.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#8-s3-object-lock","title":"8. S3 Object Lock","text":"<ul> <li> <p>Descripci\u00f3n: Esta caracter\u00edstica permite configurar pol\u00edticas de bloqueo de objetos para evitar la eliminaci\u00f3n o modificaci\u00f3n de objetos durante un per\u00edodo de retenci\u00f3n especificado.</p> </li> <li> <p>Casos de Uso: Cumplimiento normativo, protecci\u00f3n de datos cr\u00edticos contra borrado accidental.</p> </li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#seleccion-de-la-clase-de-almacenamiento","title":"Selecci\u00f3n de la Clase de Almacenamiento","text":"<p>La elecci\u00f3n de la clase de almacenamiento adecuada en Amazon S3 depende de los requisitos espec\u00edficos de tu aplicaci\u00f3n y de tu presupuesto. Aqu\u00ed hay algunas pautas generales para ayudarte a seleccionar la clase correcta:</p> <ul> <li>Si necesitas un alto rendimiento y disponibilidad inmediata, opta por S3 Standard.</li> <li>Si tienes datos con patrones de acceso impredecibles y deseas ahorrar costos, considera S3 Intelligent-Tiering.</li> <li>Para datos a los que se accede con menos frecuencia, S3 Standard-IA es una buena opci\u00f3n.</li> <li>Si puedes recrear datos perdidos y deseas un bajo costo, elige S3 One Zone-IA.</li> <li>Para archivar datos a largo plazo con costo m\u00ednimo, utiliza S3 Glacier o S3 Glacier Deep Archive.</li> <li>Si necesitas almacenar datos en ubicaciones locales con AWS Outposts, considera S3 Outposts.</li> </ul> <p>Recuerda que puedes cambiar la clase de almacenamiento de tus objetos en cualquier momento seg\u00fan cambien tus necesidades</p> <p>.</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#conclusion_1","title":"Conclusi\u00f3n","text":"<p>Amazon S3 ofrece una amplia gama de opciones de clase de almacenamiento para adaptarse a diversas necesidades. Al comprender las caracter\u00edsticas y los casos de uso de cada clase de almacenamiento, puedes tomar decisiones informadas sobre c\u00f3mo almacenar y gestionar tus datos en Amazon S3 de manera eficiente y rentable. Experimenta con las diferentes clases de almacenamiento para optimizar tus costos y satisfacer los requisitos de tu aplicaci\u00f3n.</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#documentacion-ampliada-amazon-simple-storage-service-amazon-s3_1","title":"Documentaci\u00f3n Ampliada: Amazon Simple Storage Service (Amazon S3)","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#introduccion-a-amazon-s3_1","title":"Introducci\u00f3n a Amazon S3","text":"<p>Amazon Simple Storage Service (Amazon S3) es un servicio de almacenamiento en la nube escalable y duradero que permite almacenar y recuperar datos en cualquier momento desde cualquier ubicaci\u00f3n en la web. Amazon S3 es ampliamente utilizado para el almacenamiento de objetos, copias de seguridad, distribuci\u00f3n de contenido y como componente central de muchas aplicaciones en la nube.</p> <p>Documentaci\u00f3n Oficial de Amazon S3: Amazon S3 - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#conceptos-clave-de-amazon-s3_1","title":"Conceptos Clave de Amazon S3","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#1-buckets_1","title":"1. Buckets","text":"<ul> <li>Buckets: Un bucket de Amazon S3 es un contenedor para almacenar objetos. Los objetos se almacenan en buckets y deben tener un nombre \u00fanico en todo Amazon S3.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de un Bucket - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#2-objetos_1","title":"2. Objetos","text":"<ul> <li>Objetos: Los objetos son unidades de datos que se almacenan en buckets. Un objeto puede ser cualquier tipo de archivo, como documentos, im\u00e1genes, videos y m\u00e1s.</li> </ul> <p>Documentaci\u00f3n Relacionada: Carga de Objetos en S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#3-regiones_1","title":"3. Regiones","text":"<ul> <li>Regiones: Amazon S3 est\u00e1 disponible en m\u00faltiples regiones de todo el mundo. Puedes seleccionar la regi\u00f3n que mejor se adapte a tus necesidades de rendimiento y cumplimiento.</li> </ul> <p>Documentaci\u00f3n Relacionada: Seleccionar una Regi\u00f3n para tu Bucket - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#4-clases-de-almacenamiento_1","title":"4. Clases de Almacenamiento","text":"<ul> <li>Clases de Almacenamiento: Amazon S3 ofrece diversas clases de almacenamiento, como S3 Standard, S3 Intelligent-Tiering, S3 Glacier, S3 Glacier Deep Archive, entre otras, cada una dise\u00f1ada para diferentes casos de uso y costos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Clases de Almacenamiento de S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#5-control-de-acceso_1","title":"5. Control de Acceso","text":"<ul> <li>Control de Acceso: Puedes definir pol\u00edticas de control de acceso para determinar qui\u00e9n puede acceder y qu\u00e9 acciones pueden realizar en tus buckets y objetos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Control de Acceso en S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#configuracion-y-uso-basico-de-amazon-s3_1","title":"Configuraci\u00f3n y Uso B\u00e1sico de Amazon S3","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#1-creacion-de-un-bucket_1","title":"1. Creaci\u00f3n de un Bucket","text":"<ul> <li>Desde la Consola de AWS, puedes crear un nuevo bucket y seleccionar su regi\u00f3n.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de un Bucket - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#2-carga-de-objetos_1","title":"2. Carga de Objetos","text":"<ul> <li>Puedes cargar objetos en tu bucket utilizando la Consola de AWS, la AWS CLI o SDKs.</li> </ul> <p>Documentaci\u00f3n Relacionada: Carga de Objetos en S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#3-acceso-a-objetos_1","title":"3. Acceso a Objetos","text":"<ul> <li>Puedes configurar permisos de acceso a objetos para definir qui\u00e9n puede ver y descargar los objetos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Configuraci\u00f3n de Permisos de Objetos - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#4-versiones-de-objetos_1","title":"4. Versiones de Objetos","text":"<ul> <li>Amazon S3 admite versiones de objetos, lo que permite mantener un historial de cambios en los objetos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Versionado de Objetos en S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#5-almacenamiento-de-datos_1","title":"5. Almacenamiento de Datos","text":"<ul> <li>Utiliza las clases de almacenamiento adecuadas seg\u00fan tus requisitos de rendimiento y costo.</li> </ul> <p>Documentaci\u00f3n Relacionada: Clases de Almacenamiento de S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#casos-de-uso-comunes-de-amazon-s3_1","title":"Casos de Uso Comunes de Amazon S3","text":""},{"location":"SBD/Tema01/AlmacenamientoAWS/#1-almacenamiento-de-copias-de-seguridad_1","title":"1. Almacenamiento de Copias de Seguridad","text":"<ul> <li>Utiliza Amazon S3 para almacenar copias de seguridad de tus datos y sistemas cr\u00edticos.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#2-distribucion-de-contenido-estatico_1","title":"2. Distribuci\u00f3n de Contenido Est\u00e1tico","text":"<ul> <li>Almacena y distribuye contenido web est\u00e1tico, como im\u00e1genes y archivos CSS, para mejorar la velocidad de carga de tu sitio web.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#3-almacenamiento-de-datos-para-aplicaciones_1","title":"3. Almacenamiento de Datos para Aplicaciones","text":"<ul> <li>Almacena datos de aplicaciones y archivos generados por usuarios en Amazon S3.</li> </ul>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#4-almacenamiento-de-datos-para-analisis_1","title":"4. Almacenamiento de Datos para An\u00e1lisis","text":"<ul> <li>Almacena datos para an\u00e1lisis y procesamiento posterior utilizando servicios de AWS como Amazon Redshift y Amazon Athena.</li> </ul> <p>Documentaci\u00f3n Relacionada: Casos de Uso de Amazon S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#recomendaciones-de-seguridad_1","title":"Recomendaciones de Seguridad","text":"<ul> <li>Configuraci\u00f3n de Control de Acceso: Limita el acceso a tus buckets y objetos utilizando pol\u00edticas y ACLs.</li> </ul> <p>Documentaci\u00f3n Relacionada: Control de Acceso en S3 - AWS</p> <ul> <li>Cifrado de Datos: Habilita el cifrado de datos en reposo y en tr\u00e1nsito para proteger la confidencialidad de tus datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Cifrado de Datos en S3 - AWS</p> <ul> <li>Versionado de Objetos: Utiliza la funci\u00f3n de versionado de objetos para mantener un historial de cambios.</li> </ul> <p>Documentaci\u00f3n Relacionada: Versionado de Objetos en S3 - AWS</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#ayuda-y-documentacion_1","title":"Ayuda y Documentaci\u00f3n","text":"<p>Amazon S3 ofrece documentaci\u00f3n completa en la p\u00e1gina oficial de AWS. Tambi\u00e9n puedes utilizar la AWS CLI y SDKs para interactuar program\u00e1ticamente con Amazon S3.</p>"},{"location":"SBD/Tema01/AlmacenamientoAWS/#conclusion_2","title":"Conclusi\u00f3n","text":"<p>Amazon Simple Storage Service (Amazon S3) es un servicio de almacenamiento vers\u00e1til y altamente escalable que se utiliza en una amplia variedad de aplicaciones y casos de uso. Al comprender las caracter\u00edsticas y los casos de uso de cada clase de almacenamiento, puedes tomar</p>"},{"location":"SBD/Tema01/BigDataConAWS/","title":"1. Big Data con AWS","text":""},{"location":"SBD/Tema01/BigDataConAWS/#11-introduccion-a-aws","title":"1.1. Introducci\u00f3n a AWS","text":"<p>Amazon Web Services (AWS) es una plataforma de servicios en la nube l\u00edder en el mundo que ofrece una amplia gama de servicios de infraestructura, almacenamiento, c\u00f3mputo, bases de datos, an\u00e1lisis y m\u00e1s. </p> <p>AWS proporciona la infraestructura necesaria para ejecutar aplicaciones, almacenar datos y procesar informaci\u00f3n a escala global. En el contexto de Big Data, AWS ofrece herramientas y servicios para administrar, procesar y analizar grandes vol\u00famenes de datos de manera eficiente y escalable.</p> <p>AWS ofrece una amplia gama de servicios y herramientas para facilitar proyectos de Big Data. Puedes aprovechar la escalabilidad, la variedad de servicios y las medidas de seguridad de AWS para administrar y analizar grandes vol\u00famenes de datos de manera efectiva.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#12-por-que-aws-para-big-data","title":"1.2. Por Qu\u00e9 AWS para Big Data","text":""},{"location":"SBD/Tema01/BigDataConAWS/#121-escalabilidad","title":"1.2.1. Escalabilidad","text":"<p>AWS ofrece la capacidad de escalar recursos de manera flexible seg\u00fan las necesidades de tu proyecto de Big Data. Puedes aumentar o reducir la capacidad de c\u00f3mputo y almacenamiento seg\u00fan la demanda, lo que te permite manejar grandes vol\u00famenes de datos sin preocuparte por la infraestructura subyacente.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#122-variedad-de-servicios","title":"1.2.2. Variedad de Servicios","text":"<p>AWS proporciona una amplia gama de servicios espec\u00edficamente dise\u00f1ados para el procesamiento y an\u00e1lisis de Big Data. Estos servicios incluyen Amazon EMR (Elastic MapReduce), Amazon Redshift, AWS Glue, Amazon Kinesis y m\u00e1s.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#123-seguridad-y-cumplimiento","title":"1.2.3. Seguridad y Cumplimiento","text":"<p>AWS implementa medidas de seguridad y cumplimiento rigurosas para proteger tus datos. Puedes administrar el acceso a tus recursos y datos, cifrar la informaci\u00f3n en tr\u00e1nsito y en reposo, y cumplir con regulaciones espec\u00edficas de la industria.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#13-principales-servicios-de-aws-para-big-data","title":"1.3. Principales Servicios de AWS para Big Data","text":""},{"location":"SBD/Tema01/BigDataConAWS/#131-amazon-s3-amazon-simple-storage-service","title":"1.3.1. Amazon S3 (Amazon Simple Storage Service)","text":"<p>Amazon S3 es un servicio de almacenamiento en la nube altamente escalable, seguro y confiable que permite a las empresas almacenar, gestionar y acceder a datos de manera eficiente en la plataforma de AWS.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#132-amazon-emr-elastic-mapreduce","title":"1.3.2. Amazon EMR (Elastic MapReduce)","text":"<p>Amazon EMR es un servicio de administraci\u00f3n de cl\u00fasteres de c\u00f3digo abierto que te permite procesar grandes vol\u00famenes de datos de manera distribuida utilizando frameworks como Apache Hadoop, Apache Spark y Apache Hive. Puedes crear y administrar cl\u00fasteres de EMR de manera sencilla y escalarlos seg\u00fan sea necesario.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#133-amazon-redshift","title":"1.3.3. Amazon Redshift","text":"<p>Amazon Redshift es un servicio de data warehousing completamente administrado que te permite analizar grandes conjuntos de datos de manera eficiente. Es ideal para almacenar y consultar datos anal\u00edticos, y admite integraci\u00f3n con herramientas de visualizaci\u00f3n populares.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#134-aws-glue","title":"1.3.4. AWS Glue","text":"<p>AWS Glue es un servicio de ETL (Extract, Transform, Load) completamente administrado que facilita la preparaci\u00f3n y transformaci\u00f3n de datos para an\u00e1lisis. Puedes definir trabajos de ETL utilizando un entorno visual o escribir scripts en lenguaje Python.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#135-amazon-kinesis","title":"1.3.5. Amazon Kinesis","text":"<p>Amazon Kinesis es una plataforma para el streaming de datos en tiempo real. Te permite capturar, procesar y analizar flujos de datos en tiempo real, lo que es fundamental para aplicaciones de an\u00e1lisis en tiempo real y procesamiento de eventos.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#14-ejemplo-de-uso-procesamiento-de-logs-con-aws","title":"1.4. Ejemplo de Uso: Procesamiento de Logs con AWS","text":"<p>Supongamos que deseas analizar registros (logs) de aplicaciones web para obtener informaci\u00f3n valiosa. Puedes utilizar AWS para este escenario:</p> <ol> <li> <p>Almacenamiento de Logs: Utiliza Amazon S3 para almacenar los registros de aplicaciones web de manera escalable y duradera.</p> </li> <li> <p>Procesamiento con Amazon EMR: Crea un cl\u00faster de Amazon EMR para procesar los registros utilizando Apache Spark. Puedes aplicar transformaciones y consultas para extraer informaci\u00f3n relevante.</p> </li> <li> <p>Almacenamiento de Resultados: Guarda los resultados del procesamiento en Amazon Redshift para consultas posteriores y an\u00e1lisis enriquecidos.</p> </li> <li> <p>Visualizaci\u00f3n con Amazon QuickSight: Utiliza Amazon QuickSight para crear paneles de control y visualizaciones interactivas que muestren informaci\u00f3n clave extra\u00edda de los logs.</p> </li> </ol>"},{"location":"SBD/Tema01/BigDataConAWS/#15-aws-academy","title":"1.5 AWS Academy","text":"<p>AWS Academy es un programa global de formaci\u00f3n t\u00e9cnica respaldado por Amazon Web Services. Ofrece a estudiantes y educadores la capacitaci\u00f3n y los recursos necesarios para desarrollar habilidades en la nube. </p> <p>La misi\u00f3n de AWS Academy es proporcionar educaci\u00f3n de alta calidad y actualizada en AWS, ayudando a los estudiantes a prepararse para carreras en la nube.</p>"},{"location":"SBD/Tema01/BigDataConAWS/#151-beneficios","title":"1.5.1 Beneficios","text":"<ul> <li>Los estudiantes tienen la oportunidad de adquirir habilidades en la nube altamente demandadas por empleadores en una variedad de industrias. Ejemplo: Un estudio de empleo reciente mostr\u00f3 que el 80% de las empresas buscan profesionales de AWS.</li> <li>AWS Academy se enfoca en la pr\u00e1ctica y proyectos reales, lo que permite a los estudiantes aplicar sus conocimientos en situaciones del mundo real.</li> </ul>"},{"location":"SBD/Tema01/BigDataConAWS/#152-cursos-ofrecidos","title":"1.5.2. Cursos Ofrecidos","text":"<ul> <li>AWS Academy ofrece una amplia gama de cursos que cubren una variedad de temas, desde fundamentos de la nube hasta cursos especializados en \u00e1reas c\u00f3mo desarrollo de aplicaciones y an\u00e1lisis de datos. Ejemplo: \"Fundamentos de AWS Cloud\" es un curso de nivel inicial que introduce los conceptos b\u00e1sicos de la nube.</li> <li>Muchos de los cursos de AWS Academy est\u00e1n dise\u00f1ados para preparar a los estudiantes para las certificaciones de AWS, lo que les brinda una ventaja competitiva en el mercado laboral.</li> </ul>"},{"location":"SBD/Tema01/BigDataConAWS/#153-learner-labs","title":"1.5.3. Learner Labs","text":"<ul> <li>Los Learner Labs son espacios en l\u00ednea donde los estudiantes pueden realizar pr\u00e1cticas relacionadas con AWS. Estos entornos ya est\u00e1n preconfigurados con recursos de AWS, c\u00f3mo servidores virtuales y bases de datos, lo que permite a los estudiantes centrarse en aprender sin preocuparse por la infraestructura subyacente.</li> </ul>"},{"location":"SBD/Tema01/BigDataConAWS/#154-certificaciones","title":"1.5.4. Certificaciones","text":"<p>Las certificaciones de AWS son reconocidas globalmente y validan las habilidades t\u00e9cnicas en la nube. Ejemplo: La certificaci\u00f3n \"AWS Certified Solutions Architect\" demuestra la capacidad de dise\u00f1ar sistemas escalables en AWS.</p>"},{"location":"SBD/Tema01/DataLakeAWS/","title":"Documentaci\u00f3n: Creaci\u00f3n y Gesti\u00f3n de un Data Lake en AWS","text":""},{"location":"SBD/Tema01/DataLakeAWS/#introduccion-a-data-lake-en-aws","title":"Introducci\u00f3n a Data Lake en AWS","text":"<p>Un data lake es un repositorio centralizado que permite almacenar grandes vol\u00famenes de datos en su formato original. AWS ofrece una serie de servicios que te permiten crear y gestionar un data lake escalable, seguro y altamente disponible.</p> <p>Documentaci\u00f3n Oficial de AWS sobre Data Lake: AWS Data Lake - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#componentes-clave-de-un-data-lake-en-aws","title":"Componentes Clave de un Data Lake en AWS","text":""},{"location":"SBD/Tema01/DataLakeAWS/#1-amazon-s3","title":"1. Amazon S3","text":"<ul> <li>Amazon S3: Utiliza Amazon Simple Storage Service (Amazon S3) como el almacenamiento principal para tu data lake. Amazon S3 es altamente escalable, duradero y ofrece capacidades de cifrado para garantizar la seguridad de tus datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Amazon S3 - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#2-aws-glue","title":"2. AWS Glue","text":"<ul> <li>AWS Glue: Utiliza AWS Glue para catalogar, limpiar y transformar datos antes de cargarlos en el data lake. AWS Glue es un servicio de ETL totalmente administrado.</li> </ul> <p>Documentaci\u00f3n Relacionada: AWS Glue - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#3-aws-lake-formation","title":"3. AWS Lake Formation","text":"<ul> <li>AWS Lake Formation: AWS Lake Formation te ayuda a configurar y gestionar un data lake de manera m\u00e1s sencilla, incluida la configuraci\u00f3n de permisos y la gesti\u00f3n de metadatos.</li> </ul> <p>Documentaci\u00f3n Relacionada: AWS Lake Formation - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#4-herramientas-de-analisis","title":"4. Herramientas de An\u00e1lisis","text":"<ul> <li>Herramientas de An\u00e1lisis: Utiliza herramientas de an\u00e1lisis como Amazon Athena, Amazon Redshift, AWS EMR y AWS Quicksight para consultar, analizar y visualizar datos en tu data lake.</li> </ul> <p>Documentaci\u00f3n Relacionada: Herramientas de An\u00e1lisis en AWS - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#configuracion-y-uso-basico-de-un-data-lake-en-aws","title":"Configuraci\u00f3n y Uso B\u00e1sico de un Data Lake en AWS","text":""},{"location":"SBD/Tema01/DataLakeAWS/#1-creacion-de-un-data-lake","title":"1. Creaci\u00f3n de un Data Lake","text":"<ul> <li>Configura un bucket de Amazon S3 como el almacenamiento central de tu data lake.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de un Data Lake en Amazon S3 - AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#2-catalogacion-de-datos","title":"2. Catalogaci\u00f3n de Datos","text":"<ul> <li>Utiliza AWS Glue para catalogar datos en tu data lake, lo que facilita la b\u00fasqueda y el acceso a los datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Catalogaci\u00f3n de Datos con AWS Glue - AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#3-gobernanza-y-seguridad","title":"3. Gobernanza y Seguridad","text":"<ul> <li>Configura pol\u00edticas de control de acceso, cifrado de datos y auditor\u00eda para garantizar la seguridad y la conformidad de tus datos en el data lake.</li> </ul> <p>Documentaci\u00f3n Relacionada: Gobernanza y Seguridad en Data Lake - AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#4-procesamiento-de-datos","title":"4. Procesamiento de Datos","text":"<ul> <li>Utiliza servicios de procesamiento de datos como AWS EMR o AWS Lambda para realizar transformaciones y an\u00e1lisis en tus datos del data lake.</li> </ul> <p>Documentaci\u00f3n Relacionada: Procesamiento de Datos en AWS - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#casos-de-uso-comunes-de-un-data-lake-en-aws","title":"Casos de Uso Comunes de un Data Lake en AWS","text":""},{"location":"SBD/Tema01/DataLakeAWS/#1-analisis-de-datos","title":"1. An\u00e1lisis de Datos","text":"<ul> <li>Almacena y analiza datos de m\u00faltiples fuentes para obtener informaci\u00f3n valiosa sobre tu negocio.</li> </ul>"},{"location":"SBD/Tema01/DataLakeAWS/#2-data-warehousing","title":"2. Data Warehousing","text":"<ul> <li>Utiliza un data lake junto con servicios como Amazon Redshift para implementar soluciones de data warehousing.</li> </ul>"},{"location":"SBD/Tema01/DataLakeAWS/#3-ciencia-de-datos","title":"3. Ciencia de Datos","text":"<ul> <li>Facilita proyectos de ciencia de datos al proporcionar un repositorio centralizado para datos brutos y procesados.</li> </ul> <p>Documentaci\u00f3n Relacionada: Casos de Uso de Data Lake - AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#recomendaciones-de-mejores-practicas","title":"Recomendaciones de Mejores Pr\u00e1cticas","text":"<ul> <li> <p>Planificaci\u00f3n de Datos: Dise\u00f1a una estrategia de planificaci\u00f3n de datos que defina c\u00f3mo se organizar\u00e1n y catalogar\u00e1n los datos en el data lake.</p> </li> <li> <p>Automatizaci\u00f3n de Procesos: Utiliza servicios de automatizaci\u00f3n como AWS Step Functions para orquestar flujos de trabajo de procesamiento de datos.</p> </li> </ul> <p>Documentaci\u00f3n Relacionada: Orquestaci\u00f3n de Flujos de Trabajo con AWS Step Functions - AWS</p> <ul> <li>Monitorizaci\u00f3n y Auditor\u00eda: Implementa una soluci\u00f3n de monitorizaci\u00f3n y auditor\u00eda para supervisar el uso y el rendimiento de tu data lake.</li> </ul> <p>Documentaci\u00f3n Relacionada: Monitorizaci\u00f3n en AWS - AWS</p>"},{"location":"SBD/Tema01/DataLakeAWS/#ayuda-y-documentacion-adicional","title":"Ayuda y Documentaci\u00f3n Adicional","text":"<p>Para obtener m\u00e1s detalles sobre la creaci\u00f3n y gesti\u00f3n de un data lake en AWS, te recomiendo consultar la documentaci\u00f3n oficial de AWS sobre Data Lake. Adem\u00e1s, AWS ofrece tutoriales detallados y ejemplos de implementaci\u00f3n para ayudarte en tu proyecto de data lake.</p>"},{"location":"SBD/Tema01/DataLakeAWS/#conclusion","title":"Conclusi\u00f3n","text":"<p>La creaci\u00f3n y gesti\u00f3n de un data lake en AWS es fundamental para aprovechar al m\u00e1ximo tus datos y habilitar an\u00e1lisis avanzados. Siguiendo las mejores pr\u00e1cticas de seguridad y gobernanza, puedes construir un data lake robusto y escalable que satisfaga las necesidades de tu organizaci\u00f3n.</p> <p>Puedes crear y gestionar un data lake en AWS sin utilizar AWS Lake Formation siguiendo una serie de pasos y utilizando los servicios principales de AWS. A continuaci\u00f3n, te proporciono una gu\u00eda paso a paso sobre c\u00f3mo hacerlo:</p>"},{"location":"SBD/Tema01/DataLakeAWS/#creacion-y-gestion-de-un-data-lake-en-aws-sin-aws-lake-formation","title":"Creaci\u00f3n y Gesti\u00f3n de un Data Lake en AWS sin AWS Lake Formation","text":""},{"location":"SBD/Tema01/DataLakeAWS/#paso-1-configurar-amazon-s3","title":"Paso 1: Configurar Amazon S3","text":"<ol> <li> <p>Crear un Bucket de Amazon S3: Inicia sesi\u00f3n en la consola de AWS y crea un bucket de S3 que servir\u00e1 como el almacenamiento central para tu data lake. Organiza tus datos en carpetas dentro del bucket seg\u00fan las categor\u00edas o fuentes de datos.</p> </li> <li> <p>Configurar Pol\u00edticas de Acceso: Configura las pol\u00edticas de acceso y permisos en tu bucket de S3 para garantizar que solo los usuarios autorizados puedan acceder a los datos. Utiliza las pol\u00edticas de S3 y IAM para administrar el acceso.</p> </li> <li> <p>Habilitar Cifrado: Habilita el cifrado de datos en reposo y en tr\u00e1nsito en tu bucket de S3 para garantizar la seguridad de los datos almacenados.</p> </li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-2-catalogar-datos-con-aws-glue","title":"Paso 2: Catalogar Datos con AWS Glue","text":"<ol> <li> <p>Utilizar AWS Glue Data Catalog: Utiliza AWS Glue Data Catalog para catalogar y gestionar los metadatos de tus datos en el data lake. AWS Glue permite crear tablas y definir esquemas para tus datos.</p> </li> <li> <p>Ejecutar Crawler: Configura y ejecuta crawlers de AWS Glue para descubrir y catalogar autom\u00e1ticamente los datos en tu bucket de S3. Esto facilita la b\u00fasqueda y el acceso a los datos.</p> </li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-3-procesamiento-y-transformacion-de-datos","title":"Paso 3: Procesamiento y Transformaci\u00f3n de Datos","text":"<ol> <li>Utilizar Servicios de Procesamiento: Utiliza servicios de procesamiento como AWS Lambda, AWS Glue ETL o AWS Step Functions para realizar transformaciones y limpieza de datos seg\u00fan sea necesario antes de cargarlos en el data lake.</li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-4-herramientas-de-analisis","title":"Paso 4: Herramientas de An\u00e1lisis","text":"<ol> <li>Configurar Herramientas de An\u00e1lisis: Configura herramientas de an\u00e1lisis como Amazon Athena, Amazon Redshift o AWS QuickSight para consultar, analizar y visualizar datos en tu data lake.</li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-5-gobernanza-y-seguridad","title":"Paso 5: Gobernanza y Seguridad","text":"<ol> <li> <p>Implementar Gobernanza: Define pol\u00edticas y procedimientos de gobernanza de datos para garantizar la calidad y la conformidad de los datos en el data lake.</p> </li> <li> <p>Auditor\u00eda y Monitoreo: Implementa una soluci\u00f3n de auditor\u00eda y monitoreo para supervisar el acceso y el rendimiento de tu data lake. Puedes utilizar AWS CloudTrail y Amazon CloudWatch para esto.</p> </li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-6-automatizacion-de-procesos","title":"Paso 6: Automatizaci\u00f3n de Procesos","text":"<ol> <li>Automatizaci\u00f3n de Flujos de Trabajo: Utiliza servicios como AWS Step Functions para orquestar flujos de trabajo de procesamiento y an\u00e1lisis de datos de manera automatizada.</li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-7-casos-de-uso-comunes","title":"Paso 7: Casos de Uso Comunes","text":"<ol> <li>Implementar Casos de Uso: Utiliza tu data lake para una variedad de casos de uso, como an\u00e1lisis de datos, ciencia de datos, an\u00e1lisis de registros y m\u00e1s, aprovechando las herramientas y servicios adecuados.</li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#recomendaciones-de-mejores-practicas_1","title":"Recomendaciones de Mejores Pr\u00e1cticas","text":"<ul> <li> <p>Planifica y dise\u00f1a cuidadosamente la estructura de tus datos en el data lake para facilitar la b\u00fasqueda y el acceso.</p> </li> <li> <p>Implementa pol\u00edticas de retenci\u00f3n de datos para administrar el ciclo de vida de los datos en el data lake.</p> </li> <li> <p>Capacita a los usuarios y equipos de TI en el uso de las herramientas y servicios de AWS para el data lake.</p> </li> <li> <p>Establece una estrategia de escalabilidad para que el data lake pueda crecer con la cantidad de datos y el uso.</p> </li> </ul>"},{"location":"SBD/Tema01/DataLakeAWS/#ayuda-y-documentacion-adicional_1","title":"Ayuda y Documentaci\u00f3n Adicional","text":"<p>Para obtener m\u00e1s detalles sobre la creaci\u00f3n y gesti\u00f3n de un data lake en AWS sin utilizar AWS Lake Formation, puedes consultar la documentaci\u00f3n oficial de AWS sobre Data Lake. Adem\u00e1s, AWS ofrece tutoriales y ejemplos de implementaci\u00f3n para ayudarte en tu proyecto de data lake.</p>"},{"location":"SBD/Tema01/DataLakeAWS/#conclusion_1","title":"Conclusi\u00f3n","text":"<p>Crear y gestionar un data lake en AWS sin AWS Lake Formation es factible utilizando los servicios principales de AWS y siguiendo las mejores pr\u00e1cticas de gobernanza y seguridad. Esto te permitir\u00e1 almacenar, procesar y analizar datos de manera eficiente y escalable en tu organizaci\u00f3n.</p> <p>Claro, aqu\u00ed tienes un ejemplo simplificado de c\u00f3mo crear y gestionar un data lake en AWS utilizando Amazon S3, AWS Glue y Amazon Athena. En este ejemplo, supondremos que estamos trabajando con datos de registros de servidores web almacenados en archivos JSON en un bucket de Amazon S3.</p>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-1-configurar-amazon-s3_1","title":"Paso 1: Configurar Amazon S3","text":"<ol> <li> <p>Crear un Bucket de Amazon S3: Inicia sesi\u00f3n en la consola de AWS y crea un bucket de S3 llamado \"mi-data-lake\".</p> </li> <li> <p>Configurar Pol\u00edticas de Acceso: Configura pol\u00edticas de acceso en el bucket de S3 para definir qui\u00e9n puede acceder a los datos y en qu\u00e9 condiciones.</p> </li> <li> <p>Habilitar Cifrado: Habilita el cifrado de datos en reposo y en tr\u00e1nsito en el bucket de S3 para garantizar la seguridad de los datos almacenados.</p> </li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-2-catalogar-datos-con-aws-glue_1","title":"Paso 2: Catalogar Datos con AWS Glue","text":"<ol> <li> <p>Utilizar AWS Glue Data Catalog: Configura AWS Glue Data Catalog para catalogar y gestionar los metadatos de tus datos en el data lake.</p> </li> <li> <p>Ejecutar Crawler: Crea un Crawler de AWS Glue y config\u00faralo para que descubra y catalogue autom\u00e1ticamente los datos en el bucket de S3. El Crawler puede reconocer el formato JSON de los archivos y crear tablas en el cat\u00e1logo.</p> </li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-3-procesamiento-y-transformacion-de-datos_1","title":"Paso 3: Procesamiento y Transformaci\u00f3n de Datos","text":"<ol> <li>Utilizar AWS Glue ETL: Utiliza AWS Glue ETL para definir trabajos de transformaci\u00f3n de datos. Por ejemplo, puedes limpiar y estructurar los datos JSON en tablas relacionales.</li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-4-herramientas-de-analisis_1","title":"Paso 4: Herramientas de An\u00e1lisis","text":"<ol> <li>Configurar Amazon Athena: Configura Amazon Athena para que consulte los datos catalogados en el cat\u00e1logo de AWS Glue. Puedes utilizar SQL est\u00e1ndar para consultar los datos.</li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-5-gobernanza-y-seguridad_1","title":"Paso 5: Gobernanza y Seguridad","text":"<ol> <li> <p>Pol\u00edticas de Acceso: Configura pol\u00edticas de acceso y permisos en Amazon Athena para controlar qui\u00e9n puede ejecutar consultas en el data lake.</p> </li> <li> <p>Auditor\u00eda y Monitoreo: Implementa la auditor\u00eda y el monitoreo de las consultas en Amazon Athena utilizando AWS CloudTrail y Amazon CloudWatch.</p> </li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-6-automatizacion-de-procesos_1","title":"Paso 6: Automatizaci\u00f3n de Procesos","text":"<ol> <li>Automatizaci\u00f3n de Flujos de Trabajo: Utiliza AWS Step Functions para crear flujos de trabajo automatizados que incluyan la ejecuci\u00f3n de trabajos de AWS Glue ETL y consultas en Amazon Athena.</li> </ol>"},{"location":"SBD/Tema01/DataLakeAWS/#paso-7-casos-de-uso-comunes_1","title":"Paso 7: Casos de Uso Comunes","text":"<ol> <li>Casos de Uso: Utiliza el data lake para casos de uso comunes, como an\u00e1lisis de registros de servidores web, generaci\u00f3n de informes de tr\u00e1fico, seguimiento de usuarios y m\u00e1s.</li> </ol> <p>Este es un ejemplo b\u00e1sico, y en un entorno real, la configuraci\u00f3n y gesti\u00f3n del data lake ser\u00edan m\u00e1s complejas y estar\u00edan dise\u00f1adas para satisfacer las necesidades espec\u00edficas de tu organizaci\u00f3n. Adem\u00e1s, AWS ofrece servicios adicionales para la gesti\u00f3n de datos, como AWS Glue DataBrew y AWS Lake Formation, que pueden facilitar a\u00fan m\u00e1s la creaci\u00f3n y gesti\u00f3n de un data lake.</p> <p>Crear un Data Lake en AWS sin utilizar AWS Lake Formation implica configurar manualmente los servicios de AWS para almacenar, catalogar y gestionar tus datos. A continuaci\u00f3n, te proporciono un ejemplo pr\u00e1ctico de c\u00f3mo puedes crear un Data Lake utilizando servicios como Amazon S3, AWS Glue y Amazon Athena:</p> <p>Paso 1: Configuraci\u00f3n de Almacenamiento en Amazon S3:</p> <ol> <li>Crea un bucket de Amazon S3 para actuar como el almacenamiento central de tu Data Lake.</li> <li>Organiza tus datos en carpetas l\u00f3gicas dentro del bucket de S3. Por ejemplo, puedes tener carpetas como <code>datos_brutos</code>, <code>datos_transformados</code>, <code>archivos_csv</code>, etc.</li> </ol> <p>Paso 2: Carga de Datos:</p> <ol> <li>Carga tus datos en formato bruto en la carpeta <code>datos_brutos</code> en tu bucket de S3. Puedes utilizar la consola de AWS, la CLI de AWS o herramientas de transferencia como AWS DataSync.</li> </ol> <p>Paso 3: Catalogaci\u00f3n de Datos con AWS Glue:</p> <ol> <li>Configura AWS Glue Crawler para descubrir y catalogar autom\u00e1ticamente los datos en tu bucket de S3. Debes definir una base de datos de AWS Glue y tablas para cada conjunto de datos que quieras catalogar.</li> <li>Ejecuta el Crawler para que escanee tus datos y genere metadatos en el Cat\u00e1logo de AWS Glue.</li> </ol> <p>Paso 4: Transformaci\u00f3n de Datos con AWS Glue:</p> <ol> <li>Crea trabajos de AWS Glue para realizar transformaciones en tus datos catalogados si es necesario. Esto podr\u00eda incluir la limpieza de datos, la agregaci\u00f3n o la conversi\u00f3n de formatos.</li> <li>Almacena los resultados de las transformaciones en una ubicaci\u00f3n espec\u00edfica en tu bucket de S3, por ejemplo, en la carpeta <code>datos_transformados</code>.</li> </ol> <p>Paso 5: Consulta de Datos con Amazon Athena:</p> <ol> <li>Utiliza Amazon Athena para consultar los datos en tu Data Lake. Puedes escribir consultas SQL est\u00e1ndar para acceder a los datos catalogados en el Cat\u00e1logo de AWS Glue.</li> <li>Amazon Athena utiliza Presto como motor de consulta, lo que te permite realizar an\u00e1lisis ad hoc sobre tus datos.</li> </ol> <p>Paso 6: Gesti\u00f3n de Seguridad y Acceso:</p> <ol> <li>Configura pol\u00edticas de acceso en Amazon S3 para controlar qui\u00e9n puede acceder y modificar tus datos.</li> <li>Utiliza AWS Identity and Access Management (IAM) para gestionar permisos de acceso a los servicios de AWS y recursos.</li> </ol> <p>Paso 7: Monitoreo y Optimizaci\u00f3n:</p> <ol> <li>Configura la monitorizaci\u00f3n y los registros de AWS CloudWatch para supervisar el rendimiento de tu Data Lake.</li> <li>Optimiza la configuraci\u00f3n de almacenamiento y las consultas para mejorar la eficiencia y reducir costos.</li> </ol> <p>Este es un ejemplo b\u00e1sico de c\u00f3mo puedes crear un Data Lake en AWS sin utilizar AWS Lake Formation. Ten en cuenta que esta configuraci\u00f3n manual puede ser m\u00e1s laboriosa que utilizar Lake Formation, que simplifica muchas de estas tareas. Adem\u00e1s, puedes personalizar y expandir esta arquitectura seg\u00fan las necesidades espec\u00edficas de tu proyecto y tu organizaci\u00f3n.</p> <p>Claro, aqu\u00ed tienes un conjunto de datos de ejemplo en formato CSV que puedes utilizar para tu Data Lake en AWS. Estos datos representan informaci\u00f3n ficticia de ventas:</p> <p>datos_brutos/ejemplo_ventas.csv:</p> <pre><code>fecha,producto,cantidad,precio\n2023-01-01,Producto A,10,100.00\n2023-01-01,Producto B,5,75.00\n2023-01-02,Producto A,8,100.00\n2023-01-02,Producto C,3,50.00\n2023-01-03,Producto B,12,75.00\n2023-01-03,Producto A,15,100.00\n2023-01-04,Producto C,6,50.00\n2023-01-04,Producto A,20,100.00\n2023-01-05,Producto B,7,75.00\n2023-01-05,Producto C,4,50.00\n</code></pre> <p>Puedes cargar estos datos en tu bucket de Amazon S3 en la carpeta <code>datos_brutos</code> para comenzar a construir tu Data Lake. Luego, puedes seguir los pasos mencionados anteriormente para catalogar, transformar y consultar estos datos utilizando servicios como AWS Glue y Amazon Athena.</p> <p>Recuerda que estos datos son solo un ejemplo y puedes adaptarlos seg\u00fan tus necesidades y el escenario de tu proyecto de Data Lake en AWS.</p>"},{"location":"SBD/Tema01/EtlAWS/","title":"Documentaci\u00f3n Ampliada: AWS Glue","text":""},{"location":"SBD/Tema01/EtlAWS/#introduccion-a-aws-glue","title":"Introducci\u00f3n a AWS Glue","text":"<p>AWS Glue es un servicio de extracci\u00f3n, transformaci\u00f3n y carga (ETL) completamente administrado que facilita la preparaci\u00f3n y carga de datos para el an\u00e1lisis en plataformas de big data. Con AWS Glue, puedes definir, ejecutar y monitorear trabajos ETL de manera sencilla, lo que te permite mover y transformar datos desde diversas fuentes hacia almacenes de datos como Amazon Redshift, Amazon S3 y m\u00e1s.</p> <p>Documentaci\u00f3n Oficial de AWS Glue: AWS Glue - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#componentes-clave-de-aws-glue","title":"Componentes Clave de AWS Glue","text":""},{"location":"SBD/Tema01/EtlAWS/#1-crawlers","title":"1. Crawlers","text":"<ul> <li>Crawlers: Los crawlers son componentes de AWS Glue que exploran tus fuentes de datos, identifican la estructura y el esquema de tus datos y generan metadatos que se utilizan en los trabajos ETL.</li> </ul> <p>Documentaci\u00f3n Relacionada: Crawlers en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#2-catalogo-de-datos","title":"2. Cat\u00e1logo de Datos","text":"<ul> <li>Cat\u00e1logo de Datos: El cat\u00e1logo de datos de AWS Glue es un repositorio centralizado donde se almacenan los metadatos de tus fuentes de datos, tablas y esquemas. Facilita la gesti\u00f3n y organizaci\u00f3n de tus datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Cat\u00e1logo de Datos en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#3-trabajos-etl","title":"3. Trabajos ETL","text":"<ul> <li>Trabajos ETL: Los trabajos ETL son scripts o flujos de trabajo que transforman y mueven datos de una fuente a un destino. AWS Glue permite crear, programar y monitorear trabajos ETL de manera sencilla.</li> </ul> <p>Documentaci\u00f3n Relacionada: Trabajos ETL en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#4-desarrollo-de-scripts","title":"4. Desarrollo de Scripts","text":"<ul> <li>Desarrollo de Scripts: AWS Glue permite desarrollar trabajos ETL utilizando lenguajes como Python o Scala. Puedes personalizar la l\u00f3gica de transformaci\u00f3n de datos seg\u00fan tus necesidades.</li> </ul> <p>Documentaci\u00f3n Relacionada: Desarrollo de Trabajos con Scripts en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#configuracion-y-uso-basico-de-aws-glue","title":"Configuraci\u00f3n y Uso B\u00e1sico de AWS Glue","text":""},{"location":"SBD/Tema01/EtlAWS/#1-creacion-de-un-crawler","title":"1. Creaci\u00f3n de un Crawler","text":"<ul> <li>Utiliza un crawler para explorar tus fuentes de datos y generar metadatos en el cat\u00e1logo de datos de AWS Glue.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de un Crawler en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#2-creacion-de-un-catalogo-de-datos","title":"2. Creaci\u00f3n de un Cat\u00e1logo de Datos","text":"<ul> <li>Configura un cat\u00e1logo de datos en AWS Glue para almacenar metadatos de fuentes de datos, tablas y esquemas.</li> </ul> <p>Documentaci\u00f3n Relacionada: Configuraci\u00f3n del Cat\u00e1logo de Datos en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#3-desarrollo-de-un-trabajo-etl","title":"3. Desarrollo de un Trabajo ETL","text":"<ul> <li>Desarrolla un trabajo ETL en AWS Glue utilizando lenguajes de script como Python o Scala para transformar y mover datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Desarrollo de Trabajos ETL en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#4-ejecucion-de-un-trabajo-etl","title":"4. Ejecuci\u00f3n de un Trabajo ETL","text":"<ul> <li>Programa y ejecuta trabajos ETL en AWS Glue para mover y transformar datos de acuerdo a tus necesidades.</li> </ul> <p>Documentaci\u00f3n Relacionada: Programaci\u00f3n y Ejecuci\u00f3n de Trabajos en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#casos-de-uso-comunes-de-aws-glue","title":"Casos de Uso Comunes de AWS Glue","text":""},{"location":"SBD/Tema01/EtlAWS/#1-preparacion-de-datos-para-analisis","title":"1. Preparaci\u00f3n de Datos para An\u00e1lisis","text":"<ul> <li>Utiliza AWS Glue para preparar datos antes de cargarlos en almacenes de datos como Amazon Redshift o Amazon S3.</li> </ul>"},{"location":"SBD/Tema01/EtlAWS/#2-integracion-de-datos-de-multiples-fuentes","title":"2. Integraci\u00f3n de Datos de M\u00faltiples Fuentes","text":"<ul> <li>Combina y transforma datos de diversas fuentes para obtener una vista unificada de tus datos.</li> </ul>"},{"location":"SBD/Tema01/EtlAWS/#3-limpieza-y-transformacion-de-datos","title":"3. Limpieza y Transformaci\u00f3n de Datos","text":"<ul> <li>Aplica reglas de limpie</li> </ul> <p>za y transformaci\u00f3n a tus datos para asegurar la calidad y consistencia.</p> <p>Documentaci\u00f3n Relacionada: Casos de Uso de AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#recomendaciones-de-seguridad","title":"Recomendaciones de Seguridad","text":"<ul> <li>Control de Acceso: Configura pol\u00edticas de control de acceso para garantizar que solo usuarios autorizados puedan acceder y modificar tus recursos de AWS Glue.</li> </ul> <p>Documentaci\u00f3n Relacionada: Control de Acceso en AWS Glue - AWS</p> <ul> <li>Seguridad de Datos: Utiliza cifrado de datos en reposo y en tr\u00e1nsito para proteger la confidencialidad de tus datos en AWS Glue.</li> </ul> <p>Documentaci\u00f3n Relacionada: Seguridad en AWS Glue - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#ayuda-y-documentacion","title":"Ayuda y Documentaci\u00f3n","text":"<p>Para obtener m\u00e1s detalles sobre AWS Glue y c\u00f3mo utilizarlo en tus proyectos, puedes consultar la documentaci\u00f3n oficial de AWS Glue. Adem\u00e1s, AWS ofrece ejemplos de c\u00f3digo y tutoriales para facilitar la implementaci\u00f3n.</p>"},{"location":"SBD/Tema01/EtlAWS/#conclusion","title":"Conclusi\u00f3n","text":"<p>AWS Glue es una herramienta poderosa para la preparaci\u00f3n y carga de datos en entornos de big data. Al comprender los componentes clave y las mejores pr\u00e1cticas de seguridad, puedes aprovechar al m\u00e1ximo este servicio para facilitar tus flujos de trabajo ETL y an\u00e1lisis de datos.</p> <p>Por supuesto, aqu\u00ed tienes una documentaci\u00f3n ampliada sobre Amazon Athena, un servicio de AWS que permite consultar datos almacenados en Amazon S3 utilizando SQL est\u00e1ndar.</p>"},{"location":"SBD/Tema01/EtlAWS/#documentacion-ampliada-amazon-athena","title":"Documentaci\u00f3n Ampliada: Amazon Athena","text":""},{"location":"SBD/Tema01/EtlAWS/#introduccion-a-amazon-athena","title":"Introducci\u00f3n a Amazon Athena","text":"<p>Amazon Athena es un servicio de consulta interactiva y an\u00e1lisis de datos que permite analizar grandes vol\u00famenes de datos almacenados en Amazon S3 utilizando SQL est\u00e1ndar. Con Athena, puedes ejecutar consultas SQL en datos no estructurados o semiestructurados sin necesidad de configurar ni administrar la infraestructura de base de datos.</p> <p>Documentaci\u00f3n Oficial de Amazon Athena: Amazon Athena - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#componentes-clave-de-amazon-athena","title":"Componentes Clave de Amazon Athena","text":""},{"location":"SBD/Tema01/EtlAWS/#1-tablas","title":"1. Tablas","text":"<ul> <li>Tablas: En Amazon Athena, las tablas son definiciones de esquema que se utilizan para organizar y consultar datos en Amazon S3. Puedes crear tablas externas que hacen referencia a datos en S3 sin mover ni copiar los datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de Tablas en Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#2-consultas","title":"2. Consultas","text":"<ul> <li>Consultas: Utiliza consultas SQL est\u00e1ndar para analizar y extraer informaci\u00f3n de tus datos en Amazon S3.</li> </ul> <p>Documentaci\u00f3n Relacionada: Ejecuci\u00f3n de Consultas en Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#3-resultados","title":"3. Resultados","text":"<ul> <li>Resultados: Las consultas en Athena generan resultados que pueden descargarse, visualizarse o almacenarse en otros servicios de AWS.</li> </ul> <p>Documentaci\u00f3n Relacionada: Gesti\u00f3n de Resultados de Consultas en Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#configuracion-y-uso-basico-de-amazon-athena","title":"Configuraci\u00f3n y Uso B\u00e1sico de Amazon Athena","text":""},{"location":"SBD/Tema01/EtlAWS/#1-creacion-de-tablas","title":"1. Creaci\u00f3n de Tablas","text":"<ul> <li>Define tablas en Athena para organizar y consultar tus datos en Amazon S3. Puedes crear tablas externas que hacen referencia a datos en S3 sin mover los datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de Tablas en Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#2-ejecucion-de-consultas","title":"2. Ejecuci\u00f3n de Consultas","text":"<ul> <li>Utiliza la consola de Athena o herramientas como AWS Glue DataBrew para ejecutar consultas SQL en tus datos en Amazon S3.</li> </ul> <p>Documentaci\u00f3n Relacionada: Ejecuci\u00f3n de Consultas en Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#3-gestion-de-resultados","title":"3. Gesti\u00f3n de Resultados","text":"<ul> <li>Administra y descarga los resultados de tus consultas en Athena para su an\u00e1lisis o almacenamiento en otros servicios de AWS.</li> </ul> <p>Documentaci\u00f3n Relacionada: Gesti\u00f3n de Resultados de Consultas en Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#casos-de-uso-comunes-de-amazon-athena","title":"Casos de Uso Comunes de Amazon Athena","text":""},{"location":"SBD/Tema01/EtlAWS/#1-analisis-de-datos-en-amazon-s3","title":"1. An\u00e1lisis de Datos en Amazon S3","text":"<ul> <li>Utiliza Athena para analizar y consultar datos en Amazon S3 sin necesidad de moverlos a una base de datos.</li> </ul>"},{"location":"SBD/Tema01/EtlAWS/#2-analisis-de-logs-y-registros","title":"2. An\u00e1lisis de Logs y Registros","text":"<ul> <li>Examina registros y datos de aplicaci\u00f3n almacenados en Amazon S3 para obtener informaci\u00f3n sobre el rendimiento y el comportamiento de las aplicaciones.</li> </ul>"},{"location":"SBD/Tema01/EtlAWS/#3-exploracion-de-datos","title":"3. Exploraci\u00f3n de Datos","text":"<ul> <li>Realiza an\u00e1lisis exploratorios de datos utilizando consultas SQL en datos semiestructurados o no estructurados.</li> </ul> <p>Documentaci\u00f3n Relacionada: Casos de Uso de Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#recomendaciones-de-seguridad_1","title":"Recomendaciones de Seguridad","text":"<ul> <li>Control de Acceso: Configura pol\u00edticas de control de acceso para garantizar que solo usuarios autorizados puedan ejecutar consultas en Athena.</li> </ul> <p>Documentaci\u00f3n Relacionada: Control de Acceso en Athena - AWS</p> <ul> <li>Cifrado de Datos: Habilita el cifrado de datos en reposo y en tr\u00e1nsito para proteger la confidencialidad de tus datos en Athena.</li> </ul> <p>Documentaci\u00f3n Relacionada: Cifrado de Datos en Athena - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#ayuda-y-documentacion_1","title":"Ayuda y Documentaci\u00f3n","text":"<p>Para obtener m\u00e1s detalles sobre Amazon Athena y c\u00f3mo utilizarlo en tus proyectos, puedes consultar la documentaci\u00f3n oficial de Amazon Athena. Adem\u00e1s, AWS ofrece ejemplos de c\u00f3digo y tutoriales para facilitar la implementaci\u00f3n.</p>"},{"location":"SBD/Tema01/EtlAWS/#conclusion_1","title":"Conclusi\u00f3n","text":"<p>Amazon Athena es una herramienta poderosa para analizar datos en Amazon S3 mediante consultas SQL est\u00e1ndar. Al comprender los conceptos clave y las mejores pr\u00e1cticas de seguridad, puedes aprovechar al m\u00e1ximo este servicio para realizar an\u00e1lisis de datos eficaces en tu organizaci\u00f3n.</p> <p>Claro, aqu\u00ed tienes una documentaci\u00f3n detallada sobre c\u00f3mo realizar una ETL (Extract, Transform, Load) utilizando los servicios de AWS, junto con enlaces a la documentaci\u00f3n oficial de AWS para obtener m\u00e1s informaci\u00f3n detallada.</p>"},{"location":"SBD/Tema01/EtlAWS/#documentacion-realizacion-de-una-etl-con-servicios-de-aws","title":"Documentaci\u00f3n: Realizaci\u00f3n de una ETL con Servicios de AWS","text":""},{"location":"SBD/Tema01/EtlAWS/#introduccion-a-etl-en-aws","title":"Introducci\u00f3n a ETL en AWS","text":"<p>El proceso ETL (Extract, Transform, Load) es fundamental para la gesti\u00f3n y preparaci\u00f3n de datos en la nube de AWS. AWS ofrece una variedad de servicios que facilitan la ejecuci\u00f3n de ETL en la nube.</p> <p>Documentaci\u00f3n Oficial de AWS sobre ETL: ETL en AWS - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#componentes-clave-de-una-etl-en-aws","title":"Componentes Clave de una ETL en AWS","text":""},{"location":"SBD/Tema01/EtlAWS/#1-amazon-s3","title":"1. Amazon S3","text":"<ul> <li>Amazon S3: Utiliza Amazon Simple Storage Service (Amazon S3) como el almacenamiento central para tus datos brutos y transformados. Amazon S3 es escalable y altamente duradero.</li> </ul> <p>Documentaci\u00f3n Relacionada: Amazon S3 - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#2-aws-glue","title":"2. AWS Glue","text":"<ul> <li>AWS Glue: Utiliza AWS Glue para automatizar tareas de extracci\u00f3n, transformaci\u00f3n y carga de datos. AWS Glue es un servicio de ETL totalmente administrado.</li> </ul> <p>Documentaci\u00f3n Relacionada: AWS Glue - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#3-aws-step-functions","title":"3. AWS Step Functions","text":"<ul> <li>AWS Step Functions: Utiliza AWS Step Functions para orquestar flujos de trabajo de ETL que involucran m\u00faltiples pasos y servicios de AWS.</li> </ul> <p>Documentaci\u00f3n Relacionada: AWS Step Functions - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#4-herramientas-de-analisis","title":"4. Herramientas de An\u00e1lisis","text":"<ul> <li>Herramientas de An\u00e1lisis: Utiliza herramientas de an\u00e1lisis como Amazon Athena, Amazon Redshift o AWS QuickSight para analizar los datos transformados despu\u00e9s de la carga.</li> </ul> <p>Documentaci\u00f3n Relacionada: Herramientas de An\u00e1lisis en AWS - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#configuracion-y-uso-basico-de-una-etl-en-aws","title":"Configuraci\u00f3n y Uso B\u00e1sico de una ETL en AWS","text":""},{"location":"SBD/Tema01/EtlAWS/#1-configuracion-de-almacenamiento","title":"1. Configuraci\u00f3n de Almacenamiento","text":"<ul> <li>Configura un Bucket de Amazon S3: Crea un bucket de Amazon S3 para almacenar tus datos brutos y transformados.</li> </ul> <p>Documentaci\u00f3n Relacionada: Crear un Bucket de S3 - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#2-extraccion-de-datos","title":"2. Extracci\u00f3n de Datos","text":"<ul> <li>Utiliza AWS Glue Crawlers: Configura y ejecuta AWS Glue Crawlers para descubrir y catalogar autom\u00e1ticamente los datos en tus fuentes, como bases de datos, archivos y servicios.</li> </ul> <p>Documentaci\u00f3n Relacionada: Configurar AWS Glue Crawlers - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#3-transformacion-de-datos","title":"3. Transformaci\u00f3n de Datos","text":"<ul> <li>Utiliza AWS Glue ETL Jobs: Crea trabajos de ETL en AWS Glue para transformar datos seg\u00fan tus necesidades. Puedes utilizar el editor de scripts de Python de AWS Glue para personalizar las transformaciones.</li> </ul> <p>Documentaci\u00f3n Relacionada: Crear un Job de AWS Glue ETL - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#4-carga-de-datos","title":"4. Carga de Datos","text":"<ul> <li>Carga de Datos en Amazon S3: Despu\u00e9s de la transformaci\u00f3n, carga los datos en un bucket de Amazon S3 para su posterior an\u00e1lisis.</li> </ul> <p>Documentaci\u00f3n Relacionada: Cargar Datos en Amazon S3 - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#5-orquestacion-de-flujos-de-trabajo","title":"5. Orquestaci\u00f3n de Flujos de Trabajo","text":"<ul> <li>Orquesta Flujos de Trabajo con AWS Step Functions: Utiliza AWS Step Functions para orquestar flujos de trabajo de ETL que involucran extracci\u00f3n, transformaci\u00f3n y carga de datos.</li> </ul> <p>Documentaci\u00f3n Relacionada: Orquestaci\u00f3n de Flujos de Trabajo con AWS Step Functions - AWS</p>"},{"location":"SBD/Tema01/EtlAWS/#recomendaciones-de-mejores-practicas","title":"Recomendaciones de Mejores Pr\u00e1cticas","text":"<ul> <li> <p>Seguridad y Gobernanza: Implementa pol\u00edticas de seguridad y gobernanza para proteger tus datos y garantizar la conformidad con las regulaciones.</p> </li> <li> <p>Monitorizaci\u00f3n y Auditor\u00eda: Establece una soluci\u00f3n de monitorizaci\u00f3n y auditor\u00eda para supervisar el rendimiento y la calidad de los flujos de trabajo de ETL.</p> </li> <li> <p>Automatizaci\u00f3n: Utiliza la automatizaci\u00f3n para ejecutar flujos de trabajo de ETL de manera regular y confiable.</p> </li> </ul>"},{"location":"SBD/Tema01/EtlAWS/#ejemplo-practico-de-etl-con-aws","title":"Ejemplo Pr\u00e1ctico de ETL con AWS","text":"<p>A continuaci\u00f3n, se muestra un ejemplo simplificado de un flujo de trabajo de ETL utilizando AWS Glue y Amazon S3:</p> <ol> <li> <p>Configura un bucket de Amazon S3 para almacenar los datos brutos.</p> </li> <li> <p>Crea un Crawler de AWS Glue para catalogar autom\u00e1ticamente los datos en el bucket.</p> </li> <li> <p>Crea un Job de AWS Glue ETL para transformar los datos catalogados.</p> </li> <li> <p>Ejecuta el Job de AWS Glue para realizar la transformaci\u00f3n y carga los datos transformados en otro bucket de Amazon S3.</p> </li> <li> <p>Utiliza Amazon Athena para consultar y analizar los datos transformados.</p> </li> </ol> <p>Este es solo un ejemplo b\u00e1sico, y los flujos de trabajo de ETL pueden ser mucho m\u00e1s complejos seg\u00fan las necesidades de tu organizaci\u00f3n.</p>"},{"location":"SBD/Tema01/EtlAWS/#ayuda-y-documentacion-adicional","title":"Ayuda y Documentaci\u00f3n Adicional","text":"<p>Para obtener m\u00e1s detalles sobre c\u00f3mo realizar una ETL con servicios de AWS, consulta la documentaci\u00f3n oficial de AWS sobre ETL. Adem\u00e1s, AWS ofrece tutoriales y ejemplos detallados para ayudarte en tu proyecto de ETL en la nube de AWS.</p>"},{"location":"SBD/Tema01/EtlAWS/#conclusion_2","title":"Conclusi\u00f3n","text":"<p>Realizar una ETL en AWS es esencial para la gesti\u00f3n de datos y an\u00e1lisis en la nube. Utilizando los servicios de AWS como AWS Glue, Amazon S3 y AWS Step Functions, puedes automatizar y simplificar el proceso de extracci\u00f3n, transformaci\u00f3n y carga de datos para satisfacer las necesidades de tu organizaci\u00f3n.</p> <p>Puedes encontrar ejemplos pr\u00e1cticos de c\u00f3mo realizar una ETL (Extract, Transform, Load) en AWS en varios lugares, incluyendo la documentaci\u00f3n oficial de AWS, tutoriales en l\u00ednea y recursos de la comunidad. Aqu\u00ed te proporciono un ejemplo sencillo de una ETL utilizando AWS Glue y Amazon S3 como punto de partida:</p> <p>Escenario: Supongamos que tienes datos brutos almacenados en Amazon S3 en formato CSV y deseas realizar una ETL para transformar estos datos y cargarlos en otra ubicaci\u00f3n en Amazon S3 en formato Parquet.</p> <p>Pasos para un Ejemplo Pr\u00e1ctico de ETL en AWS:</p> <ol> <li>Configuraci\u00f3n de Almacenamiento en Amazon S3:</li> <li>Crea un bucket de Amazon S3 para almacenar tus datos brutos y transformados.</li> <li> <p>Por ejemplo, crea dos carpetas en tu bucket: <code>datos_brutos</code> y <code>datos_transformados</code>.</p> </li> <li> <p>Utiliza AWS Glue Crawlers para Descubrir los Datos:</p> </li> <li> <p>Configura un Crawler de AWS Glue para descubrir y catalogar autom\u00e1ticamente los datos en la carpeta <code>datos_brutos</code> de tu bucket de S3.</p> </li> <li> <p>Crea un Job de AWS Glue ETL:</p> </li> <li>Crea un trabajo de ETL en AWS Glue utilizando el editor de scripts de Python de Glue.</li> <li> <p>Define la transformaci\u00f3n que deseas aplicar a tus datos. Por ejemplo, puedes seleccionar columnas, filtrar filas o realizar agregaciones.</p> </li> <li> <p>Ejecuta el Job de AWS Glue:</p> </li> <li>Ejecuta el trabajo de ETL de AWS Glue para realizar la transformaci\u00f3n de datos.</li> <li> <p>Durante el proceso de transformaci\u00f3n, guarda los datos transformados en la carpeta <code>datos_transformados</code> en tu bucket de S3 en formato Parquet.</p> </li> <li> <p>An\u00e1lisis de los Datos Transformados:</p> </li> <li>Utiliza herramientas de an\u00e1lisis como Amazon Athena o Amazon Redshift para consultar y analizar los datos transformados en formato Parquet.</li> </ol> <p>Este es un ejemplo simplificado de una ETL en AWS utilizando AWS Glue y Amazon S3. Puedes adaptar este escenario b\u00e1sico seg\u00fan tus necesidades espec\u00edficas. Para ejemplos m\u00e1s detallados y casos de uso m\u00e1s complejos, te recomiendo consultar la documentaci\u00f3n oficial de AWS, tutoriales en l\u00ednea y recursos de la comunidad, donde encontrar\u00e1s ejemplos pr\u00e1cticos adicionales y proyectos de ETL m\u00e1s avanzados. Tambi\u00e9n puedes explorar ejemplos de c\u00f3digo y scripts de ETL en repositorios de GitHub y foros de discusi\u00f3n relacionados con AWS.</p> <p>Por supuesto, aqu\u00ed te proporciono un conjunto de datos de ejemplo en formato CSV que podr\u00edas utilizar en el escenario de ETL en AWS que describ\u00ed anteriormente. Estos datos representan informaci\u00f3n ficticia de ventas:</p> <p>datos_brutos/ejemplo_ventas.csv:</p> <pre><code>fecha,producto,cantidad,precio\n2023-01-01,Producto A,10,100.00\n2023-01-01,Producto B,5,75.00\n2023-01-02,Producto A,8,100.00\n2023-01-02,Producto C,3,50.00\n2023-01-03,Producto B,12,75.00\n2023-01-03,Producto A,15,100.00\n2023-01-04,Producto C,6,50.00\n2023-01-04,Producto A,20,100.00\n2023-01-05,Producto B,7,75.00\n2023-01-05,Producto C,4,50.00\n</code></pre> <p>Estos datos representan ventas diarias de tres productos diferentes durante cinco d\u00edas. Cada fila contiene la fecha de la venta, el producto vendido, la cantidad y el precio unitario.</p> <p>Puedes cargar estos datos en tu bucket de Amazon S3 en la carpeta <code>datos_brutos</code> y utilizar AWS Glue para realizar la transformaci\u00f3n y guardar los datos transformados en la carpeta <code>datos_transformados</code> en formato Parquet.</p> <p>Recuerda que estos datos son solo un ejemplo y puedes adaptarlos seg\u00fan tus necesidades y el escenario de tu proyecto de ETL en AWS.</p>"},{"location":"SBD/Tema01/PracticasAWS/","title":"12. Practicas AWS","text":""},{"location":"SBD/Tema01/PracticasAWS/#121-practica-etl-en-aws","title":"12.1. Practica ETL en AWS","text":"<ul> <li>En un bucket S3 (datos_etl) crear dos directorios</li> <li>ciclistas</li> <li>ciclistas_procesados</li> <li>Con AWS Glue</li> <li>Utilizando el Data Catalog, crear:<ul> <li>Base de datos (datos_ciclistas)</li> <li>Tabla (ciclistas)</li> </ul> </li> <li>Crear un job (Lab Role) S3 Originales --&gt; Eliminar Duplicados --&gt; Filtrar filas --&gt; S3 Procesados</li> <li>RedShift (Lab Role)</li> <li>Crear cluster admin Qwe_1234</li> <li>Crear Base de Datos</li> <li>Crear Tabla y Definir campos</li> <li>Cargar datos en la Tabla (IGNOREHEADER AS 1)</li> <li>Crear una funci\u00f3n Lamda que haga de trigger (lanzador) del Job</li> </ul>"},{"location":"SBD/Tema01/PracticasAWS/#122-etl-con-jobs-en-aws-glue","title":"12.2. ETL con jobs en AWS Glue","text":"<p>Servicios AWS: - AWS S3 - AWS Glue Studio - AWS Glue Data Catalog - AWS Glue Job - AWS RedShift - AWS Lambda</p> <p>La pr\u00e1ctica consiste en hacer una ETL con AWS Glue utilizando un Job Visual. Los datos de partida son un fichero en formato csv con datos de ciclistas. Cargaremos los datos en un bucket S3 que tendr\u00e1 dos carpetas, una para los datos de entrada y otra para los datos procesados. Crearemos un job que elimine los duplicados y haga un filtro y seleccione solo las filas con el campo Severity = \"Grave\". Luego cargaremos los datos en un cluster RedShift y finalmente prepararemos una funci\u00f3n lambda que lance el job. Revisaremos c\u00f3mo se monitorizan los jobs y las funciones lambda.</p> <p>Los campos del fichero son:</p> <p>Pasos a seguir: - En un bucket S3 (datos_etl) crear dos directorios   - ciclistas   - ciclistas_procesados - Con AWS Glue   - Utilizando el Data Catalog, crear:     - Base de datos (datos_ciclistas)     - Tabla (ciclistas)   - Crear un job (Lab Role) S3 Originales --&gt; Eliminar Duplicados --&gt; Filtrar filas --&gt; S3 Procesados - RedShift (Lab Role)   - Crear cluster admin Qwe_1234   - Crear Base de Datos   - Crear Tabla y Definir campos   - Cargar datos en la Tabla (IGNOREHEADER AS 1) - Crear una funci\u00f3n Lambda que haga de trigger (lanzador) del Job</p>"},{"location":"SBD/Tema01/PracticasAWS/#123-etl-con-pyspark","title":"12.3. ETL con PySpark","text":"<p>Servicios AWS: - AWS S3 - AWS Glue Studio - AWS Glue Data Catalog - AWS Glue Job - AWS Glue Crawler - AWS Glue Workflow</p> <p>La pr\u00e1ctica consiste en hacer una ETL con AWS Glue utilizando c\u00f3digo PySpark. Los datos de partida son dos ficheros en formato csv con datos de clientes y ventas. Cargaremos los datos en un bucket S3 que tambi\u00e9n tendr\u00e1 una carpeta para el script de PySpark y otra para los resultados de salida. Con estos datos queremos un fichero con las ventas totales por cliente en formato JSON.</p> <p>Los campos de los ficheros son: - customers: {CUSTOMERID, CUSTOMERNAME, EMAIL, CITY, COUNTRY, TERRITORY, CONTACTFIRSTNAME, CONTACTLASTNAME} - sales: {ORDERNUMBER, QUANTITYORDERED, PRICEEACH, ORDERLINENUMBER, SALES, ORDERDATE, STATUS, QTR_ID, MONTH_ID, YEAR_ID, PRODUCTLINE, MSRP, PRODUCTCODE, DEALSIZE, CUSTOMERID}</p> <p>Pasos a seguir: - Crear un bucket (lago de datos) S3 con la siguiente estructura de carpetas y ficheros:   - datos     - clientes       - customers.csv     - ventas       - sales.csv   - Crear un crawler con AWS Glue que rastree la carpeta datos y los introduzca en una BD (ventas)   - Crear un job con Glue de Spark Script Editor     - El script debe:       - Guardarse en la carpeta scripts del bucket       - Debe seleccionar las ventas totales por cliente y guardarlas en un fichero en formato JSON en la carpeta de salida   - Crear un flujo de trabajo que lo haga todo.     - A\u00f1adir Workflow     - A\u00f1adir Trigger       - Inicio Rastreador     - A\u00f1adir Nodo       - Seleccionar Crawler     - A\u00f1adir Trigger       - Type: Evento       - Start after ANY watched event     - A\u00f1adir Job/Crawler       - Seleccionar Crawler       - Evento: \u00c9xito</p> <p>Ejemplo de c\u00f3digo:</p> <pre><code>import sys\nfrom datetime import datetime\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\n\nspark = SparkSession\\\n    .builder\\\n    .appName(\"SparkETL\")\\\n    .getOrCreate()\n\nspark.catalog.setCurrentDatabase(\"ventas\")\ndf = spark.sql(\"select * from clientes\")\n# df.show()\n\ndf = df.select(\"customername\", \"email\")\n# df.show()\n\ndf.write.format(\"json\").mode(\"overwrite\").save(\"s3://lagodatos/salida/\")\n</code></pre>"},{"location":"SBD/Tema01/PracticasAWS/#124-streaming-con-kinesis-data-streams-y-kinesis-data-firehose","title":"12.4. Streaming con Kinesis Data Streams y Kinesis Data Firehose","text":"<p>Servicios AWS: - AWS S3 - AWS Glue Data Catalog - AWS Cloud9 - AWS Kinesis Data Streams - AWS Kinesis Data Firehose</p> <p>La pr\u00e1ctica consiste en crear un escenario en el que Amazon Kinesis Delivery Stream convierte los datos de origen con formato JSON en datos de destino con formato Apache Parquet mediante el esquema de tabla de cat\u00e1logo de Glue y los almacena en un S3.</p> <p>Pasos a seguir: - Crear un bucket S3 - Crear una base de datos y una tabla (Glue Data Catalog) con el siguiente esquema:   - firstname: string   - lastname: string   - age: int - Configurar el data stream (Kinesis Data Streams) - Crear el delivery stream (Kinesis Firehose) - Configurar el entorno de desarrollo - Crear el c\u00f3digo Python que hace la funci\u00f3n de productor</p> <pre><code>import boto3\nimport random\nimport time\n\nclient = boto3.client('kinesis')\n\npartitionkey = random.randint(10, 100);\n\nfor a in range(1, 10, 1):\n    edad = random.randint(1, 90);\n    mydata = '{ \"firstname\": \"John\", \"lastname\": \"Smith\", \"age\": ' + str(edad) + ' }'\n    print(mydata)\n\n    response = client.put_record(StreamName=\"flujo_luis\", Data=mydata, PartitionKey=str(partitionkey))\n    print(response)\n    time.sleep(\n\n5)\n</code></pre>"},{"location":"SBD/Tema01/PracticasAWS/#125-streaming-con-kinesis-data-firehose-y-kinesis-data-analytics","title":"12.5. Streaming con Kinesis Data Firehose y Kinesis Data Analytics","text":"<p>Servicios AWS: - AWS S3 - AWS Kinesis Data Firehose - AWS Kinesis Data Analytics</p> <p>La pr\u00e1ctica consiste en crear un flujo de datos de bolsa con Amazon Kinesis Delivery Stream y con Kinesis Data Analytics guardarlos en un Bucket S3 tanto en crudo tal cual llegan, como ligeramente procesados. Para ello, utilizaremos 4 carpetas en el bucket, dos para los datos limpios (\u00e9xito y errores) y dos para los datos procesados (\u00e9xito y errores): - datos_brutos - errores_datos_brutos - datos_limpios - errores_datos_limpios</p> <p>Vamos a necesitar tambi\u00e9n dos flujos de Kinesis Firehose.</p> <p>Pasos a seguir:</p> <ul> <li>Crear el primer flujo (Firehose) con una entrada directa de datos (DIRECT PUT). Le asignamos las carpetas para el destino que se crear\u00e1n autom\u00e1ticamente.</li> <li>Datos del flujo: 1 Mb o 60 seg</li> <li>Rol: LabRole</li> <li>Realizar el test del Data Stream Delivery</li> <li>Comprobar que se crean los datos en bruto en la carpeta correspondiente</li> <li>Limpieza con Kinesis Data Analytics (con aplicaciones SQL)</li> <li>Crear aplicaci\u00f3n</li> <li>Descubrir el esquema. Confirmar que se est\u00e1n generando los datos de prueba</li> <li>Configurar la plantilla. Funci\u00f3n de agregaci\u00f3n en una ventana deslizante de tiempo</li> <li>Probar y ejecutar</li> <li>Crear el segundo flujo de destino</li> <li>Ejecutar</li> </ul> <p>Ayuda: Enlace a video de ayuda</p> <p>Ejemplos de An\u00e1lisis de Flujo Continuo:</p> <pre><code>-- Continuous Filter\n-- Performs a continuous filter based on a WHERE condition.\n-- .----------.   .----------.   .----------.\n-- |  SOURCE  |   |  INSERT  |   |  DESTIN. |\n-- Source--&gt;|  STREAM  |--&gt;| &amp; SELECT |--&gt;|  STREAM |--&gt;Destination\n-- |          |   |  (PUMP)  |   |          |\n-- '----------'   '----------'   '----------'\n-- STREAM (in-application): a continuously updated entity that you can SELECT from and INSERT into like a TABLE\n-- PUMP: an entity used to continuously 'SELECT ... FROM' a source STREAM, and INSERT SQL results into an output STREAM\n-- Create output stream, which can be used to send to a destination\nCREATE OR REPLACE STREAM \"DESTINATION_SQL_STREAM\" (ticker_symbol VARCHAR(4), sector VARCHAR(12), change REAL, price REAL);\n-- Create pump to insert into output\nCREATE OR REPLACE PUMP \"STREAM_PUMP\" AS INSERT INTO \"DESTINATION_SQL_STREAM\"\n-- Select all columns from source stream\nSELECT STREAM ticker_symbol, sector, change, price\nFROM \"SOURCE_SQL_STREAM_001\"\n-- LIKE compares a string to a string pattern (_ matches all char, % matches substring)\n-- SIMILAR TO compares string to a regex, may use ESCAPE\nWHERE sector SIMILAR TO '%TECH%';\n</code></pre> <pre><code>CREATE OR REPLACE STREAM \"DESTINATION_SQL_STREAM\" (\"eventType\" VARCHAR(16), \"ses_timestamp\" timestamp, \"messageId\" VARCHAR(64), \"ses_to\" VARCHAR(64), \"ses_configuration_set\" VARCHAR(32));\n\nCREATE OR REPLACE PUMP \"STREAM_PUMP\" AS INSERT INTO \"DESTINATION_SQL_STREAM\"\n\nSELECT STREAM \"eventType\", \"ses_timestamp\", \"messageId\", \"ses_to\", \"ses_configuration_set\"\nFROM \"SOURCE_SQL_STREAM_001\"\nWHERE \"eventType\" = 'Send'\n</code></pre>"},{"location":"SBD/Tema01/PracticasAWS/#126-visualizacion-de-datos-con-quicksight","title":"12.6. Visualizaci\u00f3n de datos con QuickSight","text":"<p>Para todos los ejercicios pr\u00e1cticos, utilizaremos el archivo de datos SaaS-Sales.csv proporcionado aqu\u00ed.</p> <p>Este conjunto de datos representa datos de ventas de una empresa ficticia de SaaS (Software como Servicio) que vende software de ventas y marketing a otras empresas (B2B). Cada fila de datos es una transacci\u00f3n/pedido.</p> <p>Servicios AWS: - AWS QuickSight</p> <p>Pasos a seguir: - Acceder a AWS QuickSight - Registrarse (gratis 30 d\u00edas) - Crear un nuevo an\u00e1lisis - Cargar un dataset - Empezar a a\u00f1adir visualizaciones - Publicar el informe</p> <p>Ayuda: Enlace al tutorial de ayuda</p>"},{"location":"SBD/Tema01/RedShiftAWS/","title":"Documentaci\u00f3n: AWS Redshift - Almacenamiento de Datos y An\u00e1lisis","text":"<p>Amazon Redshift es un servicio de almac\u00e9n de datos en la nube totalmente administrado y escalable. Permite a las organizaciones almacenar grandes vol\u00famenes de datos y realizar an\u00e1lisis complejos de manera eficiente. A continuaci\u00f3n, encontrar\u00e1s una gu\u00eda detallada sobre AWS Redshift, junto con enlaces a la documentaci\u00f3n oficial de AWS para obtener informaci\u00f3n adicional.</p>"},{"location":"SBD/Tema01/RedShiftAWS/#introduccion-a-amazon-redshift","title":"Introducci\u00f3n a Amazon Redshift","text":""},{"location":"SBD/Tema01/RedShiftAWS/#que-es-amazon-redshift","title":"\u00bfQu\u00e9 es Amazon Redshift?","text":"<p>Amazon Redshift es un servicio de almac\u00e9n de datos en la nube que permite a las organizaciones almacenar, consultar y analizar grandes conjuntos de datos de manera eficiente. Est\u00e1 dise\u00f1ado para admitir cargas de trabajo de an\u00e1lisis de datos y se basa en una arquitectura de almacenamiento columnar y distribuida.</p> <p>Documentaci\u00f3n Oficial de AWS sobre Amazon Redshift: Amazon Redshift - Documentaci\u00f3n de AWS</p>"},{"location":"SBD/Tema01/RedShiftAWS/#caracteristicas-clave-de-amazon-redshift","title":"Caracter\u00edsticas Clave de Amazon Redshift","text":""},{"location":"SBD/Tema01/RedShiftAWS/#1-almacenamiento-columnar","title":"1. Almacenamiento Columnar","text":"<ul> <li>Amazon Redshift almacena los datos en formato columnar, lo que permite un acceso m\u00e1s r\u00e1pido y eficiente a los datos relevantes para consultas.</li> </ul>"},{"location":"SBD/Tema01/RedShiftAWS/#2-escalabilidad","title":"2. Escalabilidad","text":"<ul> <li>Redshift es escalable, lo que significa que puedes aumentar o reducir la capacidad de almacenamiento y c\u00f3mputo seg\u00fan las necesidades de tu organizaci\u00f3n.</li> </ul>"},{"location":"SBD/Tema01/RedShiftAWS/#3-integracion-con-herramientas-de-analisis","title":"3. Integraci\u00f3n con Herramientas de An\u00e1lisis","text":"<ul> <li>Redshift es compatible con una variedad de herramientas de an\u00e1lisis y visualizaci\u00f3n, como Tableau, Power BI y Quicksight.</li> </ul>"},{"location":"SBD/Tema01/RedShiftAWS/#4-seguridad-y-cumplimiento","title":"4. Seguridad y Cumplimiento","text":"<ul> <li>Ofrece capacidades de seguridad avanzadas, incluyendo encriptaci\u00f3n, autenticaci\u00f3n basada en IAM y auditor\u00eda de consultas.</li> </ul>"},{"location":"SBD/Tema01/RedShiftAWS/#configuracion-y-uso-basico-de-amazon-redshift","title":"Configuraci\u00f3n y Uso B\u00e1sico de Amazon Redshift","text":""},{"location":"SBD/Tema01/RedShiftAWS/#1-creacion-de-un-cluster","title":"1. Creaci\u00f3n de un Cluster","text":"<ul> <li>Inicia sesi\u00f3n en la consola de AWS y crea un cluster de Amazon Redshift. Configura el tama\u00f1o del cluster y otros par\u00e1metros seg\u00fan tus necesidades.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de un Cluster de Amazon Redshift - AWS</p>"},{"location":"SBD/Tema01/RedShiftAWS/#2-configuracion-de-conexiones","title":"2. Configuraci\u00f3n de Conexiones","text":"<ul> <li>Configura las conexiones a tu cluster Redshift desde aplicaciones y herramientas de an\u00e1lisis. Obt\u00e9n la cadena de conexi\u00f3n y las credenciales necesarias.</li> </ul> <p>Documentaci\u00f3n Relacionada: Configuraci\u00f3n de Conexiones de Amazon Redshift - AWS</p>"},{"location":"SBD/Tema01/RedShiftAWS/#3-creacion-de-tablas-y-cargas-de-datos","title":"3. Creaci\u00f3n de Tablas y Cargas de Datos","text":"<ul> <li>Utiliza SQL para crear tablas en tu cluster Redshift y carga datos desde fuentes externas, como archivos CSV o desde otros sistemas de almacenamiento.</li> </ul> <p>Documentaci\u00f3n Relacionada: Creaci\u00f3n de Tablas y Carga de Datos en Redshift - AWS</p>"},{"location":"SBD/Tema01/RedShiftAWS/#4-consultas-y-analisis","title":"4. Consultas y An\u00e1lisis","text":"<ul> <li>Utiliza herramientas de an\u00e1lisis y consulta SQL para explorar y analizar tus datos almacenados en Redshift.</li> </ul> <p>Documentaci\u00f3n Relacionada: Consultas y An\u00e1lisis en Amazon Redshift - AWS</p>"},{"location":"SBD/Tema01/RedShiftAWS/#5-seguridad","title":"5. Seguridad","text":"<ul> <li>Configura la seguridad en Redshift mediante la gesti\u00f3n de grupos de seguridad, la encriptaci\u00f3n de datos y la autenticaci\u00f3n IAM.</li> </ul> <p>Documentaci\u00f3n Relacionada: Seguridad en Amazon Redshift - AWS</p>"},{"location":"SBD/Tema01/RedShiftAWS/#recomendaciones-de-mejores-practicas","title":"Recomendaciones de Mejores Pr\u00e1cticas","text":"<ul> <li> <p>Realiza copias de seguridad y mant\u00e9n una estrategia de recuperaci\u00f3n ante desastres.</p> </li> <li> <p>Monitorea el rendimiento del cluster y ajusta la capacidad de acuerdo a las cargas de trabajo.</p> </li> <li> <p>Utiliza anal\u00edtica y visualizaci\u00f3n de datos para obtener informaci\u00f3n valiosa de tus datos almacenados en Redshift.</p> </li> </ul>"},{"location":"SBD/Tema01/RedShiftAWS/#ejemplo-practico-de-uso-de-amazon-redshift","title":"Ejemplo Pr\u00e1ctico de Uso de Amazon Redshift","text":"<p>A continuaci\u00f3n, un ejemplo simplificado de c\u00f3mo utilizar Amazon Redshift:</p> <ol> <li> <p>Crear un cluster de Redshift en la consola de AWS.</p> </li> <li> <p>Utilizar una herramienta de administraci\u00f3n SQL o una aplicaci\u00f3n de an\u00e1lisis para conectarse al cluster y crear una base de datos.</p> </li> <li> <p>Crear tablas en la base de datos y cargar datos desde un archivo CSV.</p> </li> <li> <p>Ejecutar consultas SQL para analizar los datos y obtener informaci\u00f3n valiosa.</p> </li> </ol> <p>Este es un escenario b\u00e1sico, y Redshift es altamente configurable y escalable seg\u00fan las necesidades de tu organizaci\u00f3n.</p>"},{"location":"SBD/Tema01/RedShiftAWS/#ayuda-y-documentacion-adicional","title":"Ayuda y Documentaci\u00f3n Adicional","text":"<p>Para obtener m\u00e1s detalles sobre Amazon Redshift y c\u00f3mo utilizarlo, consulta la documentaci\u00f3n oficial de AWS sobre Amazon Redshift. Adem\u00e1s, AWS ofrece tutoriales y ejemplos de implementaci\u00f3n para ayudarte en tu proyecto de an\u00e1lisis de datos con Redshift.</p> <p>Puedes encontrar ejemplos pr\u00e1cticos de c\u00f3mo utilizar Amazon Redshift en la documentaci\u00f3n oficial de AWS, as\u00ed como en tutoriales y recursos en l\u00ednea. Aqu\u00ed te proporciono un ejemplo pr\u00e1ctico sencillo para que puedas comenzar:</p> <p>Escenario: Supongamos que tienes un conjunto de datos de ventas en formato CSV y deseas utilizar Amazon Redshift para crear un almac\u00e9n de datos y realizar an\u00e1lisis b\u00e1sicos.</p> <p>Pasos para un Ejemplo Pr\u00e1ctico:</p> <ol> <li>Crear un Cluster Redshift:</li> <li>Inicia sesi\u00f3n en la consola de AWS.</li> <li>Navega a Amazon Redshift y crea un nuevo cluster.</li> <li> <p>Configura el tama\u00f1o del cluster, las opciones de seguridad y otras configuraciones seg\u00fan tus necesidades.</p> </li> <li> <p>Conectar a tu Cluster:</p> </li> <li>Utiliza una herramienta de SQL como SQL Workbench/J o una aplicaci\u00f3n de an\u00e1lisis compatible con Redshift para conectarte a tu cluster.</li> <li> <p>Proporciona la cadena de conexi\u00f3n y las credenciales del cluster.</p> </li> <li> <p>Crear una Base de Datos:</p> </li> <li>Utiliza SQL para crear una base de datos en tu cluster.</li> <li> <p>Por ejemplo:    <pre><code>CREATE DATABASE ventas;\n</code></pre></p> </li> <li> <p>Crear Tablas y Cargar Datos:</p> </li> <li>Crea tablas en la base de datos para almacenar los datos de ventas.</li> <li>Carga los datos desde tus archivos CSV en las tablas.</li> <li> <p>Por ejemplo:    <pre><code>CREATE TABLE ventas (\nid INT,\nfecha DATE,\nproducto VARCHAR(255),\ncantidad INT,\nprecio DECIMAL(10, 2)\n);\n\nCOPY ventas FROM 's3://tu-bucket/tu-archivo.csv'\nCREDENTIALS 'aws_access_key_id=TU_ACCESS_KEY;aws_secret_access_key=TU_SECRET_KEY'\nDELIMITER ','\nCSV;\n</code></pre></p> </li> <li> <p>Consultas y An\u00e1lisis:</p> </li> <li>Ejecuta consultas SQL para analizar tus datos.</li> <li> <p>Por ejemplo, puedes calcular el total de ventas por producto:    <pre><code>SELECT producto, SUM(precio * cantidad) AS total_ventas\nFROM ventas\nGROUP BY producto;\n</code></pre></p> </li> <li> <p>Gesti\u00f3n de Seguridad:</p> </li> <li>Configura la seguridad de tu cluster Redshift para garantizar que solo usuarios autorizados puedan acceder a los datos.</li> </ol> <p>Este es un ejemplo muy simplificado, pero te da una idea de c\u00f3mo puedes utilizar Amazon Redshift para crear un almac\u00e9n de datos y realizar an\u00e1lisis b\u00e1sicos. Para escenarios m\u00e1s complejos y ejemplos detallados, te recomiendo consultar los recursos adicionales proporcionados en la documentaci\u00f3n de AWS y en tutoriales en l\u00ednea. Adem\u00e1s, puedes explorar ejemplos y proyectos de c\u00f3digo en plataformas de desarrollo como GitHub, donde encontrar\u00e1s casos de uso m\u00e1s avanzados de Amazon Redshift.</p>"},{"location":"SBD/Tema01/VpcAWS/","title":"Documentaci\u00f3n: Amazon Virtual Private Cloud (Amazon VPC)","text":""},{"location":"SBD/Tema01/VpcAWS/#introduccion-a-amazon-vpc","title":"Introducci\u00f3n a Amazon VPC","text":"<p>Amazon Virtual Private Cloud (Amazon VPC) es un servicio de red que te permite crear una red virtual aislada en la nube de AWS. Con Amazon VPC, puedes controlar la topolog\u00eda de red, asignar direcciones IP, definir tablas de rutas y aplicar reglas de seguridad para tus recursos en la nube. VPC te permite crear una extensi\u00f3n virtual de tu centro de datos en AWS.</p>"},{"location":"SBD/Tema01/VpcAWS/#conceptos-clave-de-amazon-vpc","title":"Conceptos Clave de Amazon VPC","text":""},{"location":"SBD/Tema01/VpcAWS/#1-red-virtual-vpc","title":"1. Red Virtual (VPC)","text":"<ul> <li>VPC: Una VPC es tu propia red virtual en la nube de AWS. Puedes personalizar su topolog\u00eda, direcciones IP y configuraci\u00f3n de red.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#2-subredes","title":"2. Subredes","text":"<ul> <li>Subredes: Una VPC se divide en subredes. Puedes crear subredes p\u00fablicas y privadas seg\u00fan tus necesidades.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#3-tablas-de-rutas","title":"3. Tablas de Rutas","text":"<ul> <li>Tablas de Rutas: Las tablas de rutas definen c\u00f3mo se enrutan los paquetes dentro y fuera de la VPC. Puedes personalizar las rutas y las reglas.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#4-grupos-de-seguridad","title":"4. Grupos de Seguridad","text":"<ul> <li>Grupos de Seguridad: Los grupos de seguridad son cortafuegos virtuales que controlan el tr\u00e1fico de entrada y salida de las instancias EC2.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#5-listas-de-control-de-acceso-a-la-red-nacl","title":"5. Listas de Control de Acceso a la Red (NACL)","text":"<ul> <li>NACL: Las NACL son conjuntos de reglas que controlan el tr\u00e1fico de subredes en la VPC.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#6-vpn-y-direct-connect","title":"6. VPN y Direct Connect","text":"<ul> <li>VPN y Direct Connect: Amazon VPC te permite conectar tu red local a la VPC mediante una conexi\u00f3n VPN o Direct Connect para acceso privado.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#configuracion-de-amazon-vpc","title":"Configuraci\u00f3n de Amazon VPC","text":""},{"location":"SBD/Tema01/VpcAWS/#1-creacion-de-una-vpc","title":"1. Creaci\u00f3n de una VPC","text":"<ul> <li>Define una VPC especificando su rango de direcciones IP y configuraci\u00f3n de red.</li> <li>Puedes seleccionar un rango de direcciones IP IPv4 CIDR para tu VPC.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#2-creacion-de-subredes","title":"2. Creaci\u00f3n de Subredes","text":"<ul> <li>Divide tu VPC en subredes p\u00fablicas y privadas.</li> <li>Configura las tablas de rutas para permitir o denegar el tr\u00e1fico.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#3-configuracion-de-grupos-de-seguridad","title":"3. Configuraci\u00f3n de Grupos de Seguridad","text":"<ul> <li>Define grupos de seguridad para controlar el tr\u00e1fico de red a instancias EC2.</li> <li>Asigna reglas de entrada y salida a los grupos de seguridad.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#4-configuracion-de-nacl","title":"4. Configuraci\u00f3n de NACL","text":"<ul> <li>Configura listas de control de acceso a la red (NACL) para controlar el tr\u00e1fico de subredes.</li> <li>Define reglas de entrada y salida en las NACL.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#escenarios-comunes-en-amazon-vpc","title":"Escenarios Comunes en Amazon VPC","text":""},{"location":"SBD/Tema01/VpcAWS/#1-vpc-con-subredes-publicas-y-privadas","title":"1. VPC con Subredes P\u00fablicas y Privadas","text":"<ul> <li>Crea una VPC con subredes p\u00fablicas que tienen acceso a Internet y subredes privadas que est\u00e1n aisladas.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#2-conexion-a-una-red-local","title":"2. Conexi\u00f3n a una Red Local","text":"<ul> <li>Configura una VPN o Direct Connect para conectar tu red local a tu VPC en AWS.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#3-despliegue-de-aplicaciones-en-vpc","title":"3. Despliegue de Aplicaciones en VPC","text":"<ul> <li>Implementa aplicaciones y servicios en tus subredes personalizadas dentro de la VPC.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#recomendaciones-de-seguridad","title":"Recomendaciones de Seguridad","text":"<ul> <li>Seguridad de Grupos: Asigna grupos de seguridad para controlar el tr\u00e1fico de red a nivel de instancia.</li> <li>Aislamiento de Subredes: Dise\u00f1a subredes para aislar componentes cr\u00edticos.</li> <li>Monitoreo y Auditor\u00eda: Habilita el monitoreo y la auditor\u00eda de red para supervisar y proteger tu VPC.</li> </ul>"},{"location":"SBD/Tema01/VpcAWS/#ayuda-y-documentacion","title":"Ayuda y Documentaci\u00f3n","text":"<p>Amazon VPC ofrece documentaci\u00f3n detallada y ejemplos de configuraci\u00f3n en la documentaci\u00f3n oficial de AWS. Tambi\u00e9n puedes utilizar la Consola de AWS para configurar y administrar tu VPC de manera visual.</p>"},{"location":"SBD/Tema01/VpcAWS/#conclusion","title":"Conclusion","text":"<p>Amazon Virtual Private Cloud (Amazon VPC) es un servicio esencial para crear y administrar redes virtuales personalizadas en la nube de AWS. Con la capacidad de definir la topolog\u00eda de red, asignar direcciones IP y aplicar reglas de seguridad, VPC proporciona un control completo sobre la conectividad y la seguridad de tus recursos en AWS. Explora Amazon VPC para dise\u00f1ar y desplegar redes personalizadas en la nube.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/","title":"2. Infraestructura de AWS","text":""},{"location":"SBD/Tema02/InfraestructuraAWS/#21-introduccion-a-la-infraestructura-de-aws","title":"2.1 Introducci\u00f3n a la Infraestructura de AWS","text":"<p>AWS es una plataforma de servicios en la nube que ofrece una amplia gama de servicios de c\u00f3mputo, almacenamiento, bases de datos, redes, an\u00e1lisis y m\u00e1s. La infraestructura de AWS est\u00e1 dise\u00f1ada para proporcionar una base s\u00f3lida para la implementaci\u00f3n de aplicaciones y servicios en la nube.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#22-regiones-y-zonas-de-disponibilidad","title":"2.2. Regiones y Zonas de Disponibilidad","text":""},{"location":"SBD/Tema02/InfraestructuraAWS/#221-regiones","title":"2.2.1. Regiones","text":"<p>AWS opera en m\u00faltiples regiones en todo el mundo. Cada regi\u00f3n es una ubicaci\u00f3n geogr\u00e1fica que contiene uno o m\u00e1s centros de datos llamados \"Zonas de Disponibilidad\". </p> <ul> <li>La replicaci\u00f3n de datos entre regiones es controlada por usted.</li> <li>La comunicaci\u00f3n entre regiones utiliza infraestructura de red troncal de AWS.</li> <li>Cada regi\u00f3n proporciona a la red niveles plenos de redundancia y conectividad.</li> <li>Una regi\u00f3n normalmente consta de dos o m\u00e1s zonas de disponibilidad.</li> </ul> <p>Ejemplos de regiones incluyen \"us-east-1\" (Norte de Virginia), \"eu-west-1\" (Irlanda), entre otras.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#222-zonas-de-disponibilidad","title":"2.2.2. Zonas de Disponibilidad","text":"<p>Cada regi\u00f3n de AWS consta de al menos dos Zonas de Disponibilidad (AZ). Las Zonas de Disponibilidad son centros de datos separados f\u00edsicamente dentro de una regi\u00f3n y est\u00e1n dise\u00f1adas para ser independientes entre s\u00ed en t\u00e9rminos de energ\u00eda y conectividad. Esto proporciona alta disponibilidad y redundancia.</p> <p></p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#223-centros-de-datos","title":"2.2.3. Centros de datos","text":"<ul> <li>Los centros de datos de AWS est\u00e1n dise\u00f1ados para ofrecer seguridad.</li> <li>En los centros de datos se almacenan y se procesan los datos.</li> <li>Cada centro de datos tiene alimentaci\u00f3n, redes y conectividad redundantes, y se aloja en una instalaci\u00f3n independiente.</li> <li>Un centro de datos suele albergar entre 50 000 y 80 000 servidores f\u00edsicos.</li> </ul>"},{"location":"SBD/Tema02/InfraestructuraAWS/#23-servicios-basicos-de-aws","title":"2.3. Servicios B\u00e1sicos de AWS","text":"<p>Este es el esquema de servicios b\u00e1sicos de AWS</p> <p></p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#231-amazon-ec2-elastic-compute-cloud","title":"2.3.1. Amazon EC2 (Elastic Compute Cloud)","text":"<p>Amazon EC2 es un servicio de c\u00f3mputo escalable que te permite lanzar y administrar m\u00e1quinas virtuales (instancias) en la nube. Puedes seleccionar el tipo de instancia, el sistema operativo y la capacidad de c\u00f3mputo que necesitas.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#232-amazon-s3-simple-storage-service","title":"2.3.2. Amazon S3 (Simple Storage Service)","text":"<p>Amazon S3 es un servicio de almacenamiento en la nube que permite almacenar y recuperar datos en forma de objetos. Es altamente escalable, duradero y se utiliza para almacenar una variedad de tipos de datos, incluidas im\u00e1genes, videos, archivos de registro y m\u00e1s.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#233-servicios-de-bd","title":"2.3.3. Servicios de BD","text":"<p>Estos servicios son parte de la amplia gama de servicios en la nube ofrecidos por Amazon Web Services (AWS) y son esenciales para gestionar bases de datos en la nube.</p> <ol> <li> <p>Amazon Relational Database Service (RDS):    Amazon RDS es un servicio de administraci\u00f3n de bases de datos relacionales completamente gestionado. Proporciona una infraestructura escalable y de alta disponibilidad para bases de datos relacionales como MySQL, PostgreSQL, Oracle, SQL Server y MariaDB.</p> </li> <li> <p>Amazon Aurora:    Amazon Aurora es un motor de base de datos relacional compatible con MySQL y PostgreSQL que se ha optimizado para ofrecer un alto rendimiento y una escalabilidad excepcional.</p> </li> <li> <p>Amazon Redshift:    Amazon Redshift es un servicio de almacenamiento de datos en la nube que se ha dise\u00f1ado espec\u00edficamente para el an\u00e1lisis de datos y el procesamiento de consultas a gran escala. </p> </li> <li> <p>Amazon DynamoDB:    Amazon DynamoDB es un servicio de base de datos NoSQL completamente gestionado que ofrece un rendimiento r\u00e1pido y escalabilidad autom\u00e1tica.</p> </li> </ol>"},{"location":"SBD/Tema02/InfraestructuraAWS/#234-aws-lambda","title":"2.3.4. AWS Lambda","text":"<p>AWS Lambda es un servicio de c\u00f3mputo sin servidor que te permite ejecutar c\u00f3digo en respuesta a eventos sin necesidad de administrar servidores. Es ideal para la ejecuci\u00f3n de funciones peque\u00f1as y ef\u00edmeras.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#235-amazon-vpc-virtual-private-cloud","title":"2.3.5. Amazon VPC (Virtual Private Cloud)","text":"<p>Amazon VPC te permite crear una red virtual aislada en la nube donde puedes lanzar recursos de AWS de manera segura. Puedes definir tu propia topolog\u00eda de red, subredes, tablas de rutas y reglas de seguridad.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#236-aws-iam-identity-and-access-management","title":"2.3.6. AWS IAM (Identity and Access Management)","text":"<p>AWS IAM es un servicio de administraci\u00f3n de identidades que te permite controlar el acceso a tus recursos de AWS. Puedes crear usuarios, grupos y roles, y definir pol\u00edticas de acceso.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#24-arquitecturas-en-aws","title":"2.4. Arquitecturas en AWS","text":""},{"location":"SBD/Tema02/InfraestructuraAWS/#241-arquitectura-de-alta-disponibilidad-ha","title":"2.4.1. Arquitectura de Alta Disponibilidad (HA)","text":"<p>Las arquitecturas de alta disponibilidad en AWS se basan en la redundancia y la distribuci\u00f3n geogr\u00e1fica de recursos para garantizar que las aplicaciones est\u00e9n siempre disponibles incluso en caso de fallos.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#242-escalabilidad-automatica","title":"2.4.2. Escalabilidad Autom\u00e1tica","text":"<p>La escalabilidad autom\u00e1tica permite que los recursos de AWS se ajusten autom\u00e1ticamente en funci\u00f3n de la demanda. Puedes escalar horizontalmente agregando instancias o verticalmente mejorando las instancias existentes.</p>"},{"location":"SBD/Tema02/InfraestructuraAWS/#243-arquitectura-sin-servidor-serverless","title":"2.4.3. Arquitectura sin Servidor (Serverless)","text":"<p>Las arquitecturas sin servidor aprovechan servicios como AWS Lambda y Amazon API Gateway para eliminar la administraci\u00f3n de servidores y ejecutar c\u00f3digo de manera ef\u00edmera en respuesta a eventos.</p>"},{"location":"SBD/Tema03/SeguridadAWS/","title":"3. Seguridad en al nube de AWS","text":""},{"location":"SBD/Tema03/SeguridadAWS/#31-modelo-de-responsabilidad-compartida","title":"3.1. Modelo de responsabilidad compartida","text":"<p>El modelo de responsabilidad compartida de AWS es un concepto fundamental para comprender c\u00f3mo se dividen las responsabilidades de seguridad entre AWS, c\u00f3mo proveedor de servicios en la nube, y los clientes que utilizan esos servicios. Este modelo se aplica a fin de garantizar la seguridad de los datos y la infraestructura en la nube.</p> <p>Responsabilidades de AWS:</p> <p>AWS es responsable de la seguridad de la nube, lo que significa que se encarga de proteger la infraestructura f\u00edsica, los centros de datos, la red y los servicios fundamentales que ofrece. Las responsabilidades de AWS incluyen:</p> <ul> <li>Seguridad de la infraestructura: AWS debe proteger los centros de datos, servidores, redes y otros componentes f\u00edsicos de su infraestructura global.</li> <li>Gesti\u00f3n de servicios compartidos: AWS es responsable de garantizar la seguridad de los servicios compartidos, como la gesti\u00f3n de identidad y acceso, y la administraci\u00f3n de la red subyacente.</li> </ul> <p>Responsabilidades del cliente:</p> <p>Los clientes que utilizan los servicios de AWS tienen la responsabilidad de asegurarse de que sus aplicaciones y datos est\u00e9n seguros dentro de la nube. Esto incluye:</p> <ul> <li>Seguridad de la aplicaci\u00f3n: Los clientes deben asegurarse de que sus aplicaciones est\u00e9n configuradas y protegidas adecuadamente, lo que incluye el manejo de credenciales, la seguridad de las aplicaciones y la configuraci\u00f3n de cortafuegos.</li> <li>Gesti\u00f3n de datos: Los clientes son responsables de la seguridad de los datos que almacenan en la nube, lo que incluye la encriptaci\u00f3n, la gesti\u00f3n de copias de seguridad y la gesti\u00f3n de acceso.</li> <li>Gesti\u00f3n de identidad y acceso: Los clientes deben administrar qui\u00e9n tiene acceso a sus recursos en la nube y c\u00f3mo se otorgan los permisos.</li> </ul> <p>El modelo de responsabilidad compartida se ilustra mejor de la siguiente manera:</p> <p></p>"},{"location":"SBD/Tema03/SeguridadAWS/#32-responsabilidad-en-materia-de-seguridad-y-caracteristicas-del-servicio","title":"3.2. Responsabilidad en materia de seguridad y caracter\u00edsticas del servicio","text":""},{"location":"SBD/Tema03/SeguridadAWS/#321-infraestructura-como-servicio-iaas","title":"3.2.1. Infraestructura c\u00f3mo servicio (IaaS)","text":"<ul> <li>El cliente tiene m\u00e1s flexibilidad en lo que respecta a la configuraci\u00f3n de redes y almacenamiento.</li> <li>El cliente es responsable de administrar m\u00e1s aspectos de la seguridad. </li> <li>El cliente configura los controles de acceso.</li> </ul> <p>Servicios administrados por el cliente:</p> <ul> <li>Amazon EC2</li> <li>Amazon Elastic Block Store (Amazon EBS)</li> <li>Amazon Virtual Private Cloud (Amazon VPC)</li> </ul>"},{"location":"SBD/Tema03/SeguridadAWS/#322-plataforma-como-servicio-paas","title":"3.2.2. Plataforma c\u00f3mo servicio (PaaS)","text":"<ul> <li>El cliente no necesita administrar la infraestructura subyacente.</li> <li>AWS gestiona el sistema operativo, la implementaci\u00f3n de parches a la base de datos, la configuraci\u00f3n del  firewall y la recuperaci\u00f3n de desastres.</li> <li>El cliente puede centrarse en la administraci\u00f3n de c\u00f3digo o datos.</li> </ul> <p>Servicios administrados por AWS:</p> <ul> <li>AWS Lambda</li> <li>Amazon Relational Database Service (Amazon RDS)</li> <li>AWS Elastic Beanstalk. Es un servicio que facilita la implementaci\u00f3n y administraci\u00f3n de aplicaciones web en la nube</li> </ul>"},{"location":"SBD/Tema03/SeguridadAWS/#323-software-como-servicio-saas","title":"3.2.3. Software c\u00f3mo servicio (SaaS)","text":"<ul> <li>El software est\u00e1 alojado de forma centralizada.</li> <li>Cuenta con licencia seg\u00fan un modelo de suscripci\u00f3n o de pago por uso.</li> <li>Normalmente, el acceso a los servicios se realiza a trav\u00e9s de un navegador web, una aplicaci\u00f3n m\u00f3vil o una interfaz de programaci\u00f3n de aplicaciones (API).</li> <li>Los clientes no necesitan administrar la infraestructura que respalda el servicio.</li> </ul> <p>Ejemplos de SaaS:</p> <ul> <li>AWS Trusted Advisor. Es un servicio que proporciona recomendaciones personalizadas para optimizar tus recursos de AWS.</li> <li>AWS Shield. Ofrece protecci\u00f3n contra ataques DDoS (Denegaci\u00f3n de Servicio Distribuida) a tus aplicaciones y recursos en la nube de AWS</li> <li>Amazon\u00a0Chime. Es un servicio de comunicaci\u00f3n y colaboraci\u00f3n en l\u00ednea que incluye videoconferencias, llamadas de voz, chat y compartici\u00f3n de pantalla</li> </ul>"},{"location":"SBD/Tema03/SeguridadAWS/#actividad","title":"Actividad","text":"<p>\u00bfQui\u00e9n es responsable? \u00bfAWS o el cliente?: </p>  \u00bfActualizaciones y parches en el sistema operativo en la instancia\u00a0EC2?  <p>El usuario</p>  \u00bfSeguridad f\u00edsica del centro de datos?  <p>AWS</p>  \u00bfInfraestructura de virtualizaci\u00f3n?  <p>AWS</p>  \u00bfConfiguraci\u00f3n de grupos de seguridad de EC2?  <p>El usuario</p>  \u00bfConfiguraci\u00f3n de las aplicaciones que se ejecutan en la instancia EC2?  <p>El usuario</p>  \u00bfActualizaciones o parches de Oracle si la instancia de Oracle se ejecuta como una instancia de Amazon RDS?  <p>AWS</p>  \u00bfActualizaciones o parches de Oracle si Oracle se ejecuta en una instancia EC2?  <p>El usuario</p>  \u00bfConfiguraci\u00f3n de acceso al bucket de S3?  <p>El usuario</p>  \u00bfGarantizar que la consola de administraci\u00f3n de AWS no sea pirateada?  <p>AWS</p>  \u00bfConfigurar la subred?  <p>El usuario</p>  \u00bfConfigurar la VPC?  <p>El usuario</p>  \u00bfProteger frente a interrupciones de red en las regiones de AWS?  <p>AWS</p>  \u00bfProteger las claves SSH?  <p>El usuario</p>  \u00bfGarantizar el aislamiento de red entre los datos de los clientes de AWS?  <p>AWS</p>  \u00bfGarantizar una conexi\u00f3n de red de baja latencia entre el servidor web y el bucket de S3?  <p>AWS</p>  \u00bfRequerir la autenticaci\u00f3n multifactor para todos los inicios de sesi\u00f3n de los usuarios?  <p>El usuario</p>"},{"location":"SBD/Tema03/SeguridadAWS/#33-aws-identity-and-access-management-iam","title":"3.3. AWS Identity and Access Management (IAM)","text":"<p>AWS Identity and Access Management (IAM) es un servicio que te permite controlar el acceso a los recursos y servicios de AWS de forma segura. </p> <p>IAM permite administrar identidades, c\u00f3mo usuarios y roles, y asignar permisos para que los usuarios y aplicaciones puedan acceder y realizar acciones en los recursos de AWS. </p> <p>IAM es fundamental para garantizar la seguridad y el cumplimiento en tu entorno de AWS.</p>"},{"location":"SBD/Tema03/SeguridadAWS/#32-conceptos-clave-de-iam","title":"3.2. Conceptos Clave de IAM","text":"<ul> <li> <p>Usuarios IAM: Representan individuos o aplicaciones que necesitan acceso a recursos de AWS. Cada usuario tiene credenciales \u00fanicas y se le asignan permisos espec\u00edficos.</p> </li> <li> <p>Grupos IAM: Los grupos son conjuntos l\u00f3gicos de usuarios. Puedes asignar permisos a un grupo en lugar de asignarlos individualmente a cada usuario. Esto facilita la gesti\u00f3n de permisos.</p> </li> <li> <p>Roles IAM: Los roles son identidades temporales que pueden asumir usuarios, servicios o recursos en AWS. Los roles son \u00fatiles para aplicaciones que se ejecutan en instancias EC2, servicios de Lambda y m\u00e1s.</p> </li> <li> <p>Pol\u00edticas IAM: Las pol\u00edticas son documentos que definen los permisos y las acciones permitidas o denegadas en recursos de AWS. Puedes adjuntar pol\u00edticas a usuarios, grupos y roles.</p> </li> </ul> <p></p>"},{"location":"SBD/Tema03/SeguridadAWS/#34-autentificacion-de-usuario-de-iam","title":"3.4. Autentificaci\u00f3n de usuario de IAM","text":"<p>El usuario de IAM tiene dos tipos de acceso:</p> <p>Acceso mediante programaci\u00f3n.</p> <ul> <li>Se autentica con lo siguiente:<ul> <li>ID de clave de acceso</li> <li>Clave de acceso secreta</li> </ul> </li> <li>Proporciona acceso a la CLI de AWS y al SDK de AWS.</li> </ul> <p>Acceso a la consola de administraci\u00f3n de AWS</p> <ul> <li>Se autentica con lo siguiente:<ul> <li>ID de cuenta o alias de 12\u00a0d\u00edgitos</li> <li>Nombre de usuario de IAM</li> <li>Contrase\u00f1a de IAM</li> </ul> </li> </ul>"},{"location":"SBD/Tema03/SeguridadAWS/#35-recomendaciones-de-seguridad","title":"3.5. Recomendaciones de Seguridad","text":"<ul> <li>Principio de Menor Privilegio: Asigna permisos m\u00ednimos necesarios para realizar una tarea.</li> <li>Rotaci\u00f3n de Credenciales: Cambia las contrase\u00f1as y las claves de acceso peri\u00f3dicamente.</li> <li>Auditor\u00eda: Habilita el registro de auditor\u00eda en IAM para supervisar eventos y actividades.</li> </ul>"},{"location":"SBD/Tema03/SeguridadAWS/#36-ayuda-y-documentacion","title":"3.6. Ayuda y Documentaci\u00f3n","text":"<p>La Consola de IAM proporciona una amplia documentaci\u00f3n y ayuda en l\u00ednea. Adem\u00e1s, puedes consultar la documentaci\u00f3n oficial de AWS IAM para obtener informaci\u00f3n detallada sobre pol\u00edticas, roles y pr\u00e1cticas recomendadas.</p>"},{"location":"SBD/Tema04/Informatica/","title":"4. Inform\u00e1tica AWS","text":""},{"location":"SBD/Tema04/Informatica/#41-amazon-ec2-elastic-compute-cloud","title":"4.1. Amazon EC2 (Elastic Compute Cloud)","text":"<p>Amazon Elastic Compute Cloud (Amazon EC2) es un servicio de c\u00f3mputo en la nube escalable que permite a las empresas y desarrolladores lanzar y administrar m\u00e1quinas virtuales (instancias) en la infraestructura de AWS. EC2 proporciona la capacidad de c\u00f3mputo necesaria para ejecutar aplicaciones y cargas de trabajo de manera flexible y rentable.</p>"},{"location":"SBD/Tema04/Informatica/#42-principales-caracteristicas-de-ec2","title":"4.2. Principales Caracter\u00edsticas de EC2","text":"<ul> <li>Escalabilidad Vertical y Horizontal: Puedes escalar tus instancias hacia arriba (aumentar la capacidad) o hacia abajo (disminuir la capacidad) seg\u00fan la demanda. Esto garantiza que siempre tengas suficiente capacidad de c\u00f3mputo.</li> <li>Diversidad de Recursos: EC2 ofrece una amplia variedad de tipos de instancia optimizados para diferentes cargas de trabajo, desde instancias de prop\u00f3sito general hasta instancias optimizadas para GPU y c\u00f3mputo intensivo.</li> <li>Flexibilidad de SO: Puedes seleccionar el sistema operativo que mejor se adapte a tus necesidades, incluidos Linux, Windows, macOS y sistemas basados en contenedores c\u00f3mo Amazon ECS.</li> <li>Almacenamiento EBS: EC2 ofrece almacenamiento Elastic Block Store (EBS) para adjuntar vol\u00famenes de datos persistentes a tus instancias. Puedes crear instant\u00e1neas (snapshots) de estos vol\u00famenes para copias de seguridad y replicaci\u00f3n.</li> <li>Amazon VPC: Puedes crear tu propia red virtual (Amazon VPC) para aislar tus instancias y controlar el acceso a ellas. Tambi\u00e9n puedes configurar grupos de seguridad y asignar direcciones IP el\u00e1sticas.</li> <li>Auto Scaling y Load Balancing: EC2 es compatible con Auto Scaling para ajustar autom\u00e1ticamente el n\u00famero de instancias en funci\u00f3n de la demanda. Tambi\u00e9n puedes usar Amazon Elastic Load Balancing (ELB) para distribuir el tr\u00e1fico entre m\u00faltiples instancias.</li> </ul>"},{"location":"SBD/Tema04/Informatica/#43-creacion-de-instancias-ec2","title":"4.3. Creaci\u00f3n de Instancias EC2","text":"<p>El proceso de creaci\u00f3n de instancias EC2 generalmente implica los siguientes pasos:</p> <ol> <li>Inicia sesi\u00f3n en la Consola de AWS con tus credenciales de cuenta.</li> <li>Desde el panel de AWS, navega a la secci\u00f3n \"Servicios\" y selecciona \"EC2\" bajo la categor\u00eda \"Compute\".</li> <li>Haz clic en \"Launch Instance\" para comenzar el proceso de lanzamiento de una instancia.</li> <li>Selecciona la opciones de la instancia</li> <li>Despu\u00e9s de lanzar la instancia, puedes conectarte a ella utilizando SSH (para sistemas basados en Unix) o RDP (para sistemas Windows).</li> </ol> <p>Elecciones que se toman con el asistente de lanzamiento de instancias:</p> <ol> <li>AMI Imagen de Amazon Machine (AMI)<ul> <li>Es una plantilla que se utiliza para crear una instancia EC2 (una m\u00e1quina virtual, o VM, que se ejecuta en la nube de AWS).</li> <li>Contiene un sistema operativo Windows o Linux.</li> <li>Tambi\u00e9n suele tener alg\u00fan sistema de software preinstalado.</li> </ul> </li> <li>Tipo de instancia<ul> <li>El tipo de instancia que elija determina los siguientes elementos: La memoria (RAM), la capacidad de procesamiento (CPU), el espacio en disco y tipo de disco (almacenamiento), el rendimiento de red</li> </ul> </li> <li>Configuraci\u00f3n de red<ul> <li>\u00bfD\u00f3nde debe implementarse la instancia? </li> <li>Identificar la VPC y, de forma opcional, la subred</li> <li>\u00bfDeber\u00eda asignarse una direcci\u00f3n IP p\u00fablica autom\u00e1ticamente?</li> <li>Para que sea accesible desde Internet</li> </ul> </li> <li>Rol de IAM<ul> <li>\u00bfTendr\u00e1 que interactuar el software de la instancia EC2 con otros servicios de AWS? Si es as\u00ed, asocie el rol de IAM adecuado.</li> </ul> </li> <li>Datos de usuario<ul> <li>De forma opcional, puede especificar un script de datos de usuario durante el llanzamiento de la instancia. </li> <li>Utilice scripts de datos de usuario para personalizar el entorno de tiempo de ejecuci\u00f3n de la instancia.  </li> <li>El script se ejecuta la primera vez que se inicia la instancia.</li> </ul> </li> <li>Opciones de almacenamiento<ul> <li>Configure el volumen ra\u00edz.</li> <li>Lugar donde est\u00e1 instalado el sistema operativo invitado</li> <li>Adjunte vol\u00famenes de almacenamiento adicionales (opcional).</li> <li>Es posible que la AMI incluya m\u00e1s de un volumen.</li> <li>Para cada volumen, especifique lo siguiente:<ul> <li>El tama\u00f1o del disco (en GB)</li> <li>El tipo de volumen. Hay diferentes tipos de unidades de estado s\u00f3lido (SSD) y unidades de disco duro (HDD) disponibles.</li> <li>Si el volumen se eliminar\u00e1 cuando se termine la instancia</li> <li>Si se debe utilizar el cifrado</li> </ul> </li> <li>Opciones de almacenamiento<ul> <li>Amazon Elastic Block Store (Amazon EBS): Ofrece vol\u00famenes de almacenamiento de nivel de bloque persistentes. Puede detener la instancia e iniciarla de nuevo sin perder los datos.</li> <li>Almac\u00e9n de instancias de Amazon EC2: El almacenamiento se proporciona en discos asociados al equipo host en el que se ejecuta la instancia EC2. Si la instancia se detiene, se eliminar\u00e1n los datos almacenados aqu\u00ed.</li> </ul> </li> <li>Otras opciones de almacenamiento (no para el volumen ra\u00edz): <ul> <li>Montar un sistema de archivos de Amazon Elastic File System (Amazon EFS)</li> <li>Conectarse a Amazon Simple Storage Service (Amazon S3) </li> </ul> </li> </ul> </li> <li>Etiquetas<ul> <li>Una etiqueta es una marca que se puede asignar a un recurso de AWS. </li> <li>Cada etiqueta consta de una clave y un valor opcional.</li> <li>El etiquetado es la forma en que asocia metadatos a una instancia EC2. </li> <li>Los beneficios potenciales del etiquetado son la capacidad de filtrado, la automatizaci\u00f3n, la asignaci\u00f3n de costos y el control de acceso.</li> </ul> </li> <li>Grupo de seguridad<ul> <li>Un grupo de seguridad es un conjunto de reglas de firewall que controlan el tr\u00e1fico a la instancia. </li> <li>Se encuentra fuera del sistema operativo invitado de la instancia.</li> <li>Cree reglas que especifiquen el origen y los puertos que las comunicaciones de red pueden utilizar.</li> <li>Especifique el n\u00famero de puerto y el protocolo, como el Protocolo de control de transmisi\u00f3n (TCP), el Protocolo de datagramas de usuario (UDP) o el Protocolo de mensaje de control de Internet (ICMP).</li> <li>Especifique el origen (por ejemplo, una direcci\u00f3n IP u otro grupo de seguridad) que tiene permiso para utilizar la regla.</li> </ul> </li> <li>Par de claves<ul> <li>En el lanzamiento de la instancia, debe especificar un par de claves existente o crear uno nuevo.</li> <li>Un par de claves consta de lo siguiente: <ul> <li>Una clave p\u00fablica que AWS almacena.</li> <li>Un archivo de clave privada que usted almacena. </li> <li>Posibilita las conexiones seguras a la instancia. </li> </ul> </li> <li>Para las AMI de Windows: <ul> <li>Utilice la clave privada para obtener la contrase\u00f1a de administrador que necesita para iniciar sesi\u00f3n en la instancia. </li> </ul> </li> <li>Para las AMI de Linux: <ul> <li>Utilice la clave privada para utilizar SSH y conectarse de forma segura a la instancia.</li> </ul> </li> </ul> </li> </ol> <p>Ciclo de vida de las instancias</p> <p></p> <p>Que ocurre cuando detienes una instancia</p> <ul> <li>El reinicio de una instancia no cambiar\u00e1 las direcciones IP ni los nombres de host DNS.</li> <li>Cuando se detiene una instancia y se vuelve a iniciar, sucede lo siguiente: <ul> <li>Se modifican la direcci\u00f3n IPv4 p\u00fablica y el nombre de host DNS externo.</li> <li>La direcci\u00f3n IPv4 privada y el nombre de host DNS interno permanecen iguales.</li> </ul> </li> <li>Si necesitas una direcci\u00f3n IP p\u00fablica persistente, asocia una direcci\u00f3n IP el\u00e1stica a la instancia.</li> <li>Caracter\u00edsticas de la direcci\u00f3n IP el\u00e1stica: <ul> <li>Se puede asociar a las instancias en la regi\u00f3n seg\u00fan sea necesario.</li> <li>Permanece asignada a su cuenta hasta que decida liberarla.</li> </ul> </li> </ul>"},{"location":"SBD/Tema04/Informatica/#44-casos-de-uso-de-ec2","title":"4.4. Casos de Uso de EC2","text":"<p>Amazon EC2 es vers\u00e1til y se utiliza en una amplia variedad de casos de uso, que incluyen:</p> <ul> <li>Hospedaje de Sitios Web: Ejecutar servidores web y alojar sitios y aplicaciones web.</li> <li>Desarrollo y Pruebas: Crear entornos de desarrollo y pruebas bajo demanda.</li> <li>Procesamiento de Datos: Ejecutar tareas de procesamiento de datos y an\u00e1lisis con clusters de EC2.</li> <li>Aplicaciones Empresariales: Ejecutar aplicaciones empresariales cr\u00edticas en instancias EC2.</li> <li>Ejecuci\u00f3n de Contenedores: Implementar y administrar contenedores con servicios como Amazon ECS y EKS.</li> </ul>"},{"location":"SBD/Tema04/Informatica/#45-introduccion-a-aws-cli","title":"4.5. Introducci\u00f3n a AWS CLI","text":"<p>AWS CLI es una interfaz de l\u00ednea de comandos que te permite interactuar con los servicios y recursos de Amazon Web Services (AWS) directamente desde tu terminal. Con AWS CLI, puedes administrar y configurar recursos de AWS, automatizar tareas y realizar operaciones de forma eficiente sin necesidad de utilizar la interfaz web de AWS.</p>"},{"location":"SBD/Tema04/Informatica/#451-instalacion-en-windows","title":"4.5.1. Instalaci\u00f3n en Windows","text":"<p>Puedes instalar AWS CLI en Windows siguiendo estos pasos:</p> <ol> <li>Descarga el instalador de AWS CLI para Windows desde el sitio web oficial de AWS.</li> <li>Ejecuta el instalador descargado y sigue las instrucciones de instalaci\u00f3n.</li> </ol>"},{"location":"SBD/Tema04/Informatica/#452-instalacion-en-linux-y-macos","title":"4.5.2. Instalaci\u00f3n en Linux y macOS","text":"<p>En sistemas Linux y macOS, puedes instalar AWS CLI utilizando el administrador de paquetes <code>pip</code> de Python o a trav\u00e9s de la instalaci\u00f3n de paquetes de tu sistema.</p> <p>Instalaci\u00f3n con <code>pip</code></p> <p>Ejecuta el siguiente comando en tu terminal:</p> <pre><code>pip install awscli\n</code></pre> <p>Instalaci\u00f3n en macOS con Homebrew</p> <p>Si utilizas Homebrew en macOS, puedes instalar AWS CLI con el siguiente comando:</p> <pre><code>brew install awscli\n</code></pre>"},{"location":"SBD/Tema04/Informatica/#452-configuracion-de-aws-cli","title":"4.5.2. Configuraci\u00f3n de AWS CLI","text":"<p>Despu\u00e9s de instalar AWS CLI, debes configurar las credenciales de acceso para que puedas autenticarte en AWS. Puedes hacerlo utilizando el comando <code>aws configure</code> y proporcionando tus credenciales de AWS, que incluyen la clave de acceso y la clave secreta.</p> <pre><code>aws configure\n</code></pre> <p>Tambi\u00e9n puedes configurar la regi\u00f3n predeterminada y el formato de salida preferido (por ejemplo, JSON) durante este proceso.</p>"},{"location":"SBD/Tema04/Informatica/#453-uso-basico-de-aws-cli","title":"4.5.3. Uso B\u00e1sico de AWS CLI","text":"<p>AWS CLI permite ejecutar comandos para interactuar con servicios de AWS. Aqu\u00ed tienes algunos ejemplos de comandos b\u00e1sicos:</p> <p>Listar Instancias EC2</p> <pre><code>aws ec2 describe-instances\n</code></pre> <p>Crear un Bucket de Amazon S3</p> <pre><code>aws s3 mb s3://mi-bucket\n</code></pre> <p>Subir un Archivo a Amazon S3</p> <pre><code>aws s3 cp mi-archivo.txt s3://mi-bucket/\n</code></pre> <p>Crear una Instancia EC2</p> <pre><code>aws ec2 run-instances --image-id ami-XXXXXXXXXXXXXXXXX --instance-type t2.micro --key-name mi-keypair\n</code></pre> <p>Ayuda</p> <p>Ejemplo AWS CLI</p>"},{"location":"SBD/Tema04/Informatica/#454-scripts-y-automatizacion","title":"4.5.4. Scripts y Automatizaci\u00f3n","text":"<p>AWS CLI es una herramienta poderosa para la automatizaci\u00f3n de tareas en AWS. Puedes escribir scripts y secuencias de comandos para realizar operaciones complejas y administrar recursos de manera eficiente.</p> <p>AWS CLI proporciona documentaci\u00f3n detallada y ayuda en l\u00ednea para cada comando y servicio. Puedes utilizar el comando <code>aws help</code> para obtener informaci\u00f3n sobre el uso de comandos espec\u00edficos y acceder a la documentaci\u00f3n oficial de AWS CLI en l\u00ednea.</p>"},{"location":"SBD/Tema04/Informatica/#46-amazon-vpc","title":"4.6. Amazon VPC","text":"<p>Amazon Virtual Private Cloud (Amazon VPC) es un servicio de red que te permite crear una red virtual aislada en la nube de AWS. Con Amazon VPC, puedes controlar la topolog\u00eda de red, asignar direcciones IP, definir tablas de rutas y aplicar reglas de seguridad para tus recursos en la nube. VPC te permite crear una extensi\u00f3n virtual de tu centro de datos en AWS.</p>"},{"location":"SBD/Tema04/Informatica/#461-conceptos-clave-de-amazon-vpc","title":"4.6.1. Conceptos Clave de Amazon VPC","text":"<p>Red Virtual (VPC)</p> <p>Una VPC es tu propia red virtual en la nube de AWS. Puedes personalizar su topolog\u00eda, direcciones IP y configuraci\u00f3n de red.</p> <p>Subredes</p> <p>Una VPC se divide en subredes. Puedes crear subredes p\u00fablicas y privadas seg\u00fan tus necesidades.</p> <p>Tablas de Rutas</p> <p>Las tablas de rutas definen c\u00f3mo se enrutan los paquetes dentro y fuera de la VPC. Puedes personalizar las rutas y las reglas.</p> <p>Grupos de Seguridad</p> <p>Los grupos de seguridad son cortafuegos virtuales que controlan el tr\u00e1fico de entrada y salida de las instancias EC2.</p> <p>Listas de Control de Acceso a la Red (NACL)</p> <p>Las NACL son conjuntos de reglas que controlan el tr\u00e1fico de subredes en la VPC.</p> <p>VPN y Direct Connect</p> <p>Amazon VPC te permite conectar tu red local a la VPC mediante una conexi\u00f3n VPN o Direct Connect para acceso privado.</p>"},{"location":"SBD/Tema04/Informatica/#462-configuracion-de-amazon-vpc","title":"4.6.2. Configuraci\u00f3n de Amazon VPC","text":"<p>Pasos:</p> <ol> <li> <p>Creaci\u00f3n de una VPC</p> <ul> <li>Define una VPC especificando su rango de direcciones IP y configuraci\u00f3n de red.</li> <li>Puedes seleccionar un rango de direcciones IP IPv4 CIDR para tu VPC.</li> </ul> </li> <li> <p>Creaci\u00f3n de Subredes</p> <ul> <li>Divide tu VPC en subredes p\u00fablicas y privadas.</li> <li>Configura las tablas de rutas para permitir o denegar el tr\u00e1fico.</li> </ul> </li> <li> <p>Configuraci\u00f3n de Grupos de Seguridad</p> <ul> <li>Define grupos de seguridad para controlar el tr\u00e1fico de red a instancias EC2.</li> <li>Asigna reglas de entrada y salida a los grupos de seguridad.</li> </ul> </li> <li> <p>Configuraci\u00f3n de NACL</p> </li> <li> <p>Configura listas de control de acceso a la red (NACL) para controlar el tr\u00e1fico de subredes.</p> </li> <li>Define reglas de entrada y salida en las NACL.</li> </ol>"},{"location":"SBD/Tema04/Informatica/#463-escenarios-comunes-en-amazon-vpc","title":"4.6.3. Escenarios Comunes en Amazon VPC","text":"<ul> <li>Crea una VPC con subredes p\u00fablicas que tienen acceso a Internet y subredes privadas que est\u00e1n aisladas.</li> <li>Configura una VPN o Direct Connect para conectar tu red local a tu VPC en AWS.</li> <li>Implementa aplicaciones y servicios en tus subredes personalizadas dentro de la VPC.</li> </ul>"},{"location":"SBD/Tema04/Informatica/#664-recomendaciones-de-seguridad","title":"6.6.4. Recomendaciones de Seguridad","text":"<ul> <li>Seguridad de Grupos: Asigna grupos de seguridad para controlar el tr\u00e1fico de red a nivel de instancia.</li> <li>Aislamiento de Subredes: Dise\u00f1a subredes para aislar componentes cr\u00edticos.</li> <li>Monitoreo y Auditor\u00eda: Habilita el monitoreo y la auditor\u00eda de red para supervisar y proteger tu VPC.</li> </ul>"},{"location":"SBD/Tema04/Informatica/#46-actividad","title":"4.6. Actividad","text":"<p>Crea una instancia EC2 Amazon Linux 2 AMI para utilizarla como servidor Web, con las siguientes caracter\u00edsticas:</p> <ul> <li>Red: Lab- VPC</li> <li>Almacenamiento: EBS 8 Gb</li> <li>Etiquetas: Nombre - Servidor Web</li> <li>Grupo de seguridad: Crea uno con acceso mediante SSH y acceso a trav\u00e9s de HTTP (es un servidor Web)</li> <li>Tiene que tener habilitada la protecci\u00f3n de terminaci\u00f3n.</li> <li>Claves: Crea un par de claves para su acceso mediante SSH.</li> <li>El servidor web debe iniciar con un index.php como este: <pre><code>   &lt;html&gt;&lt;h1&gt;!!! Hola, este es mi servidor Web !!!&lt;/h1&gt;&lt;/html&gt;\n</code></pre></li> <li>Una vez creada y lanzada la instancia. Accede al servidor en otra pesta\u00f1a del navegado</li> </ul>"},{"location":"SOM/IndiceSOM/","title":"Sistemes Operatius Monolloc","text":""},{"location":"SOM/IndiceSOM/#temes","title":"Temes","text":"<ul> <li>T1 Sistemes Inform\u00e0tics </li> <li>T2 Sistemes Operatius </li> <li>T3 Gesti\u00f3 de Recursos </li> <li>T4 Virtualitzaci\u00f3 </li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/","title":"1. Sistemes Inform\u00e0tics","text":""},{"location":"SOM/Tema01/SistemesInformatics/#11-que-es-un-ordinador","title":"1.1. \u00bfQu\u00e9 \u00e8s un ordinador?","text":"<p>En valenci\u00e0, la paraula ''ordinador'' t\u00e9 el seu origen en la paraula francesa ''ordinateur'' i fa refer\u00e8ncia a un dispositiu electr\u00f2nic, de prop\u00f2sit general, amb capacitat per a rebre informaci\u00f3, emmagatzemar-la durant un temps (almenys l'imprescindible per a dur a terme la seua tasca), processar-la per a rebre un resultat i oferir aqueix resultat a l'exterior.</p> <p>Per tant, podem dir que es tracta d'un dispositiu amb les seg\u00fcent funcions b\u00e0siques:</p> <ul> <li>Transmetre informaci\u00f3.</li> <li>Emmagatzemar informaci\u00f3.</li> <li>Processar informaci\u00f3.</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#12-definicions","title":"1.2. Definicions","text":"<ul> <li>Inform\u00e0tica: Ci\u00e8ncia que estudia el tractament autom\u00e0tic de les dades. Procedeix de la fusi\u00f3 de les paraules informaci\u00f3 i autom\u00e0tica.</li> <li>Ordinador: M\u00e0quina composta d'elements f\u00edsics (Maquinari) capa\u00e7 de realitzar una gran varietat de treballs a gran velocitat i amb gran precisi\u00f3.</li> <li>Maquinari (Hardware): Component f\u00edsics d'un ordinador.</li> <li>Programari (Software): Component no f\u00edsics de l'ordinador que posen en funcionament a aquests \u00faltims. S\u00f3n els programes que ens serveixen per a processar les dades.</li> <li>Microprogramari (Firmware): Part intangible (programari) dels components del maquinari. Programari amb el qual estan programades les mem\u00f2ries ROM</li> <li>Instrucci\u00f3: Ordre necess\u00e0ria perqu\u00e8 funcionen els components f\u00edsics.</li> <li>Programa: Conjunt d'instruccions.</li> <li>Aplicaci\u00f3: Conjunt de programes.</li> <li>Sistema Operatiu: Component Programari d'un Sistema Inform\u00e0tic capa\u00e7 de fer que els programes processen informaci\u00f3 (dades) sobre els components electr\u00f2nics d'un ordinador.</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#13-sistema-informatic","title":"1.3. Sistema Inform\u00e0tic","text":"<p>Sempre que parlem d'un sistema, ens referim a diferents elements que es relacionen entre si. En el cas d'un sistema inform\u00e0tic, aquests elements s\u00f3n tres:</p> <ul> <li>El maquinari: Que inclou qualsevol dispositiu electr\u00f2nic utilitzat en el proc\u00e9s de la informaci\u00f3.</li> <li>El programari: Que est\u00e0 format per qualsevol element l\u00f2gic involucrat en el proc\u00e9s.</li> <li>Els usuaris: S\u00f3n les persones que ho utilitzen. \u00c9s l'element en el qual menys es repara quan es parla d'un sistema inform\u00e0tic, per\u00f2 sense ell, la resta dels elements no tindrien sentit.</li> </ul> <p>Els elements f\u00edsics que formen part del sistema inform\u00e0tic reben el nom gen\u00e8ric de maquinari. Aquest concepte \u00e9s molt gen\u00e8ric i pot fer refer\u00e8ncia tant a components que es troben dins del moble de l'ordinador, com a uns altres que estan en l'exterior.</p> <p>La majoria continuen utilitzant, hui dia, el model d'arquitectura que va introduir el matem\u00e0tic hongar\u00e9s John Von Neumann en 1949. Segons aquest esquema, un ordinador pot representar-se d'una forma modular, amb aquests quatre elements:</p>"},{"location":"SOM/Tema01/SistemesInformatics/#14-components-fisics","title":"1.4 Components f\u00edsics","text":"<ul> <li>El processador, que dirigeix el funcionament de l'ordinador i processa les dades.</li> <li>La mem\u00f2ria principal, que emmagatzema les instruccions que executa el processador i les dades sobre els quals s'apliquen aquestes.</li> <li>Els dispositius d'entrada/eixida, que comuniquen a l'ordinador amb el seu entorn.</li> <li>Els busos, que actuen com a canal de comunicaci\u00f3 entre el processador, la mem\u00f2ria i els dispositius d'entrada/eixida.</li> </ul> <p>En definitiva, podr\u00edem representar l'esquema de funcionament de l'arquitectura Von Neumann amb aquesta imatge:</p> <p></p>"},{"location":"SOM/Tema01/SistemesInformatics/#15-cpu-processador","title":"1.5. CPU (Processador)","text":"<p>Ja hem dit abans que el processador \u00e9s una part fonamental del maquinari de l'ordinador, que s'encarrega de llegir de mem\u00f2ria les instruccions que ha d'executar, les interpreta i les executa.</p> <p>Encara que l'estructura interna de qualsevol processador actual \u00e9s extremadament complexa, a nivell l\u00f2gic podem dir que est\u00e0 formada pels seg\u00fcents elements:</p> <ul> <li>Una unitat aritm\u00e8tica i l\u00f2gica o ALU (de Arithmetic-Logic Unit)</li> <li>Una unitat de control o UC</li> <li>Una s\u00e8rie de registres de mem\u00f2ria</li> </ul> <p>Vegem aquests components amb detall.</p>"},{"location":"SOM/Tema01/SistemesInformatics/#151-alu","title":"1.5.1. ALU","text":"<p>La ALU (de Arithmetic-Logic Unit) s'encarrega de realitzar les operacions de c\u00e0lcul:</p> <ul> <li>Aritm\u00e8tiques (com les sumes)</li> <li>L\u00f2giques (com AND i OR)</li> <li>Comparatives (que permeten saber, per exemple si un valor \u00e9s major que un altre).</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#152-uc","title":"1.5.2. UC","text":"<p>La UC realitza el seg\u00fcent:</p> <ul> <li>Obt\u00e9 de la mem\u00f2ria la seg\u00fcent instrucci\u00f3 a executar.</li> <li>La interpreta.</li> <li>Torna a la mem\u00f2ria per a obtindre les dades implicades en l'operaci\u00f3, els situa en la ALU.</li> <li>Una vegada obtingut el resultat, el retorna a la posici\u00f3 adequada de la mem\u00f2ria.</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#153-registres","title":"1.5.3. Registres","text":"<p>Els registres de mem\u00f2ria emmagatzemen temporalment informaci\u00f3 relacionada amb el processament de dades que s'est\u00e0 realitzant. Els principals s\u00f3n:</p> <ul> <li>Comptador de programa: Que guarda la direcci\u00f3 de mem\u00f2ria de la instrucci\u00f3 que s'executar\u00e0 a continuaci\u00f3 de l'actual.</li> <li>Registre Acumulador: Guarda els resultats temporals d'una operaci\u00f3 c\u00edclica que es troba en curs en la ALU.</li> <li>Registre d'instrucci\u00f3: Cont\u00e9 el codi de la instrucci\u00f3 que s'est\u00e0 executant.</li> <li>Registre de direcci\u00f3 de memoria: Cont\u00e9 la direcci\u00f3 de mem\u00f2ria a la que s\u2019accedeix.</li> <li>Registre d'intercanvi de mem\u00f2ria: Cont\u00e9 informaci\u00f3 que s\u2019ha de escriure o llegir de la memoria.</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#154-joc-dinstrucions","title":"1.5.4. Joc d'instrucions","text":"<p>\u00c9s el conjunt d'instruccions que un processador en particular \u00e9s capa\u00e7 d'interpretar. En realitat, a m\u00e9s de les instruccions, tamb\u00e9 estan implicats els registres que inclou el disseny del processador, els tipus de dades que sap manejar, les interrupcions, etc.</p> <p>Algunes vegades, processadors amb un disseny totalment diferents tenen els mateixos jocs d'instruccions. Aix\u00f2 es fa perseguint la compatibilitat entre diferents models de processador del mateix fabricador o entre processadors de fabricants diferents.</p> <p>No obstant aix\u00f2, el normal \u00e9s que els processadors que s\u00f3n diferents tinguen jocs d'instruccions diferents.</p> <p>Interpretant el funcionament del processador d'una forma simplista, podem dir que l'execuci\u00f3 d'un programa es basa en un proc\u00e9s repetitiu en el qual es van llegint i executant una s\u00e8rie d'instruccions preestablides.</p> <p>Cicle d'instrucci\u00f3</p> <p>El Cicle b\u00e0sic d'instrucci\u00f3 i segueix el seg\u00fcent esquema:</p> <p></p> <p>En definitiva, el cicle d'instrucci\u00f3 \u00e9s el per\u00edode que tarda el processador a executar una instrucci\u00f3 del seu joc d'instruccions. Podem dividir-ho en dues etapes:</p> <ul> <li>Lectura</li> <li>Execuci\u00f3</li> </ul> <p>Etapa de Lectura</p> <p>Llegir la instrucci\u00f3 seg\u00fcent:</p> <ul> <li>Es passa el valor del comptador de programa al bus de direccions.</li> <li>Es carrega la instrucci\u00f3 des de la mem\u00f2ria principal al registre de dades.</li> <li>S'incrementa el valor del comptador de programa.</li> <li>Es carrega el valor del registre de dades en el registre d'instrucci\u00f3.</li> <li>El descodificador d'instrucci\u00f3 interpreta la instrucci\u00f3.</li> <li>Si hi ha dades implicades, es carreguen en els registres de dades.</li> </ul> <p>Etapa de Execuci\u00f3</p> <p>Executar la instrucci\u00f3:</p> <ul> <li>La unitat de control interpreta la instrucci\u00f3 com una s\u00e8rie de senyals de control i les envia a les unitats funcionals implicades perqu\u00e8 es realitze l'acci\u00f3.</li> <li>Segons la instrucci\u00f3, el resultat s'envia a la mem\u00f2ria principal o a algun dispositiu.</li> </ul> <p>Instruccions</p> <p>En general, les instruccions es classifiquen en les seg\u00fcents categories:</p> <ul> <li>Processador-mem\u00f2ria: S'envien dades des de la mem\u00f2ria al processador o al rev\u00e9s.</li> <li>Processador-E/S: S'envien dades des d'un dispositiu d'entrada/eixida al processador o al rev\u00e9s.</li> <li>Tractament de dades: realitza una operaci\u00f3 aritm\u00e8tica, una operaci\u00f3 l\u00f2gica o una comparaci\u00f3.</li> <li>Control: Modifica la seq\u00fc\u00e8ncia d'execuci\u00f3 del programa, \u00e9s a dir, col\u00b7loca un valor diferent en el registre comptador de programa.</li> </ul> <p>Interrupcions</p> <p>Una Interrupci\u00f3 consisteix en un senyal que rep el processador en unes certes situacions i que ocasiona la suspensi\u00f3 temporal del programa que s'est\u00e0 executant. L'objectiu \u00e9s atendre possibles incid\u00e8ncies que sorgisquen al llarg de l'execuci\u00f3 del programa.</p> <p>D'aquesta manera s'aconsegueix millorar l'efici\u00e8ncia del processament perqu\u00e8, per exemple, el processador pot dedicar-se a executar un proc\u00e9s mentre espera una operaci\u00f3 d'entrada/eixida d'un proc\u00e9s diferent, sent avisat quan l'operaci\u00f3 d'entrada/eixida concloga.</p> <p>Existeixen diferents tipus d'interrupcions:</p> <ul> <li>De programa: Es produeixen quan, en tractar d'executar una instrucci\u00f3, s'obt\u00e9 un error inesperat (una divisi\u00f3 per zero, l'\u00fas d'una posici\u00f3 de mem\u00f2ria no autoritzada, etc).</li> <li>Per fallada maquinari: Quan es produeix una fallada imprevista en l'\u00fas d'un dispositiu (com un error de paritat en una posici\u00f3 de mem\u00f2ria).</li> <li>De rellotge: Produ\u00efdes pel rellotge del sistema.</li> <li>D'entrada/eixida: quan es produeix una situaci\u00f3 d'error en una operaci\u00f3 d'entrada/eixida o quan aquesta ha acabat satisfact\u00f2riament.</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#16-memoria","title":"1.6. Mem\u00f2ria","text":"<p>Des d'un punt de vista gen\u00e8ric, la mem\u00f2ria \u00e9s la part de l'ordinador que s'encarrega d'emmagatzemar les dades que intervenen en el proc\u00e9s. No obstant aix\u00f2, dins del sistema inform\u00e0tic existeixen diferents tipus de mem\u00f2ria, que anirem desglossant:</p>"},{"location":"SOM/Tema01/SistemesInformatics/#161-registres","title":"1.6.1. Registres","text":"<p>Els registres s\u00f3n xicotetes porcions de mem\u00f2ria que es troben integrades en el processador i que, per tant, funcionen a la mateixa velocitat que aquest.</p>"},{"location":"SOM/Tema01/SistemesInformatics/#162-memoria-cau","title":"1.6.2. Mem\u00f2ria Cau","text":"<ul> <li>El seu funcionament \u00e9s similar al de la mem\u00f2ria principal, que comentarem a continuaci\u00f3, per\u00f2 la seua grand\u00e0ria \u00e9s molt menor i el seu acc\u00e9s molt m\u00e9s r\u00e0pid.</li> <li>La idea \u00e9s que, quan el processador necessita accedir a una dada, es copia a la mem\u00f2ria cau tot el bloc que el cont\u00e9. Aix\u00ed, si es produeixen accessos successius (per a llegir o escriure) a la mateixa dada o a les seues dades circumdants, el temps d'acc\u00e9s es redueix dr\u00e0sticament.</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#163-memoria-principal","title":"1.6.3. Mem\u00f2ria Principal","text":"<ul> <li>Tamb\u00e9 es diu Mem\u00f2ria d'acc\u00e9s aleatori o Mem\u00f2ria RAM (de l'angl\u00e9s, Random-Access Memory) perqu\u00e8 en els primers ordinadors era l'\u00fanica mem\u00f2ria que permetia accedir a les dades sense seguir un ordre previ.</li> <li>Aquest \u00e9s el lloc on han de trobar-se tant les instruccions com les dades perqu\u00e8 el processador puga utilitzar-los. El seu contingut s'organitza en posicions de mem\u00f2ria que estan identificades de manera individual per una direcci\u00f3 \u00fanica.</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#164-dispositius-demmagatzematge-extern","title":"1.6.4. Dispositius d'emmagatzematge extern","text":"<ul> <li>S\u00f3n dispositius que permeten emmagatzemar grans volums d'informaci\u00f3.</li> <li>El seu principal caracter\u00edstica \u00e9s que no \u00e9s vol\u00e0til, \u00e9s a dir, no necessiten un subministrament continu de corrent el\u00e8ctric per a mantindre la informaci\u00f3 que contenen.</li> <li>Existeixen dispositius constru\u00efts a partir de tecnologies molt diferents, com les unitats magn\u00e8tiques (HDD, de l'angl\u00e9s Hard Disk Drive), les \u00f2ptiques (CD/DVD, de l'angl\u00e8s Compact Disc/Digital Versatile Disc) o les flaix (SSD, de l'angl\u00e9s Solid State Drive).</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#165-jerraquia-de-memories","title":"1.6.5. Jerraquia de memories","text":"<p>En principi, existeixen tres dades fonamentals que hem de tindre en compte quan ens referim a la mem\u00f2ria: la seua quantitat, la seua velocitat i el cost per unitat d'emmagatzematge (per exemple, el cost per byte).</p> <p>Gr\u00e0ficament obtenim una jerarquia de la mem\u00f2ria amb forma piramidal</p> <p></p> <p>Si prenem com a punt de partida la imatge anterior, podem afirmar que, segons es descendeix en la jerarquia, es compleixen les seg\u00fcents caracter\u00edstiques:</p> <ul> <li>Disminueix el cost per byte.</li> <li>Augmenta la capacitat.</li> <li>Augmenta el temps d'acc\u00e9s.</li> <li>Disminueix la freq\u00fc\u00e8ncia amb la qual s'accedeix a la mem\u00f2ria.</li> </ul> <p>La mem\u00f2ria principal funciona a una velocitat molt inferior a la del processador. No obstant aix\u00f2, aquest ha d'accedir a la mem\u00f2ria per a obtindre cadascuna de les instruccions que ha d'executar. Resulta evident la c\u00e0rrega que suposa aquesta situaci\u00f3 per al rendiment del processador.</p> <p>Per a resoldre-ho, els dissenyadors recorren al principi de proximitat. La idea consisteix a col\u00b7locar, entre el processador i la mem\u00f2ria principal, una mem\u00f2ria de poca grand\u00e0ria i gran velocitat, a la qual anomenem mem\u00f2ria cau.</p> <p>La idea \u00e9s que, cada vegada que el processador sol\u00b7licite una dada de la mem\u00f2ria principal, es busque primer en la mem\u00f2ria cau. Si no es troba, es llig de la mem\u00f2ria principal el bloc complet que cont\u00e9 la dada sol\u00b7licitada i es guarda en la cau.</p>"},{"location":"SOM/Tema01/SistemesInformatics/#17-unitats-dentradaeixida","title":"1.7. Unitats d'Entrada/Eixida","text":"<p>Els dispositius d'entrada/eixida tenen un doble objectiu:</p> <ul> <li>Permeten que l'ordinador es comunique amb l'exterior. Aix\u00ed obt\u00e9 la informaci\u00f3 que ha de processar o ofereix els resultats dels seus c\u00e0lculs.</li> <li>Codifiquen la informaci\u00f3 d'entrada en un format que comprenga l'ordinador i, la informaci\u00f3 d'eixida, en un format que s'entenga en l'exterior.</li> </ul> <p>El concepte general de les unitats d'entrada/eixida es va desenvolupar des de les primeres generacions d'ordinadors, en els quals les unitats d'entrada eren bastant senzilles.</p> <p>Hui dia, aquest concepte abasta una gran varietat de dispositius, molts d'ells totalment diferents i que s'han desenvolupat per a satisfer les necessitats de les diferents aplicacions.</p> <p>Existeix una gran varietat de dispositius d'entrada/eixida, per la qual cosa comen\u00e7arem per classificar-los en tres categories:</p> <ul> <li>Dispositius d'entrada: S\u00f3n els que s'encarreguen de subministrar informaci\u00f3 a l'ordinador. Entre els m\u00e9s coneguts trobem aquests: teclat, ratol\u00ed, webcam, micr\u00f2fon, esc\u00e0ner, etc</li> <li>Dispositius d'eixida: S\u00f3n els que s'encarreguen d'oferir informaci\u00f3 a l'exterior. Entre els m\u00e9s coneguts trobem aquests: monitor, impressora, altaveus, auriculars, etc.</li> <li>Dispositius d'entrada i eixida: S\u00f3n els que poden realitzar les dues funcions anteriors de manera simult\u00e0nia. Entre els m\u00e9s coneguts trobem els seg\u00fcents: pantalla t\u00e0ctil, dispositius d'emmagatzematge extern (discos durs, mem\u00f2ries USB, CDs o Dvds, \u2026), targetes de xarxa, \u2026</li> </ul>"},{"location":"SOM/Tema01/SistemesInformatics/#18-busos","title":"1.8. Busos","text":"<p>Podem definir els busos com a canals que serveixen per a transferir dades entre els diferents components d'un ordinador. Permeten interconnectar des de les diferents parts d'un circuit integrat fins als dispositius perif\u00e8rics units a l'ordinador. Segons la seua naturalesa, podem trobar dos tipus de busos:</p> <ul> <li>L\u00ednies de dades: Tots els bits d'un mateix byte s\u00f3n enviats alhora per les diferents l\u00ednies de dades del bus.</li> <li>L\u00ednies d'adre\u00e7a: Per elles circulen els bits que representen la posici\u00f3 de mem\u00f2ria o el dispositiu de dest\u00ed de la informaci\u00f3 que s'est\u00e0 transmetent.</li> <li>L\u00ednies de control: S'encarreguen d'enviar senyals de control entre els dispositius. Poden contindre informaci\u00f3 sobre l'estat de la comunicaci\u00f3, interrupcions o DMA.</li> </ul> <p></p>"},{"location":"SOM/Tema02/SistemesOperatius/","title":"2. Sistemes Operatius","text":""},{"location":"SOM/Tema02/SistemesOperatius/#21-sistema-operatiu-i-aplicacions","title":"2.1. Sistema Operatiu i aplicacions","text":"<p>La RAE defineix el programari com el conjunt de programes, instruccions i regles inform\u00e0tiques per a executar certes tasques en un ordinador\". Per tant, el programari \u00e9s l'encarregat de dirigir l'ordinador en la tasca d'obtenir resultats particulars.</p> <p>En l\u00ednies generals, podem dir que existeixen dos tipus de programari:</p> <ul> <li>El programari de sistema.</li> <li>El programari d'aplicaci\u00f3.</li> </ul> <p>Parlem d'ambd\u00f3s tipus de forma m\u00e9s detallada.</p>"},{"location":"SOM/Tema02/SistemesOperatius/#211-programari-de-sistema","title":"2.1.1. Programari de sistema","text":"<p>El programari de sistema, tamb\u00e9 conegut com a programari de base, \u00e9s el conjunt de programari que es fa c\u00e0rrec de gestionar els recursos hardware del sistema inform\u00e0tic, separant tant els usuaris finals com els desenvolupadors de programari de les seues caracter\u00edstiques espec\u00edfiques.</p> <p>Per a aconseguir-ho, incorpora una interf\u00edcie adequada per a l'usuari final i un conjunt de funcions i procediments que poden ser invocats pels programes d'aplicaci\u00f3 i que rep el nom d'API (de l'angl\u00e9s Application Programming Interface).</p> <p></p> <p>Encara que l'element fonamental del programari de sistema siga el sistema operatiu, tamb\u00e9 s'inclouen en aquest nivell els controladors de dispositiu, les eines de diagn\u00f2stic i altres utilitats. Entre els sistemes operatius m\u00e9s utilitzats es troben:</p> <ul> <li>Microsoft Windows.</li> <li>GNU/Linux.</li> <li>Apple macOS.</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#212-programari-daplicacio","title":"2.1.2. Programari d'aplicaci\u00f3","text":"<p>Est\u00e0 format per els programes que permeten als usuaris realitzar tasques concretes, que poden ser generals (processadors de text, fulls de c\u00e0lcul, navegadors d'internet, etc.) o espec\u00edfics per a activitats particulars que puguen recolzar-se en un sistema inform\u00e0tic (comptabilitat, disseny assistit per ordinador, videojocs, etc.).</p> <p>\u00c9s molt freq\u00fcent que just despr\u00e9s d'instal\u00b7lar un sistema operatiu trobem instal\u00b7lats alguns programes (calculadora, navegador, editor de textos, etc.). Encara que aquests programes formin part del programari d'aplicaci\u00f3, \u00e9s molt freq\u00fcent que els usuaris finals pensen que formen part del sistema operatiu. No obstant aix\u00f2, nom\u00e9s es tracta d'un complement que incorporen els prove\u00efdors del sistema operatiu per a facilitar certes tasques comunes.</p>"},{"location":"SOM/Tema02/SistemesOperatius/#22-sistemes-operatius-actuals","title":"2.2. Sistemes Operatius Actuals","text":"<p>Ja hem esmentat alguns dels sistemes operatius m\u00e9s utilitzats en ordinadors: Microsoft Windows, GNU/Linux i Apple macOS. No obstant aix\u00f2, nom\u00e9s ens hav\u00edem referit a les solucions d'escriptori, \u00e9s a dir, als sistemes operatius dissenyats per a l'\u00fas diari per part d'un usuari o un grup redu\u00eft d'ells. No obstant aix\u00f2, existeixen sistemes operatius per a ordinadors la tasca dels quals consisteix en oferir serveis a trav\u00e9s d'una xarxa a altres ordinadors (i als seus usuaris). En aquests casos, els sistemes d'escriptori actuen com a clients dels sistemes servidors.</p> <p>Nota</p> <p>GNU significa: \"GNU's Not Unix\"</p> <p>A m\u00e9s, existeixen altres sistemes operatius que, encara que no estan dissenyats per a ordinadors, tamb\u00e9 s\u00f3n molt comuns en l'actualitat, s\u00f3n els destinats a tel\u00e8fons intel\u00b7ligents (smartphones). Entre ells, podem mencionar els seg\u00fcents: Android, iOS, Windows Phone i, en menor mesura, Ubuntu Phone, Firefox OS, BlackBerry OS i Symbian.</p> <p>Tamb\u00e9 hi ha altres exemples de sistemes operatius que, en el moment d'escriure aquestes l\u00ednies, mostren certa rellev\u00e0ncia. Ens referim als seg\u00fcents:</p> <ul> <li>Chrome OS: Un sistema operatiu basat en GNU/Linux, desenvolupat per Google i orientat a Internet, on la principal eina \u00e9s el navegador.</li> <li>webOS: Un sistema operatiu basat en GNU/Linux, desenvolupat per LG per a incloure'l en els seus televisors.</li> <li>Tizen: Un sistema operatiu basat en GNU/Linux, recolzat per Linux Mobile Foundation (LiMo), Linux Foundation i Samsung, per a ser instal\u00b7lat en tel\u00e8fons intel\u00b7ligents, tauletes, etc.</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#23-interficie-dels-so","title":"2.3. Interficie dels S.O.","text":"<p>La interf\u00edcie dels sistemes operatius \u00e9s la que ens permet la comunicaci\u00f3 entre els usuaris i el maquinari de la m\u00e0quina.</p> <p></p> <p>Els sistemes operatius tenen dos tipus d'interf\u00edcie:</p> <ul> <li>Interf\u00edcie de tipus text: Totes les ordres que l'usuari introdu\u00efsca i les respostes que el SO dona se introduiran o visualitzaran mitjan\u00e7ant cadenes de car\u00e0cters.</li> <li>Interf\u00edcie de tipus gr\u00e0fic: El mitj\u00e0 de comunicaci\u00f3 entre l'usuari i l'ordinador \u00e9s gr\u00e0fic, i \u00e9s necessari l'\u00fas del ratol\u00ed.</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#24-so-lliures-i-propietaris","title":"2.4. S.O. Lliures i propietaris","text":"<p>Davant de l'\u00e0mplia gamma de sistemes operatius que trobem en l'actualitat, ens veiem obligats a acotar l'\u00e0mbit al qual ens dedicarem en aquest curs, amb l'objectiu de ser el m\u00e9s concrets possible. En aquest sentit, ens decantem per les versions d'escriptori de dos entorns principals:</p> <ul> <li>El sistema operatiu Microsoft Windows, com a paradigma dels sistemes amb llic\u00e8ncia de codi tancat.</li> <li>El sistema operatiu Ubuntu, que potser \u00e9s el que t\u00e9 una major repercussi\u00f3 entre els que ofereixen llic\u00e8ncies de codi obert.</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#25-programari-de-base-dun-so","title":"2.5. Programari de base d'un S.O.","text":"<p>Si no existira el programari de sistema tamb\u00e9 anomenat programari de base, cada programador que, per exemple, estiguera escrivint un programa que oferira dades impresses, hauria d'escriure les instruccions necess\u00e0ries per a controlar de forma precisa la impressora.</p> <p>Si, a m\u00e9s, l'objectiu f\u00f3ra que el programa funcionara en ordinadors amb diferents models d'impressora, hauria de repetir la feina per a cada model concret. Aix\u00f2 faria que la feina a la qual s'enfrontaria f\u00f3ra immensa.</p> <p>El programari de sistema fa que els programes d'aplicacions puguen manejar les impressores d'una forma gen\u00e8rica, amb ordres b\u00e0siques i senzilles, i el que \u00e9s m\u00e9s important, generals per a qualsevol model d'impressora.</p> <p>A m\u00e9s, aquesta idea s'aplica tamb\u00e9 a la resta dels dispositius: discs durs, dispositius d'emmagatzematge USB, monitors, ratolins, etc. Totes les ordres d'aquest tipus s\u00f3n les que formen l'API. Encara que l'element fonamental del programari de sistema siga el sistema operatiu, tamb\u00e9 s'inclouen en aquest nivell els controladors de dispositiu, les eines de diagn\u00f2stic i altres utilitats.</p>"},{"location":"SOM/Tema02/SistemesOperatius/#26-elements-i-estructura-del-so","title":"2.6. Elements i estructura del S.O.","text":"<p>Podr\u00edem definir el concepte de Sistema Operatiu com un programa, o un conjunt de programes que col\u00b7laboren entre ells per a administrar els elements f\u00edsics d'un sistema inform\u00e0tic, optimitzant el seu \u00fas i oferint determinats serveis als programes d'aplicaci\u00f3.</p> <p>Un sistema operatiu es far\u00e0 c\u00e0rrec d'aspectes com:</p> <ul> <li>L'\u00fas, compartit i ordenat, dels recursos entre diferents usuaris.</li> <li>La protecci\u00f3 de recursos, per evitar que un usuari accedisca a recursos als quals no est\u00e0 autoritzat.</li> </ul> <p>Perqu\u00e8 aquesta protecci\u00f3 siga possible, el sistema inform\u00e0tic ha de ser capa\u00e7 d'executar instruccions en dos nivells diferents:</p> <ul> <li>En mode usuari: \u00c9s el mode menys privilegiat de funcionament del sistema. En aquest mode no es permet l'acc\u00e9s directe al maquinari.</li> <li>En mode nucli (tamb\u00e9 anomenat mode kernel) o mode supervisor: En ell, les instruccions s'executen en un mode privilegiat, tenint acc\u00e9s directe a tota la mem\u00f2ria (inclosos els espais d'adreces de tots els processos que estiguen executant-se). En aquest mode nom\u00e9s s'executen algunes parts del sistema operatiu.</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#27-classificacio-dels-so","title":"2.7. Classificaci\u00f3 dels S.O.","text":"<p>Per nombre d'usuaris:</p> <ul> <li>Monousuari: Nom\u00e9s un usuari en l'ordinador en un moment donat.</li> <li>Multiusuari: Varios usuaris en l'ordinador.</li> </ul> <p>Per nombre de processos:</p> <ul> <li>Monotasca: Nom\u00e9s processa una tasca en un instant donat.</li> <li>Multitasca: Varies tasques simult\u00e0niament</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#28-elements-dun-so","title":"2.8. Elements d'un S.O.","text":"<p>Com podem imaginar, un sistema operatiu \u00e9s un programa molt complex que ha d'estar molt ben organitzat i estructurat internament per a dur a terme la seua feina d'una forma molt eficient. En aquest sentit, els sistemes operatius es subdividixen en diferents components que estan especialitzats en aspectes molt concrets del mateix.</p> <p>Els elements que constitueixen la majoria dels sistemes operatius s\u00f3n els seg\u00fcents:</p> <ul> <li>Gestor de processos.</li> <li>Gestor de mem\u00f2ria virtual.</li> <li>Gestor d'emmagatzematge secundari.</li> <li>Gestor d'entrada i eixida.</li> <li>Sistema d'arxius.</li> <li>Sistemes de protecci\u00f3.</li> <li>Sistema de comunicacions.</li> <li>Programes de sistema.</li> <li>Gestor de recursos.</li> </ul> <p></p>"},{"location":"SOM/Tema02/SistemesOperatius/#29-estructura-dun-so","title":"2.9 Estructura d'un  S.O.","text":"<p>Podem plantejar-nos la manera en qu\u00e8 aquests elements s'organitzen dins del sistema operatiu per a dur a terme el seu objectiu. Tamb\u00e9 ser\u00e0 important per al disseny del sistema establir quins components del mateix s'executen en mode nucli i quins en mode usuari.</p> <p>En aquest sentit, els plantejaments que s'apliquen en els sistemes operatius m\u00e9s coneguts s\u00f3n els seg\u00fcents:</p> <ul> <li>Monol\u00edtic.</li> <li>Micronucli.</li> <li>Nucli h\u00edbrid</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#291-monolitic","title":"2.9.1. Monol\u00edtic","text":""},{"location":"SOM/Tema02/SistemesOperatius/#292-micronucli","title":"2.9.2. Micronucli","text":""},{"location":"SOM/Tema02/SistemesOperatius/#293-nucli-hibrid","title":"2.9.3. Nucli h\u00edbrid","text":""},{"location":"SOM/Tema02/SistemesOperatius/#210-funcions-del-so","title":"2.10 Funcions del S.O.","text":"<p>La estructura d'un sistema operatiu es divideix en diferents m\u00f2duls que solen estar especialitzats en funcions concretes. En alguns casos existeix una relaci\u00f3 directa entre un determinat m\u00f2dul i una funci\u00f3 concreta del sistema operatiu. No obstant aix\u00f2, en altres casos, s\u00f3n diversos els m\u00f2duls que cooperen d'alguna manera per a dur a terme una funci\u00f3 espec\u00edfica.</p> <p>En qualsevol cas, aquestes s\u00f3n les principals funcions que duu a terme qualsevol sistema operatiu:</p> <ul> <li>Gesti\u00f3 de processos.</li> <li>Gesti\u00f3 de mem\u00f2ria.</li> <li>Gesti\u00f3 d'arxius.</li> <li>Gesti\u00f3 d'Entrada/Eixida (E/S).</li> </ul>"},{"location":"SOM/Tema02/SistemesOperatius/#bibliografia","title":"BIBLIOGRAFIA","text":"<p>Enlla\u00e7 a la font original (Cap\u00edtols 3 i 4)</p>"},{"location":"SOM/Tema03/GestioRecursos/","title":"3. Gesti\u00f3 de Recursos","text":"<p>En aquest tema veurem en detall la gesti\u00f3 de recursos que realitza el sistema operatiu:</p> <ul> <li>Gesti\u00f3 del processador</li> <li>Gesti\u00f3 de la mem\u00f2ria</li> <li>Gesti\u00f3 d'Entrada/Sortida</li> <li>Gesti\u00f3 d'Arxius</li> </ul>"},{"location":"SOM/Tema03/GestioRecursos/#31-gestio-del-processador","title":"3.1. Gesti\u00f3 del Processador","text":"<p>L'element del sistema operatiu que es fa c\u00e0rrec de la gesti\u00f3 del processador \u00e9s el planificador i les seues funcions son:</p> <ul> <li>Fer el canvi d'estat dels processos.</li> <li>Gestionar la cua d'espera de processos.</li> <li>Aplicar els algoritmes de planificaci\u00f3.</li> <li>Gestionar l'intercanvi de dades entre mem\u00f2ria i disc.</li> </ul> <p>Comencem amb el concepte de proces.</p>"},{"location":"SOM/Tema03/GestioRecursos/#311-proces","title":"3.1.1. Proces","text":"<p>La idea fonamental d'un sistema inform\u00e0tic consisteix en un dispositiu que \u00e9s capa\u00e7 d'executar ordres agrupades en forma de programes. Quan un programa no est\u00e0 en execuci\u00f3, no ser\u00e0 m\u00e9s que un fitxer de dades en un mitj\u00e0 d'emmagatzematge.</p> <p>En aquest sentit, podem entendre el concepte de proc\u00e9s com un programa que s'est\u00e0 executant. No obstant aix\u00f2, una definici\u00f3 m\u00e9s acad\u00e8mica seria aquesta:</p> <ul> <li>Una unitat d'activitat que executa una seq\u00fc\u00e8ncia ordenada d'instruccions, que disposa d'una s\u00e8rie de recursos assignats pel sistema i que es troba en un estat particular.</li> </ul> <p>Un programa, ent\u00e8s com un fitxer que cont\u00e9 ordres, resideix a la mem\u00f2ria secund\u00e0ria de l'ordinador, mentre que un proc\u00e9s resideix a la mem\u00f2ria principal. Tot proc\u00e9s t\u00e9 associat un espai d'adreces a la mem\u00f2ria principal, on es guarden les pr\u00f2pies instruccions del proc\u00e9s i les dades que maneja. A m\u00e9s, el sistema disposar\u00e0 d'una Taula de processos on guarda la informaci\u00f3 rellevant de cada proc\u00e9s:</p> <ul> <li>L'identificador del proc\u00e9s (PID, de l'angl\u00e8s, Process IDentifier)</li> <li>L'estat del proc\u00e9s, \u00e9s a dir, si est\u00e0 executant-se o no.</li> <li>La seva prioritat respecte als altres processos del sistema.</li> <li>La posici\u00f3 de mem\u00f2ria on es troba, entre altres.</li> </ul> <p>Els sistemes operatius intenten resoldre de la millor manera possible les seg\u00fcents situacions sobre els processos:</p> <ul> <li>Oferir als processos els recursos que necessiten.</li> <li>Repartir el temps d'execuci\u00f3 del processador entre diversos processos, de manera que estiga ocupat el major temps possible i permetent que tots ells tinguen un temps de resposta adequat.</li> <li>Facilitar la creaci\u00f3 de processos per part de l'usuari i d'altres processos</li> <li>Facilitar la comunicaci\u00f3 entre diferents processos.</li> </ul> <p>3.1.3. Execuci\u00f3 d'un proc\u00e9s</p> <p>Important:</p> <p>Perqu\u00e8 un proc\u00e9s s'execute, la seua seq\u00fc\u00e8ncia d'instruccions ha de trobar-se en la mem\u00f2ria principal.</p> <p>A m\u00e9s, en tots els sistemes operatius moderns, es va intercalant l'execuci\u00f3 de diferents processos, de manera que s'alternen l'\u00fas del processador.</p> <ul> <li>Nomenem multitasca o multiprogramaci\u00f3 a la capacitat que tenen els sistemes operatius actuals d'alternar l'\u00fas del processador entre diferents processos. Donada la velocitat a la qual funcionen els processadors, l'usuari t\u00e9 la sensaci\u00f3 que els processos s'executen al mateix temps.</li> <li>Quan en un sistema inform\u00e0tic disposem de diversos processadors, poden executar-se diversos processos al mateix temps. A aquesta t\u00e8cnica la diem multiproc\u00e9s o multiprocessament. Quan tots els processadors actuen en igualtat de condicions, parlem de multiproc\u00e9s sim\u00e8tric o SMP (Symmetric Multi-Processing). Quan el sistema disposa de processadors amb funcions especialitzades, parlem de multiproc\u00e9s asim\u00e8tric o AMP (Asymmetric Multi-*Processing).</li> </ul> <p>3.1.4 Estats d'un proc\u00e9s</p> <ul> <li>En execuci\u00f3: En aquest estat es trobar\u00e0 el proc\u00e9s que ocupa l'atenci\u00f3 del processador en aqueix moment.</li> <li>Preparat: En aquest estat es troben els processos que no s'estan executant, per\u00f2 que podrien fer-ho en qualsevol moment.</li> <li>Bloquejat: En aquest estat estaran els processos que han sol\u00b7licitat algun servei del sistema operatiu i estan esperant una resposta.</li> </ul> <p></p> <p>El processador executa un codi que pertany a un m\u00f2dul del sistema operatiu, anomenat Distribu\u00efdor (Dispatcher), cada vegada que un proc\u00e9s haja consumit el seu temps o haja sol\u00b7licitat algun servei pel qual haja d'esperar.</p> <p>Aix\u00ed s'evita que un proc\u00e9s s'apropie del processador de manera indefinida.</p> <p>Cada vegada que es crea un nou proc\u00e9s, aquest \u00e9s situat en estat de Preparat.</p> <p>Quan el proc\u00e9s que s'est\u00e0 executant \u00e9s interromput, el Distribu\u00efdor tria un nou proc\u00e9s entre els quals es troben en estat Preparat. L'estat del proc\u00e9s triat passa a ser En Execuci\u00f3 mentre que el proc\u00e9s que abandona l'execuci\u00f3 passar\u00e0 a estat Preparat (si ha consumit el seu temps) o Bloquejat (si ha realitzat una petici\u00f3 al sistema).</p> <p></p> <p>Els processos que es troben en estat Preparat esperen el seu torn en una cua.</p> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#315-canvi-de-context","title":"3.1.5 Canvi de context","text":"<p>Quan s'executa el m\u00f2dul del kernel que s'encarrega de parar l'execuci\u00f3 d'un proc\u00e9s i fer els canvis necessaris perqu\u00e8 s'execute un proc\u00e9s diferent, es produeix un canvi de context, amb aquestes accions:</p> <ul> <li>Guarda en la mem\u00f2ria principal el valor dels registres del processador per al proc\u00e9s que s'estava executant.</li> <li>Recupera el valor dels registres del processador, des de la mem\u00f2ria principal, per al proc\u00e9s que pren el relleu. El proc\u00e9s triat dependr\u00e0 del Planificador del sistema operatiu.</li> <li>S'executa la instrucci\u00f3 indicada en el Comptador de Programa, que forma part del context que acabem de recuperar i, per tant, ser\u00e0 la seg\u00fcent del nou proc\u00e9s.</li> </ul>"},{"location":"SOM/Tema03/GestioRecursos/#316-planificacio-de-processos","title":"3.1.6. Planificaci\u00f3 de processos","text":"<p>Perqu\u00e8 un sistema multiprogramat siga efica\u00e7 necessita una Planificaci\u00f3 de processos, anar assignant processos al processador al llarg del temps. Objectius:</p> <ul> <li>Rendiment: Tracta de maximitzar el nombre d'accions que es completen en un termini de temps determinat.</li> <li>Temps de resposta: El sistema ha de respondre a les sol\u00b7licituds dels usuaris en un temps adequat.</li> <li>Temps de retorn: El sistema ha d'oferir resultats dels processos per lots en un temps adequat.</li> <li>Equitat: Tots els processos han de ser considerats segons les seues caracter\u00edstiques.</li> <li>Efici\u00e8ncia: S'ha d'aspirar al fet que el processador estiga actiu constantment.</li> </ul> <p>Com cal esperar, el m\u00f2dul del sistema operatiu que s'encarrega d'aquesta tasca es denomina Planificador (en angl\u00e9s, Scheduler).</p> <p>Segons el disseny del sistema operatiu, el Planificador utilitzar\u00e0 uns criteris o altres per a dur a terme la seua tasca. Aquests criteris reben el nom d'Algorismes de Planificaci\u00f3 (o tamb\u00e9, Pol\u00edtiques de Planificaci\u00f3).</p> <p>Vegem a continuaci\u00f3 els principals algoritmes de planificaci\u00f3</p> <p>Nota aclaridora:</p> <p>Una pol\u00edtica de planificaci\u00f3 \u00e9s no apropiativa (en angl\u00e9s, non-preemptive) quan, una vegada que un proc\u00e9s pren el control del processador, no l'abandona fins que acaba o fins que es bloqueja. Ser\u00e0 apropiativa (en angl\u00e9s, preemptive) quan el sistema pot interrompre el proc\u00e9s per a executar un altre diferent.</p>"},{"location":"SOM/Tema03/GestioRecursos/#317-algoritmes-de-planificacio","title":"3.1.7. Algoritmes de planificaci\u00f3","text":"<p>FCFS (First Come First Served)</p> <p>\u00c9s emprat en processos per lots (sense intervenci\u00f3 de l'usuari) i \u00e9s no apropiatiu. Els processos es van posant en cua segons arriben i se'ls assigna l'estat Preparat. Quan \u00e9s assignat al processador, no l'abandona fins que acaba. Una dels seues avantatges principals consisteix en el fet que \u00e9s un algorisme molt senzill d'implementar i tamb\u00e9 \u00e9s f\u00e0cilment predictible. Entre els seus principals inconvenients podem esmentar que els processos llargs poden fer esperar molt als processos curts FCFS (First Come First Served) Exemple pr\u00e0ctic en el qual disposem de cinc processos que s'incorporen al sistema en moments successius i que tenen diferents temps de duraci\u00f3</p> <p></p> <p>SJF (Shortest Job First)</p> <p>\u00c9s emprat en processos per lots (sense intervenci\u00f3 de l'usuari) i \u00e9s no apropiatiu. Els processos es van posant en cua segons arriben i se'ls assigna l'estat Preparat, per\u00f2 el Planificador tria el que t\u00e9 un menor temps previst d'execuci\u00f3.</p> <p></p> <p>SRTF (Shortest Remaining Time First)</p> <p>SRTF (Shortest Remaining Time First) \u00e9s un algoritme emprat en processos per lots (sense intervenci\u00f3 de l'usuari) i no apropiatiu. Els processos es posen en cua segons arriben i se'ls assigna l'estat Preparat. No obstant aix\u00f2, el Planificador tria el proc\u00e9s amb el temps previst m\u00e9s curt d'execuci\u00f3.</p> <p></p> <p>RR (Round Robin)</p> <p>RR (Round Robin) s'utilitza en processos interactius (on interv\u00e9 l'usuari) i \u00e9s apropiatiu. Els processos es posen en cua segons arriben i se'ls assigna l'estat Preparat. El processador s'assigna a cada proc\u00e9s en ordre durant un per\u00edode de temps anomenat \"Qu\u00e0ntum\", que \u00e9s igual per a tots els processos.</p> <p></p> <p>Planificaci\u00f3 per prioritat</p> <p>La planificaci\u00f3 per prioritat s'emplea en processos interactius i \u00e9s apropiativa. Cada proc\u00e9s rep un nombre enter que representa la seva prioritat, on un nombre menor indica una prioritat m\u00e9s alta. Si es considera no apropiativa, funciona com l'algoritme \"Primer el m\u00e9s curt\" (SJF), per\u00f2 considera la prioritat en lloc de la durada.</p> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#318-comunicacio-entre-processos","title":"3.1.8. Comunicaci\u00f3 entre processos","text":"<p>Els sistemes operatius sovint executen diversos processos que han de comunicar-se per col\u00b7laborar en un objectiu com\u00fa. </p> <p>Aix\u00f2 es fa mitjan\u00e7ant funcions anomenades IPC (Inter-Process Communication) que faciliten l'enviament de missatges entre processos i la sincronitzaci\u00f3.</p>"},{"location":"SOM/Tema03/GestioRecursos/#32-gestio-de-memoria","title":"3.2. Gesti\u00f3 de Mem\u00f2ria","text":"<p>La gesti\u00f3 de mem\u00f2ria en un sistema operatiu es refereix a l'administraci\u00f3 i control de la mem\u00f2ria del sistema. Aix\u00f2 \u00e9s essencial per garantir que els programes s'executen sense problemes i no hi haja conflictes en l'\u00fas de la mem\u00f2ria. Aquests s\u00f3n els conceptes clau:</p> <ol> <li> <p>Assignaci\u00f3 de Mem\u00f2ria: La gesti\u00f3 de mem\u00f2ria implica assignar espai de mem\u00f2ria a programes i processos. Aix\u00f2 es fa per garantir que cada programa tinga suficient mem\u00f2ria per funcionar correctament.</p> </li> <li> <p>Administraci\u00f3 de l'Espai Lliure: El sistema operatiu realitza un seguiment de l'espai lliure en la mem\u00f2ria per saber on carregar nous programes o dades.</p> </li> <li> <p>Protecci\u00f3 de la Mem\u00f2ria: Per evitar que un programa accedisca indegudament a la mem\u00f2ria d'altres programes, s'implementen mecanismes de protecci\u00f3.</p> </li> </ol> <p>Hi ha dos esquemes clau en la gesti\u00f3 de mem\u00f2ria, la paginaci\u00f3 i la segmentaci\u00f3, que s'utilitzen juntament amb el concepte de mem\u00f2ria virtual.</p>"},{"location":"SOM/Tema03/GestioRecursos/#321-gestio-de-memoria-per-a-un-sol-proces","title":"3.2.1. Gesti\u00f3 de Mem\u00f2ria per a un Sol Proces","text":"<p>Quan es tracta d'un sol proc\u00e9s en execuci\u00f3, la gesti\u00f3 de mem\u00f2ria implica assignar i alliberar mem\u00f2ria din\u00e0micament segons les necessitats del proc\u00e9s. Aquest enfocament s'utilitza t\u00edpicament en sistemes operatius multitasca, on diversos processos competeixen per la mem\u00f2ria. Els conceptes clau inclouen:</p> <ul> <li> <p>Assignaci\u00f3 Din\u00e0mica: La mem\u00f2ria s'assigna al proc\u00e9s a mesura que la necessita. Aix\u00f2 permet un \u00fas eficient de la mem\u00f2ria, per\u00f2 requereix una gesti\u00f3 cuidadosa per evitar la fragmentaci\u00f3.</p> </li> <li> <p>Alliberament de Mem\u00f2ria: Quan un proc\u00e9s ja no necessita mem\u00f2ria, aquesta es libera i es torna a posar a disposici\u00f3 d'altres processos.</p> </li> </ul> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#322-gestio-de-memoria-amb-particions-fixes","title":"3.2.2. Gesti\u00f3 de Mem\u00f2ria amb Particions Fixes","text":"<p>En la gesti\u00f3 de mem\u00f2ria amb particions fixes, la mem\u00f2ria es divideix en seccions de grand\u00e0ria uniforme anomenades particions. Cada partici\u00f3 s'assigna a un proc\u00e9s en particular. Els aspectes clau s\u00f3n:</p> <ul> <li> <p>Assignaci\u00f3 de Particions: Cada proc\u00e9s es carrega en una partici\u00f3 de grand\u00e0ria predeterminada. Aix\u00f2 pot portar a un malbaratament de mem\u00f2ria si els processos tenen diferents grand\u00e0ries.</p> </li> <li> <p>Fragmentaci\u00f3 Interna: Les particions poden tenir espai no utilitzat, el que es coneix com fragmentaci\u00f3 interna.</p> </li> </ul> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#323-gestio-de-memoria-amb-particions-variables","title":"3.2.3. Gesti\u00f3 de Mem\u00f2ria amb Particions Variables","text":"<p>La gesti\u00f3 de mem\u00f2ria amb particions variables permet assignar mem\u00f2ria de manera m\u00e9s flexible, ja que les particions poden tenir grand\u00e0ries diferents segons les necessitats dels processos. Aspectes importants:</p> <ul> <li> <p>Assignaci\u00f3 Flexible: Els processos s'assignen a particions segons la seua grand\u00e0ria, minimitzant la fragmentaci\u00f3 interna.</p> </li> <li> <p>Fragmentaci\u00f3 Externa: Tot i reduir la fragmentaci\u00f3 interna, pot haver-hi fragmentaci\u00f3 externa, on hi ha prou mem\u00f2ria total, per\u00f2 no es pot assignar a un proc\u00e9s degut a la distribuci\u00f3 de particions.</p> </li> </ul> <p></p> <p>Fragmentaci\u00f3</p> <ul> <li>Fragmentaci\u00f3 Externa: Espai de la mem\u00f2ria que hi ha fora de les particions que no s'utilitza.</li> <li>Fragmentaci\u00f3 Interna: Espai que hi ha dins de les particions que no s'utilitza.</li> </ul>"},{"location":"SOM/Tema03/GestioRecursos/#324-memoria-virtual","title":"3.2.4. Mem\u00f2ria Virtual","text":"<p>Tots els m\u00e8todes estudiats fins al moment suposen que un proc\u00e9s ha d'estar completament carregat en mem\u00f2ria per a poder executar-se. No obstant aix\u00f2, el model de Mem\u00f2ria virtual aplica els mecanismes d'intercanvi que ja hem esmentat perqu\u00e8 les parts d'un proc\u00e9s que no estiguen sent utilitzades en un moment concret, puguen residir en mem\u00f2ria secund\u00e0ria. D'aquesta manera, s'allibera una major quantitat de mem\u00f2ria principal per a albergar un nombre de processos superior. A m\u00e9s, aquest plantejament ens permetria executar processos que foren m\u00e9s grans que la mem\u00f2ria f\u00edsica.</p> <p>Quan el proc\u00e9s fa refer\u00e8ncia a una direcci\u00f3 de mem\u00f2ria que no resideix en mem\u00f2ria principal, es produeix una fallada de p\u00e0gina. En aqueix moment, el sistema localitza un marc de p\u00e0gina lliure i c\u00e0rrega en ell la p\u00e0gina necess\u00e0ria. Si no hi haguera marcs lliures, caldria aplicar un algorisme de substituci\u00f3 per a triar la p\u00e0gina d'aquest o un altre proc\u00e9s que ha d'abandonar la mem\u00f2ria principal per a deixar espai a la qual ha de carregar-se.</p> <p>Mentre dura tota aquesta operaci\u00f3, el proc\u00e9s que va originar la fallada de p\u00e0gina roman en estat Bloquejat.</p> <p>Per a saber quines p\u00e0gines es troben en mem\u00f2ria principal i quins estan en el disc, la taula de p\u00e0gines pot incloure un bit de pres\u00e8ncia.</p> <p>Aquest tipus d'esquemes aconsegueixen que la mem\u00f2ria s'aprofite molt millor. A m\u00e9s, en poder carregar m\u00e9s processos en la mateixa quantitat de mem\u00f2ria, el processador estar\u00e0 m\u00e9s ben aprofitat.</p> <p>No obstant aix\u00f2, si es produeix una situaci\u00f3 que provoque una quantitat elevada de fallades de p\u00e0gina, els accessos a disc es multiplicaran i el rendiment pot caure de manera considerable. Aquest fenomen rep el nom de hiperpaginaci\u00f3.</p>"},{"location":"SOM/Tema03/GestioRecursos/#325-paginacio","title":"3.2.5. Paginaci\u00f3","text":"<p>La paginaci\u00f3 divideix la mem\u00f2ria en blocs de grand\u00e0ria fixa anomenats \"p\u00e0gines\". Cada proc\u00e9s rep p\u00e0gines a la mem\u00f2ria principal segons les seues necessitats. Aix\u00f2 t\u00e9 avantatges, com un \u00fas eficient de la mem\u00f2ria i una administraci\u00f3 m\u00e9s senzilla. No obstant aix\u00f2, pot haver-hi fragmentaci\u00f3 interna i requereix una taula de p\u00e0gines per fer un seguiment de les ubicacions.</p> <p> </p> <p>Aspectes dels marcs de p\u00e0gina</p> <p>Un aspecte important \u00e9s la mida dels marcs de p\u00e0gina:</p> <ul> <li>Amb marcs de p\u00e0gina petits, hi ha poca fragmentaci\u00f3 interna i taules de p\u00e0gines grans.</li> <li>Amb marcs de p\u00e0gina grans, hi ha m\u00e9s fragmentaci\u00f3 interna i taules de p\u00e0gines petites.</li> </ul> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#326-segmentacio","title":"3.2.6. Segmentaci\u00f3","text":"<p>La segmentaci\u00f3 divideix la mem\u00f2ria en segments l\u00f2gics de grand\u00e0ria variable per reflectir l'estructura l\u00f2gica d'un programa. Ofereix flexibilitat, per\u00f2 pot causar fragmentaci\u00f3 externa. Es necessita una taula de segments per rastrejar els segments a la mem\u00f2ria.</p> <p>Un programa es considera un conjunt d'elements l\u00f2gics de mides variables.</p> <p></p> <p>La segmentaci\u00f3 planteja que, en compilar un programa, aquest es converteixi en un conjunt de segments als quals se'ls assignar\u00e0 un identificador, un punt d'inici i una mida.</p> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#327-paginacio-segmentacio","title":"3.2.7.  Paginaci\u00f3 + Segmentaci\u00f3","text":"<p>Quan els segments s\u00f3n grans, \u00e9s com\u00fa utilitzar una combinaci\u00f3 de paginaci\u00f3 i segmentaci\u00f3. La idea \u00e9s dividir cada segment en p\u00e0gines de longitud fixa per a la seva ubicaci\u00f3 a la mem\u00f2ria.</p>"},{"location":"SOM/Tema03/GestioRecursos/#328-control-dus-de-memoria","title":"3.2.8. Control d'\u00fas de mem\u00f2ria","text":"<p>Per gestionar l'\u00fas de mem\u00f2ria, hi ha dos enfocaments generals: </p> <p>Mapes de bits Els mapes de bits divideixen la mem\u00f2ria en  unitats d'assignaci\u00f3, que poden ser des d'unes quantes paraules fins a diversos kilobytes. A cada unitat d'assignaci\u00f3 li correspon un bit del mapa de bits. El bit \u00e9s 0 si la unitat d'assignaci\u00f3 est\u00e0 lliure i 1 si est\u00e0 ocupada (o viceversa).</p> <p>Un mapa de bits pro porciona una manera senzilla de portar el control de les paraules de mem\u00f2ria utilitzant una quantitat de mem\u00f2ria fixa perqu\u00e8 la seua grand\u00e0ria nom\u00e9s dep\u00e9n de la grand\u00e0ria de la mem\u00f2ria i de la grand\u00e0ria de la unitat  d'assignaci\u00f3. El problema principal amb ell \u00e9s que una vegada que s'ha decidit portar a la mem\u00f2ria un proc\u00e9s de k unitats, el gestor de mem\u00f2ria ha d'examinar el mapa de bits a la recerca d'una seq\u00fc\u00e8ncia de k bits a 0 consecutius. Buscar en el mapa una seq\u00fc\u00e8ncia d'una certa longitud \u00e9s una operaci\u00f3 lenta (perqu\u00e8 la seq\u00fc\u00e8ncia en el mapa pot travessar fronteres de paraula); aquest \u00e9s un argument en contra de l'\u00fas dels mapes de bits.</p> <p></p> <p>Llistes Enlla\u00e7ades</p> <p>Una altra manera de portar el control de la mem\u00f2ria \u00e9s mantindre una llista enlla\u00e7ada de blocs de mem\u00f2ria assignats i lliures, on cada bloc \u00e9s un proc\u00e9s o un buit entre dos processos.</p> <p>La mem\u00f2ria es representa com una llista enlla\u00e7ada. Cada node de la llista representa un bloc, especificant el tipus de bloc [buit (H) o proc\u00e9s (P)], la seua adre\u00e7a de comen\u00e7ament, la seua longitud i un punter al seg\u00fcent node</p> <p>Les llistes enlla\u00e7ades mantenen registres de blocs de mem\u00f2ria assignats i lliures, on cada bloc representa un proc\u00e9s o un espai buit entre processos.</p> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#33-gestio-des","title":"3.3. Gesti\u00f3 d'E/S","text":"<p>El sistema operatiu haur\u00e0 de controlar els dispositius, detectar interrupcions i manejar errors. Tamb\u00e9 ha de proporcionar una interf\u00edcie entre els perif\u00e8rics i la resta del sistema intentant que el seu \u00fas siga el m\u00e9s est\u00e0ndard possible.</p> <p>En un sistema inform\u00e0tic modern podem trobar molts dispositius d'entrada/eixida diferents. No obstant aix\u00f2, un dels objectius del disseny d'un sistema operatiu \u00e9s que l'usuari, o el programador, els perceben d'una forma semblant, sense importar els detalls t\u00e8cnics que els distingeixen ni la difer\u00e8ncia quant a la complexitat del dispositiu.</p>"},{"location":"SOM/Tema03/GestioRecursos/#331-tecniques-de-gestio-des","title":"3.3.1. T\u00e8cniques de gesti\u00f3 d'E/S","text":"<p>Un ordinador pot utilitzar diferents t\u00e8cniques per a interactuar amb els controladors d'entrada/eixida. Com ja vam fer en l'apartat anterior, nomenarem les m\u00e9s representatives de menor a major sofisticaci\u00f3:</p> <ul> <li>Entrada/eixida programada: El processador executa una instrucci\u00f3 d'un proc\u00e9s que sol\u00b7licita una operaci\u00f3 d'entrada/eixida. Es realitza el requeriment al m\u00f2dul d'entrada/eixida corresponent, i queda en espera de rebre la resposta.e/s programada</li> </ul> <p></p> <ul> <li> <p>Entrada/eixida controlada per interrupcions: El processador executa una instrucci\u00f3 d'un proc\u00e9s que sol\u00b7licita una operaci\u00f3 d'entrada/eixida. Llavors, el proc\u00e9s espera en estat Bloquejat i el processador continua amb l'execuci\u00f3 d'altres instruccions. Quan es completa l'operaci\u00f3, el m\u00f2dul d'entrada/eixida genera una interrupci\u00f3 per al processador i aquest executa el m\u00f2dul del sistema operatiu que posa al proc\u00e9s en estat Llest. </p> </li> <li> <p>Acc\u00e9s directe a mem\u00f2ria (o DMA, de l'angl\u00e9s Direct Memory Access): L'equip disposa d'un m\u00f2dul DMA autoritzat per a accedir directament a la mem\u00f2ria RAM. D'aquesta  manera, en lloc d'encarregar-se el processador de controlar cada operaci\u00f3 individual d'entrada o eixida, es confia en el m\u00f2dul DMA perqu\u00e8 execute diverses operacions consecutives posant (o obtenint) la informaci\u00f3 directament en la mem\u00f2ria RAM. El m\u00f2dul DMA interromp al processador nom\u00e9s quan han acabat totes les operacions que tenia encarregades.</p> </li> </ul> <p></p> <ul> <li>Processadors d'entrada/eixida (o IOP): L'equip disposa d'un processador complementari amb la capacitat d'executar les operacions d'entrada/eixida, obtenint-les directament de la mem\u00f2ria principal. Tamb\u00e9 pot utilitzar t\u00e8cniques de DMA per a llegir o escriure les dades en la mem\u00f2ria. D'aquesta manera, el processador principal queda alliberat d'aquesta mena d'operacions. </li> </ul> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#332-emagatzament-intermedi","title":"3.3.2. Emagatzament intermedi","text":"<p>Quan \u00e9s necessari llegir un gran volum de dades de l'emmagatzematge secundari, el proc\u00e9s anir\u00e0 emetent sol\u00b7licituds de blocs de manera consecutiva, que anir\u00e0 processant d'un en un. Com l'emmagatzematge secundari \u00e9s molt m\u00e9s lent, entre una lectura i una altra el proc\u00e9s, probablement, romandr\u00e0 en estat Bloquejat. Una vegada completada la lectura, haur\u00e0 d'esperar en la cua de processos en estat Llest fins que el Planificador ho trie per a la seua execuci\u00f3.</p> <p>Per a evitar aquesta situaci\u00f3, s'utilitza una t\u00e8cnica denominada buffering, que consisteix en el fet que el sistema operatiu realitze les lectures abans que es produ\u00efsca la sol\u00b7licitud, emmagatzemant-les en una \u00e0rea de la mem\u00f2ria principal que rep el nom de Buffer</p> <p>Una cosa semblant pot fer-se quan disposem de dispositius molt lents que, no obstant aix\u00f2, poden rebre grans volums de dades. En aquests casos, pot utilitzar-se una mem\u00f2ria interm\u00e8dia situada en un emmagatzematge extern (t\u00edpicament, un disc) i anar enviant les dades a poc a poc al dispositiu extern.</p> <p>Aquesta t\u00e8cnica, encara que \u00e9s semblant al buffering, rep el nom de spooling i la mem\u00f2ria interm\u00e8dia rep el nom de spool (de l'angl\u00e9s, Simultaneous Peripheral Operations On-Line). \u00c9s una t\u00e8cnica que s'utilitza habitualment amb les impressores.</p>"},{"location":"SOM/Tema03/GestioRecursos/#34-gestio-darxius","title":"3.4. Gestio d'Arxius","text":"<p>El sistema operatiu \u00e9s responsable de les seg\u00fcents activitats relacionades amb la gesti\u00f3 de discos:</p> <ul> <li>Creaci\u00f3 i administraci\u00f3 de l'estructura l\u00f2gica (Sistema d'arxius).</li> <li>Administraci\u00f3 d'espai lliure.</li> <li>Assignaci\u00f3 d'emmagatzematge.</li> <li>Planificaci\u00f3 del disc: Decideix a quin proc\u00e9s se li dona servei de disc.</li> </ul> <p>El Sistema d'arxius (en angl\u00e9s, filesystem) \u00e9s el component del sistema operatiu que s'encarrega d'organitzar la manera en qu\u00e8 es guarden les dades dins dels dispositius d'emmagatzematge secundari. Per a dur a terme la seua tasca, des d'un punt de vista l\u00f2gic utilitza dos conceptes diferents:</p> <ul> <li>Arxiu (o fitxer): \u00e9s una s\u00e8rie de bytes emmagatzemats en un dispositiu d'emmagatzematge extern que, en conjunt, formen una unitat l\u00f2gica. Cada arxiu sol estar identificat en el sistema mitjan\u00e7ant un nom i una extensi\u00f3. Normalment, el nom serveix per a identificar el contingut de l'arxiu i l'extensi\u00f3 per a identificar el tipus al qual pertany.</li> <li>Carpeta (o directori): \u00e9s una manera d'agrupar arxius, segons el criteri de l'usuari, per a facilitar la seua organitzaci\u00f3. Igual que els arxius, les carpetes tenen un nom que les identifica. Per a un sistema d'arxius, una carpeta no \u00e9s m\u00e9s que un arxiu que cont\u00e9 informaci\u00f3 sobre la manera en qu\u00e8 s'organitzen les dades. Com en el cas dels arxius, per a evitar ambig\u00fcitats, no pot haver-hi dues carpetes amb el mateix nom en la mateixa ubicaci\u00f3.</li> </ul> <p>Com podem suposar, la unitat d'informaci\u00f3 amb la qual treballa un sistema d'arxius \u00e9s, precisament, l'arxiu.</p> <p>\u00c9s freq\u00fcent que cada fam\u00edlia de sistemes operatius tinga els seus propis sistemes d'arxius. Per exemple, a continuaci\u00f3 relacionem els m\u00e9s coneguts:</p> <p></p> <p>Un sistema d'arxius s'encarregar\u00e0 d'aspectes com:</p> <ul> <li>Organitzar de manera l\u00f2gica els sectors del dispositiu per a constituir arxius i directoris</li> <li>Assignar espai d'emmagatzematge als arxius i mantindre el control sobre els sectors que pertanyen a cada arxiu.</li> <li>Oferir els mecanismes que permeten crear nous arxius, canviar-los el nom i/o la ubicaci\u00f3, modificar el seu contingut o eliminar-los.</li> <li>Mantindre l'estructura jer\u00e0rquica del sistema de directoris.</li> <li>Controlar l'acc\u00e9s segur als arxius. \u00c9s a dir, que nom\u00e9s puguen accedir a les dades els usuaris autoritzats</li> <li>Controlar quins sectors romanen disponibles per a ser ocupats en qualsevol moment.</li> </ul>"},{"location":"SOM/Tema03/GestioRecursos/#341-atributs-i-permisos","title":"3.4.1. Atributs i permisos","text":"<p>El sistema operatiu ha de tindre la capacitat de controlar quin usuari pot accedir a cadascun dels seus recursos (directoris, impressores, connexions de xarxa, etc.). Per a aconseguir-ho, cadascun d'aquests recursos sol tindre associada una Llista de Control d'Acc\u00e9s o ACL (de l'angl\u00e9s, Access Control List), en la qual es relacionen els diferents usuaris que poden accedir i baix quines condicions (lectura, escriptura, execuci\u00f3, \u2026)</p> <p>D'altra banda, un determinat arxiu pot tindre associats diferents atributs, que informen sobre unes certes caracter\u00edstiques de l'arxiu o de la manera en qu\u00e8 el sistema operatiu ha de tractar-lo. Aix\u00ed, un arxiu pot tindre atributs com: directori, ocult, de sistema, xifratge, etc</p>"},{"location":"SOM/Tema03/GestioRecursos/#342-organitzacio-del-sistema-darxiux","title":"3.4.2. Organitzaci\u00f3 del sistema d'arxiux","text":"<p>Hui dia, pr\u00e0cticament tots els sistemes d'arxius que podem trobar organitzen els arxius de manera jer\u00e0rquica, permetent la creaci\u00f3 d'un arbre de directoris que faciliten l'organitzaci\u00f3 i classificaci\u00f3 del seu contingut.</p> <p>A m\u00e9s, per a evitar ambig\u00fcitats, els sistemes operatius no permeten que, dins del mateix directori, existisquen dos arxius amb el mateix nom.</p> <p></p>"},{"location":"SOM/Tema03/GestioRecursos/#343-rutes","title":"3.4.3. Rutes","text":"<p>Per a expressar la ubicaci\u00f3 exacta d'un arxiu o un directori s'utilitza la seua ruta (en angl\u00e9s, path). Encara que la manera d'expressar una ruta pot canviar segons el sistema operatiu que estiguem usant. En general es formen indicant la llista jer\u00e0rquica de directoris que representa el cam\u00ed que hem de rec\u00f3rrer per a arribar fins a un arxiu o directori. En aqueixa relaci\u00f3, l'\u00faltim element ser\u00e0 el propi arxiu o directori referenciat.</p> <p>En escriure una ruta, haurem d'utilitzar un car\u00e0cter que separe cada element del seg\u00fcent. Aquest car\u00e0cter separador sol ser una barra invertida () en els sistemes Microsoft i una barra inclinada (/) en la fam\u00edlia de sistemes Unix, com \u00e9s el cas de GNU/Linux.</p> <p>Altres car\u00e0cters especials que podem utilitzar en una ruta s\u00f3n els seg\u00fcents:</p> <ul> <li>. (un punt): Fa refer\u00e8ncia al directori en el qual ens trobem (tamb\u00e9 anomenat directori actual)</li> <li>.. (dos punts): Fa refer\u00e8ncia al directori que es troba, jer\u00e0rquicament, just damunt del directori en el qual ens trobem (tamb\u00e9 anomenat directori pare)</li> <li>~ (una virgulilla): En sistemes de la fam\u00edlia Unix, com GNU/Linux, fa refer\u00e8ncia al directori personal de l'usuari que escriu la ruta.</li> </ul> <p>Existeixen dues maneres diferents d'escriure rutes:</p> <ul> <li>De manera absoluta: Una ruta d'aquest tipus far\u00e0 refer\u00e8ncia a un arxiu o directori a partir del directori arrel.<ul> <li>En els sistemes de la fam\u00edlia Unix, una ruta absoluta comen\u00e7a per una barra inclinada. Per exemple:<ul> <li>/home/Alicia/Documentos/informe.odt</li> </ul> </li> <li>En els sistemes Microsoft, \u00e9s necessari comen\u00e7ar la ruta absoluta amb la lletra d'unitat a la qual fa refer\u00e8ncia, seguida de dos punts i una barra invertida. Per exemple:<ul> <li>c:\\Usuaris\\Alicia\\Documentos\\informe.odt</li> </ul> </li> </ul> </li> <li>De manera relativa: Una ruta d'aquest tipus far\u00e0 refer\u00e8ncia a un arxiu o directori prenent com a punt de partida el directori en el qual ens trobem. Per exemple:<ul> <li>../../Jacinto/Documents/mem\u00f2ria.odt</li> <li>(com pot apreciar-se, l'exemple \u00e9s v\u00e0lid en sistemes de la fam\u00edlia Unix, per\u00f2 bastaria amb canviar el sentit de les barres perqu\u00e8 fora v\u00e0lid en sistemes Microsoft)</li> </ul> </li> </ul>"},{"location":"SOM/Tema04/Virtualitzacio/","title":"4. Virtualizaci\u00f3n","text":""},{"location":"SOM/Tema04/Virtualitzacio/#41-virtualizacion-de-recursos-tecnologicos","title":"4.1. Virtualizaci\u00f3n de Recursos Tecnol\u00f3gicos","text":"<p>La virtualizaci\u00f3n de recursos tecnol\u00f3gicos es una tecnolog\u00eda que permite optimizar el uso de hardware y recursos inform\u00e1ticos al crear versiones virtuales de estos recursos. </p> <p>Estos recursos pueden incluir servidores, sistemas operativos, almacenamiento, redes, aplicaciones y m\u00e1s. </p> <p>La virtualizaci\u00f3n permite ejecutar m\u00faltiples entornos virtuales de forma independiente en un mismo servidor f\u00edsico. Esto proporciona una mayor flexibilidad y eficiencia en la gesti\u00f3n de los recursos.</p>"},{"location":"SOM/Tema04/Virtualitzacio/#42-conceptos-de-virtualizacion-hardware","title":"4.2. Conceptos de Virtualizaci\u00f3n Hardware","text":"<ol> <li> <p>Anfitri\u00f3n (Host): El anfitri\u00f3n es el servidor f\u00edsico en el que se instala el software de virtualizaci\u00f3n. Este servidor es responsable de alojar y administrar las m\u00e1quinas virtuales.</p> </li> <li> <p>M\u00e1quina Virtual (VM): Las m\u00e1quinas virtuales son entornos virtuales independientes que se crean en el servidor anfitri\u00f3n. Cada VM puede tener su propio sistema operativo, aplicaciones y configuraciones. Las VMs comparten los recursos f\u00edsicos del host, pero est\u00e1n aisladas entre s\u00ed.</p> </li> <li> <p>Hypervisor o Monitor de M\u00e1quina Virtual (VMM): El hipervisor es el componente clave de la virtualizaci\u00f3n. Es el software que se ejecuta en el host y permite la creaci\u00f3n, gesti\u00f3n y ejecuci\u00f3n de las m\u00e1quinas virtuales. Los hipervisores pueden ser de tipo 1 (Bare-Metal) o de tipo 2 (Hosted), como se mencion\u00f3 anteriormente.</p> </li> </ol>"},{"location":"SOM/Tema04/Virtualitzacio/#43-hipervisores-y-tipos","title":"4.3. Hipervisores y Tipos","text":"<p>Hipervisor de Tipo 1 (Bare-Metal): Este tipo de hipervisor se ejecuta directamente en el hardware f\u00edsico del servidor, sin la necesidad de un sistema operativo anfitri\u00f3n adicional. Esto garantiza un alto rendimiento y eficiencia, ya que las m\u00e1quinas virtuales se ejecutan m\u00e1s cerca del hardware. Ejemplos de hipervisores de tipo 1 incluyen VMware vSphere/ESXi, Microsoft Hyper-V, Xen y KVM.</p> <p></p> <p>Hipervisor de Tipo 2 (Hosted): Los hipervisores de tipo 2 se ejecutan sobre un sistema operativo anfitri\u00f3n existente. Estos son adecuados para entornos de desarrollo y pruebas, pero pueden tener un rendimiento ligeramente inferior en comparaci\u00f3n con los hipervisores de tipo 1. Ejemplos de hipervisores de tipo 2 incluyen VirtualBox, VMware Workstation y Parallels Desktop.</p> <p></p>"},{"location":"SOM/Tema04/Virtualitzacio/#44-como-funciona-la-virtualizacion","title":"4.4.  C\u00f3mo Funciona la Virtualizaci\u00f3n","text":"<p>La virtualizaci\u00f3n se basa en la abstracci\u00f3n de los recursos f\u00edsicos del servidor. El hipervisor se encarga de crear capas de abstracci\u00f3n entre las m\u00e1quinas virtuales y el hardware subyacente. Cuando una VM necesita recursos, el hipervisor los asigna de manera din\u00e1mica, asegurando que cada VM tenga acceso a la cantidad necesaria de CPU, memoria, almacenamiento y red. La virtualizaci\u00f3n tambi\u00e9n incluye caracter\u00edsticas como instant\u00e1neas (snapshots), clonaci\u00f3n, migraci\u00f3n en caliente y escalabilidad, lo que facilita la administraci\u00f3n de las VM.</p>"},{"location":"SOM/Tema04/Virtualitzacio/#45-ventajas-y-desventajas-de-la-virtualizacion","title":"4.5.  Ventajas y Desventajas de la Virtualizaci\u00f3n","text":"<p>Ventajas:</p> <ul> <li> <p>Mayor Utilizaci\u00f3n de Recursos: La virtualizaci\u00f3n permite consolidar m\u00faltiples aplicaciones y servidores en una sola m\u00e1quina f\u00edsica, lo que optimiza la utilizaci\u00f3n de recursos.</p> </li> <li> <p>Aislamiento: Cada m\u00e1quina virtual es independiente y aislada, lo que evita que un fallo en una VM afecte a otras.</p> </li> <li> <p>Migraci\u00f3n y Flexibilidad: Las VMs pueden moverse entre servidores f\u00edsicos, lo que facilita la migraci\u00f3n, la recuperaci\u00f3n ante desastres y la alta disponibilidad.</p> </li> <li> <p>Optimizaci\u00f3n de Costos: La virtualizaci\u00f3n reduce los costos operativos al requerir menos hardware f\u00edsico y simplificar la administraci\u00f3n.</p> </li> </ul> <p>Desventajas:</p> <ul> <li>Overhead: Existe una peque\u00f1a p\u00e9rdida de rendimiento debido al software de virtualizaci\u00f3n.</li> <li> <p>VMware Fusion: (para entornos de escritorio).</p> </li> <li> <p>Licenciamiento: Algunos productos de virtualizaci\u00f3n requieren licencias costosas, lo que puede aumentar los costos.</p> </li> <li> <p>Seguridad: Si no se configura correctamente, las VMs pueden ser vulnerables a amenazas de seguridad. La administraci\u00f3n y el acceso adecuados son cr\u00edticos.</p> </li> </ul>"},{"location":"SOM/Tema04/Virtualitzacio/#46-software-de-virtualizacion","title":"4.6. Software de Virtualizaci\u00f3n","text":"<p>Existen varias soluciones de software de virtualizaci\u00f3n en el mercado, tanto comerciales como de c\u00f3digo abierto. Algunas de las m\u00e1s populares incluyen:</p> <ul> <li>VMware vSphere/ESXi: Un hipervisor de tipo 1 l\u00edder en la industria con una amplia gama de caracter\u00edsticas.</li> <li>VMware Workstation: Un hipervisor de tipo 2 para entornos de escritorio.</li> <li>Microsoft Hyper-V: Un hipervisor de tipo 1 desarrollado por Microsoft, a menudo utilizado en entornos de Windows.</li> <li>KVM (Kernel-based Virtual Machine): Un hipervisor de c\u00f3digo abierto que se ejecuta en sistemas Linux.</li> <li>VirtualBox: Un hipervisor de tipo 2 de c\u00f3digo abierto que es popular para entornos de desarrollo y pruebas.</li> <li>Proxmox Virtual Environment: Una plataforma de virtualizaci\u00f3n de c\u00f3digo abierto que combina KVM y contenedores LXC.</li> </ul>"},{"location":"SOM/Tema04/Virtualitzacio/#47-virtual-box","title":"4.7. Virtual Box","text":"<p>VirtualBox es una herramienta de virtualizaci\u00f3n que permite a los usuarios crear y ejecutar m\u00e1quinas virtuales en un sistema anfitri\u00f3n. A continuaci\u00f3n, se presentan sus caracter\u00edsticas m\u00e1s importantes y c\u00f3mo crear una m\u00e1quina virtual a partir de una imagen ISO:</p> <ul> <li>Soporte Multiplataforma: VirtualBox es compatible con varios sistemas operativos, incluyendo Windows, Linux, macOS y m\u00e1s.</li> <li>Migraci\u00f3n en Caliente: Permite la migraci\u00f3n de m\u00e1quinas virtuales en ejecuci\u00f3n de un sistema anfitri\u00f3n a otro sin interrupciones.</li> <li>Portabilidad: Las m\u00e1quinas virtuales creadas en VirtualBox son altamente port\u00e1tiles y se pueden transferir f\u00e1cilmente a otros sistemas que ejecuten VirtualBox.</li> <li>Interfaz Gr\u00e1fica Intuitiva: Ofrece una interfaz de usuario gr\u00e1fica f\u00e1cil de usar para la gesti\u00f3n de m\u00e1quinas virtuales.</li> <li>Redes Personalizables: Permite configurar redes internas, NAT, adaptadores puente y m\u00e1s para personalizar la conectividad de las m\u00e1quinas virtuales.</li> <li>Instant\u00e1neas: Facilita la creaci\u00f3n de instant\u00e1neas de m\u00e1quinas virtuales para restaurar estados anteriores en caso de problemas.</li> <li>Extensiones y Adiciones: VirtualBox admite extensiones y adiciones que mejoran la funcionalidad de las m\u00e1quinas virtuales.</li> </ul> <p>Pasos para la creaci\u00f3n de una M\u00e1quina Virtual desde una ISO</p> <ol> <li>Descarga e Instalaci\u00f3n de VirtualBox: Descarga e instala VirtualBox desde el sitio web oficial.</li> <li>Crear una Nueva M\u00e1quina Virtual: Abre VirtualBox y haz clic en \"Nueva\". Sigue el asistente para configurar la m\u00e1quina virtual.</li> <li>Asignar Recursos: Define la cantidad de memoria RAM, CPU y espacio de almacenamiento para la m\u00e1quina virtual.</li> <li>Seleccionar la ISO: Durante la configuraci\u00f3n, elige la opci\u00f3n de arrancar desde una imagen ISO y selecciona la imagen ISO que deseas utilizar.</li> <li>Instalar el Sistema Operativo: Inicia la m\u00e1quina virtual. Se iniciar\u00e1 desde la ISO y podr\u00e1s instalar el sistema operativo c\u00f3mo lo har\u00edas en una computadora f\u00edsica.</li> <li>Personalizar Configuraciones: Despu\u00e9s de la instalaci\u00f3n, personaliza la configuraci\u00f3n de la m\u00e1quina virtual seg\u00fan tus necesidades.</li> </ol>"},{"location":"SOM/Tema04/Virtualitzacio/#471-snapshots-en-virtualbox","title":"4.7.1. Snapshots en VirtualBox","text":"<p>Las snapshots son una funci\u00f3n que permite tomar una \"foto\" instant\u00e1nea del estado actual de una m\u00e1quina virtual. Esta instant\u00e1nea incluye el sistema operativo, las aplicaciones y los datos tal como est\u00e1n en el momento de la captura. Las snapshots son \u00fatiles para:</p> <ul> <li>Backups: Puedes tomar una snapshot antes de realizar cambios significativos en la m\u00e1quina virtual. Si algo sale mal, puedes restaurarla al estado previo.</li> <li>Testing: Facilitan la experimentaci\u00f3n. Puedes crear diferentes instant\u00e1neas para probar configuraciones sin riesgo.</li> <li>Registro de Desarrollo: Los desarrolladores pueden utilizar snapshots para registrar diferentes etapas del desarrollo de software.</li> </ul> <p>C\u00f3mo funcionan:</p> <ul> <li>Para crear una snapshot, selecciona la m\u00e1quina virtual en VirtualBox y elige \"Tomar una instant\u00e1nea\".</li> <li>Puedes darle un nombre y descripci\u00f3n a la snapshot para identificarla f\u00e1cilmente.</li> <li>Una vez creada, puedes volver a ese estado en cualquier momento.</li> </ul>"},{"location":"SOM/Tema04/Virtualitzacio/#471-clonaciones-en-virtualbox","title":"4.7.1. Clonaciones en VirtualBox","text":"<p>Las clonaciones son la capacidad de duplicar una m\u00e1quina virtual existente. Esto puede ser \u00fatil para crear m\u00faltiples copias id\u00e9nticas de una VM, ahorrando tiempo y recursos. Las clonaciones son \u00fatiles para:</p> <ul> <li>Desarrollo y Pruebas: Puedes clonar una VM para probar diferentes configuraciones o escenarios sin afectar la original.</li> <li>Implementaci\u00f3n de Servidores: Facilita la creaci\u00f3n de m\u00faltiples instancias de servidores id\u00e9nticos.</li> </ul> <p>C\u00f3mo funcionan:</p> <ul> <li>Selecciona la m\u00e1quina virtual que deseas clonar en VirtualBox.</li> <li>Elige \"Clonar\" y configura las opciones, como si deseas una copia completa o enlazada.</li> <li>Una vez clonada, puedes iniciar y usar la nueva m\u00e1quina virtual de la misma manera que la original.</li> </ul> <p>Consejos Importantes</p> <ul> <li>Las snapshots consumen espacio en disco, as\u00ed que admin\u00edstralas cuidadosamente para evitar llenar el almacenamiento.</li> <li>Las clonaciones enlazadas comparten recursos con la VM original y ocupan menos espacio en disco, pero los cambios afectan a todas las instancias vinculadas.</li> <li>Estas caracter\u00edsticas hacen que VirtualBox sea una herramienta vers\u00e1til para la gesti\u00f3n y desarrollo de m\u00e1quinas virtuales. Aseg\u00farate de entender c\u00f3mo funcionan antes de usarlas en tu entorno de virtualizaci\u00f3n.</li> </ul>"},{"location":"SOM/Tema04/Virtualitzacio/#48-aws","title":"4.8. AWS","text":"<p>Amazon Web Services (AWS) es una plataforma de servicios en la nube ofrecida por Amazon. Proporciona una amplia gama de servicios en la nube que permiten a las empresas y desarrolladores ejecutar aplicaciones y servicios en l\u00ednea de manera eficiente y escalable.</p> <p>AWS ofrece servicios como almacenamiento, bases de datos, redes, an\u00e1lisis, inteligencia artificial, aprendizaje autom\u00e1tico, y m\u00e1s. Estos servicios se distribuyen a trav\u00e9s de centros de datos en todo el mundo, lo que permite a los usuarios acceder a recursos inform\u00e1ticos de alto rendimiento de manera flexible.</p> <p>Amazon Elastic Compute Cloud (EC2) es uno de los servicios m\u00e1s populares de AWS y permite crear m\u00e1quinas virtuales (instancias) en la nube. Aqu\u00ed tienes los pasos para crear una instancia EC2:</p> <ol> <li>Iniciar sesi\u00f3n en AWS: Accede a tu cuenta de AWS o crea una si a\u00fan no tienes una.</li> <li>Acceder al Panel de Control de AWS: Una vez dentro, accede al panel de control de AWS desde el men\u00fa de servicios.</li> <li>Seleccionar EC2: En el panel de control, encuentra y selecciona \"EC2\" bajo la categor\u00eda \"Compute\".</li> <li>Lanzar una Instancia: Haz clic en el bot\u00f3n \"Lanzar una instancia\" para iniciar el asistente de creaci\u00f3n.</li> <li>Elegir una Imagen (AMI): Selecciona una imagen de m\u00e1quina virtual (AMI) que se adapte a tus necesidades, como una versi\u00f3n de Linux o Windows.</li> <li>Configurar la Instancia: Define la cantidad de instancias, el tipo de instancia, y otras configuraciones como la red y el almacenamiento.</li> <li>Crear una Clave de Acceso: Crea o selecciona una clave de acceso que te permitir\u00e1 conectarte a la instancia de forma segura.</li> <li>Revisar y Lanzar: Revisa tus configuraciones y haz clic en \"Lanzar\" para iniciar la instancia.</li> <li>Asociar Reglas de Seguridad: Configura reglas de seguridad para controlar el acceso a la instancia.</li> <li>Conectar a la Instancia: Utiliza software de acceso remoto (por ejemplo, SSH para Linux) para conectarte a tu instancia EC2.</li> </ol>"},{"location":"SOM/Tema04/Virtualitzacio/#49-mapa-mental","title":"4.9. Mapa Mental","text":"<pre><code>graph LR;\n  Virtualizacion[Virtualizaci\u00f3n];\n  A[Virtualizaci\u00f3n de Recursos Tecnol\u00f3gicos];\n  B[Conceptos de Virtualizaci\u00f3n Hardware];\n  C[Hipervisores y Tipos];\n  D[C\u00f3mo Funciona la Virtualizaci\u00f3n];\n  E[Ventajas y Desventajas de la Virtualizaci\u00f3n];\n  F[Software de Virtualizaci\u00f3n];\n  Virtualizacion--&gt;A;\n  Virtualizacion--&gt;C;\n  Virtualizacion--&gt;D;\n  Virtualizacion--&gt;E;\n  Virtualizacion--&gt;F;\n  A--&gt;B;\n  B--&gt;1[Anfitri\u00f3n];\n  B--&gt;2[M\u00e1quina Virtual ];\n  B--&gt;3[Hypervisor o Monitor de M\u00e1quina Virtual];\n  C --&gt; 4[Hipervisor de Tipo 1 Bare-Metal];\n  C --&gt; 5[Hipervisor de Tipo 2 Hosted];\n  D --&gt; 6[Abstracci\u00f3n de Recursos];\n  D --&gt; 7[Asignaci\u00f3n de Recursos];\n  D --&gt; 8[Caracter\u00edsticas de la Virtualizaci\u00f3n];\n  E --&gt; 9[Ventajas];\n  E --&gt; 10[Desventajas];\n  F --&gt; 11[VMware vSphere-ESXi];\n  F --&gt; 12[VMware Workstation];\n  F --&gt; 13[Microsoft Hyper-V];\n  F --&gt; 14[KVM Kernel-based Virtual Machine];\n  F --&gt; 15[VirtualBox];\n  F --&gt; 16[Proxmox Virtual Environment];</code></pre>"}]}